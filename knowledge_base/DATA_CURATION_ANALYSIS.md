# Data Curation Analysis & Improvement Plan

**Date**: December 7, 2025  
**Status**: üî¥ **NEEDS MAJOR IMPROVEMENTS**  
**Audience**: Data curation engineers

---

## üìã Table of Contents

1. [Project Context](#project-context)
2. [Data Format Requirements](#data-format-requirements)
3. [Executive Summary](#executive-summary)
4. [Current Data Inventory](#current-data-inventory)
5. [Critical Problems](#critical-problems)
6. [Detailed Analysis by Dataset](#detailed-analysis-by-dataset)
7. [How to Download Datasets](#how-to-download-currently-available-datasets)
8. [Recommended Action Plan](#recommended-action-plan)
9. [Implementation Scripts](#implementation-scripts-needed)
10. [Validation Criteria](#validation-criteria)
11. [Success Metrics](#success-metrics)

---

## Project Context

### What is StealthRL?

**StealthRL** is a reinforcement learning system that trains language models to evade multiple AI text detectors simultaneously while maintaining text quality and ESL fairness.

**Research Goal**: Train a single model that can:
1. Evade detection by multiple detectors (FastDetectGPT, Ghostbuster, Binoculars)
2. Maintain semantic quality and coherence
3. **Critically**: Ensure fair performance for ESL (English as Second Language) writers

### Why Data Curation Matters

**ESL Fairness is the Core Contribution**: 
- Existing AI detectors are biased against ESL writers (higher false positive rates)
- This research aims to reduce detector bias by training on balanced ESL/native data
- **Target**: 40% ESL, 60% native English samples
- **Current Problem**: Only 3% ESL data available (182 samples)

**Without proper ESL data**:
- ‚ùå Cannot evaluate fairness (main research contribution)
- ‚ùå Results not publishable
- ‚ùå Model won't learn to handle ESL text properly

### Training Platform

- **Model**: Qwen2.5-Coder-3B-Instruct with LoRA (rank 16)
- **Algorithm**: GRPO (Group-Relative Policy Optimization)
- **Compute**: Tinker remote training platform
- **Training time**: ~8-12 hours for 10k samples
- **Cost**: Free (academic allocation)

### Current Project Status

‚úÖ **Task 1 Complete**: Real detectors implemented and tested  
‚ö†Ô∏è **Task 2 Partial**: Data downloaded but poorly extracted  
‚è∏Ô∏è **Task 3 Blocked**: Cannot start training without balanced dataset

**Your Mission**: Complete Task 2 by curating a balanced, high-quality dataset.

---

## Data Format Requirements

### Required JSONL Format

Every dataset must be in **JSONL** (JSON Lines) format with this exact structure:

```json
{
  "ai_text": "The text generated by an AI model that needs to be made undetectable...",
  "human_reference": "The original human-written text that the AI tried to mimic...",
  "domain": "academic",
  "is_esl": false,
  "metadata": {
    "source": "detectrl",
    "data_type": "arxiv_abstract",
    "model": "chatgpt",
    "proficiency_level": "B2"
  }
}
```

### Field Descriptions

| Field | Type | Required | Description | Example |
|-------|------|----------|-------------|----------|
| `ai_text` | string | ‚úÖ | AI-generated version of the text | "The study demonstrates that..." |
| `human_reference` | string | ‚úÖ | Original human-written text | "Our research shows that..." |
| `domain` | string | ‚úÖ | Text domain/category | "academic", "professional", "creative", "essay" |
| `is_esl` | boolean | ‚úÖ | Whether written by ESL learner | `true` or `false` |
| `metadata` | object | ‚úÖ | Source and context information | See below |

### Metadata Requirements

```json
"metadata": {
  "source": "detectrl",           // Dataset name
  "data_type": "arxiv_abstract",  // Specific data type
  "model": "chatgpt",             // AI model used (if applicable)
  "proficiency_level": "B2",      // For ESL data (A1, A2, B1, B2, C1, C2)
  "language_background": "Chinese", // For ESL data (optional)
  "additional_info": {}           // Any extra context
}
```

### Quality Requirements

**Text Length**:
- Minimum: 50 words per text
- Ideal: 100-500 words
- Maximum: No hard limit, but prefer <1000 words

**Quality Checks**:
- ‚úÖ Both `ai_text` and `human_reference` must be present
- ‚úÖ Both texts must be in English
- ‚úÖ No duplicate entries (check by content hash)
- ‚úÖ `is_esl` must be correctly labeled
- ‚úÖ Domain should match actual content
- ‚úÖ Text should be complete (no truncation)

### File Organization

```
data/
‚îú‚îÄ‚îÄ esl/                    # ESL-only datasets
‚îÇ   ‚îú‚îÄ‚îÄ toefl11.jsonl       # TOEFL essays (182 samples)
‚îÇ   ‚îú‚îÄ‚îÄ icnale.jsonl        # ICNALE corpus (target: 5,600)
‚îÇ   ‚îî‚îÄ‚îÄ ellipse.jsonl       # ELLIPSE corpus (target: 6,000)
‚îÇ
‚îú‚îÄ‚îÄ native/                 # Native English datasets
‚îÇ   ‚îú‚îÄ‚îÄ detectrl_native_large.jsonl  # DetectRL (5,600 samples)
‚îÇ   ‚îú‚îÄ‚îÄ native_full.jsonl            # ChatGPT-Bias native (303)
‚îÇ   ‚îú‚îÄ‚îÄ human_detectors.jsonl        # News articles (target: 500-1k)
‚îÇ   ‚îî‚îÄ‚îÄ ghostbuster.jsonl            # Ghostbuster data (target: 1-2k)
‚îÇ
‚îú‚îÄ‚îÄ tinker_large/           # Combined training datasets
‚îÇ   ‚îú‚îÄ‚îÄ train.jsonl         # 80% split for training
‚îÇ   ‚îî‚îÄ‚îÄ test.jsonl          # 20% split for evaluation
‚îÇ
‚îî‚îÄ‚îÄ processed/              # Final balanced datasets
    ‚îú‚îÄ‚îÄ balanced_40esl/     # 40% ESL, 60% native
    ‚îÇ   ‚îú‚îÄ‚îÄ train.jsonl
    ‚îÇ   ‚îî‚îÄ‚îÄ test.jsonl
    ‚îî‚îÄ‚îÄ maximum/            # All available data
        ‚îú‚îÄ‚îÄ train.jsonl
        ‚îî‚îÄ‚îÄ test.jsonl
```

---

## Executive Summary

**Current State**: Data curation has been **partially completed** but is severely limited in ESL coverage and underutilizes downloaded datasets.

**Key Issues**:
1. ‚ùå **Critical ESL shortage**: Only 182 ESL samples (3% of dataset) vs. 40% target
2. ‚ùå **Massive data waste**: Downloaded 2.87 GB but only extracted 485 samples from ChatGPT-Detector-Bias
3. ‚ùå **Missing ESL sources**: ICNALE and ELLIPSE not downloaded
4. ‚ùå **Unexplored datasets**: Ghostbuster, Human Detectors, DIPPER not processed

---

## Current Data Inventory

### ‚úÖ Successfully Extracted

| Source | ESL | Native | Total | Status |
|--------|-----|--------|-------|--------|
| **ChatGPT-Detector-Bias** | 182 | 303 | 485 | ‚úÖ Fully extracted |
| **DetectRL** | 0 | 5,600 | 5,600 | ‚ö†Ô∏è No ESL data |
| **TOTAL EXTRACTED** | **182** | **5,903** | **6,085** | |

### ‚ùå Downloaded But Not Processed

| Dataset | Size | Potential Samples | Status |
|---------|------|-------------------|--------|
| **Ghostbuster** | 26 MB | ~1,000-2,000? | ‚ùå Not extracted |
| **Human Detectors** | 12 MB | ~500-1,000? | ‚ùå Not extracted |
| **ai-detection-paraphrases** | 608 KB | ~100-200? | ‚ùå Not extracted |

### ‚ùå Not Downloaded (Critical ESL Sources)

| Dataset | Expected Samples | ESL Coverage | Priority |
|---------|------------------|--------------|----------|
| **ICNALE** | ~5,600 essays | 100% ESL | üî• CRITICAL |
| **ELLIPSE** | ~6,000+ essays | 100% ESL | üî• CRITICAL |
| **EFCAMDAT** | ~1,000,000+ | 100% ESL | HIGH |

---

## Critical Problems

### Problem 1: Severe ESL Data Shortage

**Current**: 182 ESL samples = **3% of total dataset**  
**Target**: 40% ESL ratio  
**Gap**: Missing **2,254 ESL samples** to reach 40% with current native data

**Impact**:
- ‚ùå Cannot properly evaluate ESL fairness (main research goal!)
- ‚ùå Model won't learn to reduce ESL bias effectively
- ‚ùå Results won't be publishable due to imbalanced data

**Root Cause**: 
- Only extracted from ChatGPT-Detector-Bias (single source)
- ICNALE and ELLIPSE mentioned in docs but never downloaded
- No exploration of other ESL corpora

### Problem 2: Massive Data Waste

**Downloaded**: 2.87 GB (349,165 DetectRL samples available)  
**Extracted**: 6,085 samples (1.7% utilization rate)  
**Wasted**: 343,080 samples sitting unused

**Specific Waste**:
- Ghostbuster (26 MB): 0 samples extracted
- Human Detectors (12 MB): 0 samples extracted  
- ai-detection-paraphrases (608 KB): 0 samples extracted

### Problem 3: Incorrect Data Source Priority

**What Was Done**: Downloaded massive detection benchmarks (DetectRL, Ghostbuster)  
**What Should Have Been Done**: Prioritize ESL sources (ICNALE, ELLIPSE)

According to project docs:
- **Target ESL sources**: TOEFL11 ‚úÖ, ICNALE ‚ùå, ELLIPSE ‚ùå
- **Actual focus**: Detection benchmarks (wrong priority for fairness research)

---

## Detailed Analysis by Dataset

### 1. ChatGPT-Detector-Bias ‚úÖ (Correctly Processed)

**What was extracted**:
- ‚úÖ 182 TOEFL essays (ESL)
- ‚úÖ 145 CS224N papers (native academic)
- ‚úÖ 70 College essays (native)
- ‚úÖ 88 Hewlett essays (native)

**Assessment**: **GOOD** - Fully extracted all available data

**Limitation**: Only source with ESL data, hence the shortage

### 2. DetectRL ‚ö†Ô∏è (Partially Processed)

**What was extracted**:
- ‚úÖ 2,800 arxiv abstracts (academic)
- ‚úÖ 2,800 writing prompts (stories)
- Total: 5,600 native samples

**What was missed**:
- ‚ùå Only extracted from 4 files out of 23 available
- ‚ùå Focused only on "abstract" and "story" data types
- ‚ùå Ignored: yelp reviews, xsum articles, other LLM types

**Potential**: Could extract **10,000-15,000 more samples** from unused files

**Assessment**: **INCOMPLETE** - Extracted <20% of available data

### 3. Ghostbuster ‚ùå (Not Processed)

**Status**: Downloaded but never examined

**Structure**: 
- Has results/ directory with CSV files
- Likely contains human vs AI text pairs
- Format needs investigation

**Action Needed**: 
1. Investigate data structure
2. Extract human-AI pairs if available
3. Estimate: ~1,000-2,000 potential samples

### 4. Human Detectors ‚ùå (Not Processed)

**Status**: Downloaded, single JSON file found

**Structure**:
- Contains news articles with human/AI versions
- Keys: generation_model, title, author, source
- Format: Dictionary with numeric keys

**Potential**: ~500-1,000 samples

**Action Needed**: Extract and convert to required format

### 5. ai-detection-paraphrases (DIPPER) ‚ùå (Not Processed)

**Status**: Downloaded but no data files found in quick search

**Expected Content**: Paraphrased versions of text for detection evasion

**Action Needed**: Deep investigation of directory structure

### 6. ICNALE ‚ùå (NOT DOWNLOADED - CRITICAL!)

**Description**: International Corpus Network of Asian Learners of English  
**Size**: ~5,600 essays from Asian ESL learners  
**ESL Coverage**: 100% (various proficiency levels)  
**Format**: Plain text essays with metadata

**Why Critical**: 
- Largest publicly available ESL corpus
- Diverse proficiency levels (A2-B2+)
- Multiple L1 backgrounds (Chinese, Japanese, Korean, etc.)
- Perfect for fairness research

**Download**: https://language.sakura.ne.jp/icnale/

**Impact if Downloaded**: Would add **5,600 ESL samples** ‚Üí 24% ESL ratio

### 7. ELLIPSE ‚ùå (NOT DOWNLOADED - CRITICAL!)

**Description**: English Language Learners Insight, Proficiency and Skills Evaluation  
**Size**: ~6,000+ essays  
**ESL Coverage**: 100% (English learners)  
**Format**: CSV with essays and scores

**Why Critical**:
- Kaggle dataset, easy to download
- Rich metadata (proficiency scores, nationality)
- Well-structured for research

**Download**: https://www.kaggle.com/competitions/feedback-prize-english-language-learning

**Impact if Downloaded**: Would add **6,000 ESL samples** ‚Üí 35% ESL ratio

---

## How to Download Currently Available Datasets

### Datasets Already Downloaded ‚úÖ

The following datasets are already in `data/raw/`:

1. **ChatGPT-Detector-Bias** (34 MB) - ‚úÖ Downloaded
2. **DetectRL** (2.8 GB) - ‚úÖ Downloaded  
3. **Ghostbuster** (26 MB) - ‚úÖ Downloaded
4. **Human Detectors** (12 MB) - ‚úÖ Downloaded
5. **ai-detection-paraphrases** (608 KB) - ‚úÖ Downloaded

These were downloaded using `scripts/download_datasets.sh`. No re-download needed.

### How to Download Missing ESL Datasets

#### ICNALE Corpus (5,600 ESL essays)

**Method 1: Web Download (Recommended)**
```bash
# 1. Visit the ICNALE website
open "https://language.sakura.ne.jp/icnale/"

# 2. Navigate to "Download" section
# 3. Register for free access (academic use)
# 4. Download "ICNALE Written Essays" package
# 5. Extract to data/raw/icnale/

# Expected structure:
# data/raw/icnale/
#   ‚îú‚îÄ‚îÄ SMK/     (Spoken Monologue Korean)
#   ‚îú‚îÄ‚îÄ PTJ/     (Part-Time Job essays)
#   ‚îî‚îÄ‚îÄ W_PTJ_1.2/ (Written Part-Time Job essays - USE THIS)
```

**Method 2: Direct Research Access**
```bash
# If you have institutional access to ICNALE corpus
# Contact: icnale@sakura.ne.jp for bulk download permissions
```

**What to download**: 
- Focus on **"ICNALE Written Essays"** component
- Subcorpus: PTJ (Part-time Job topic)
- Format: Plain text files with metadata
- Size: ~50-100 MB

#### ELLIPSE Corpus (6,000+ ESL essays)

**Method 1: Kaggle CLI (Recommended)**
```bash
# 1. Install Kaggle CLI
pip install kaggle

# 2. Set up Kaggle API credentials
# Go to: https://www.kaggle.com/settings
# Click "Create New API Token" -> downloads kaggle.json
mkdir -p ~/.kaggle
mv ~/Downloads/kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json

# 3. Download ELLIPSE dataset
cd data/raw/
kaggle competitions download -c feedback-prize-english-language-learning
unzip feedback-prize-english-language-learning.zip -d ellipse/
rm feedback-prize-english-language-learning.zip

# Expected files:
# data/raw/ellipse/
#   ‚îú‚îÄ‚îÄ train.csv (main training data - ~3,900 essays)
#   ‚îú‚îÄ‚îÄ test.csv (test data - ~2,100 essays)
#   ‚îî‚îÄ‚îÄ sample_submission.csv
```

**Method 2: Manual Download**
```bash
# 1. Visit Kaggle competition page
open "https://www.kaggle.com/competitions/feedback-prize-english-language-learning/data"

# 2. Click "Download All" button (requires Kaggle account)
# 3. Extract downloaded zip to data/raw/ellipse/
```

**What's in ELLIPSE**:
- **train.csv**: 3,911 essays with scores (cohesion, syntax, vocabulary, etc.)
- **test.csv**: 2,100 essays for evaluation
- Columns: `full_text` (essay content), `score_*` (proficiency scores)
- Format: CSV (easy to parse)

#### Alternative ESL Sources (If needed)

**TOEFL11 (Already have via ChatGPT-Detector-Bias)**
```bash
# Already extracted: data/esl/toefl11.jsonl (182 samples)
# Original source: https://catalog.ldc.upenn.edu/LDC2014T06
# Note: This is the TOEFL corpus, but limited to free subset
```

**EFCAMDAT (Advanced - Requires Application)**
```bash
# Cambridge English Write & Improve corpus
# Size: 1,000,000+ texts from language learners
# Access: Requires academic research application
# URL: https://philarion.mml.cam.ac.uk/
# Timeline: 2-4 weeks approval process
```

**Lang-8 Learner Corpus**
```bash
# Language learning platform data
# Access: https://lang-8.com/
# Note: May require special permissions for research use
# Alternative: HSK Chinese Learner Corpus (similar concept)
```

### Quick Download Script

**Already created**: `scripts/download_esl_datasets.sh` ‚úÖ

The script is ready to use:

```bash
#!/bin/bash

echo "üîΩ Downloading ESL datasets for StealthRL..."

# Create directories
mkdir -p data/raw/ellipse
mkdir -p data/raw/icnale

# Download ELLIPSE via Kaggle
echo "üì• Downloading ELLIPSE from Kaggle..."
if command -v kaggle &> /dev/null; then
    cd data/raw/
    kaggle competitions download -c feedback-prize-english-language-learning
    unzip -q feedback-prize-english-language-learning.zip -d ellipse/
    rm feedback-prize-english-language-learning.zip
    cd ../..
    echo "‚úÖ ELLIPSE downloaded: $(wc -l < data/raw/ellipse/train.csv) training essays"
else
    echo "‚ùå Kaggle CLI not installed. Install with: pip install kaggle"
    echo "   Then configure API token from https://www.kaggle.com/settings"
fi

# ICNALE requires manual download
echo ""
echo "üìã ICNALE Download Instructions:"
echo "   1. Visit: https://language.sakura.ne.jp/icnale/"
echo "   2. Register for free academic access"
echo "   3. Download 'ICNALE Written Essays' package"
echo "   4. Extract to: data/raw/icnale/"
echo ""
echo "‚è∏Ô∏è  Pausing for manual ICNALE download..."
echo "   Press Enter after completing ICNALE download, or Ctrl+C to skip"
read -p ""

# Verify downloads
echo ""
echo "üìä Verification:"
if [ -f "data/raw/ellipse/train.csv" ]; then
    echo "‚úÖ ELLIPSE: $(wc -l < data/raw/ellipse/train.csv) essays"
else
    echo "‚ùå ELLIPSE: Not found"
fi

if [ -d "data/raw/icnale" ] && [ "$(ls -A data/raw/icnale)" ]; then
    echo "‚úÖ ICNALE: Directory exists with files"
else
    echo "‚ùå ICNALE: Not downloaded yet"
fi

echo ""
echo "üéâ Download process complete!"
echo "Next steps:"
echo "   1. Run: python scripts/extract_esl_comprehensive.py"
echo "   2. Check: data/esl/ for extracted ESL data"
```

**Usage**:
```bash
chmod +x scripts/download_esl_datasets.sh
./scripts/download_esl_datasets.sh
```

### Verification After Download

```bash
# Check ELLIPSE
wc -l data/raw/ellipse/*.csv
# Expected: ~3,911 lines in train.csv, ~2,100 in test.csv

# Check ICNALE structure
find data/raw/icnale -name "*.txt" | wc -l
# Expected: ~5,600 text files

# Check total size
du -sh data/raw/ellipse data/raw/icnale
# Expected: ELLIPSE ~20-30 MB, ICNALE ~50-100 MB
```

---

## Recommended Action Plan

### Overview

**Total Time Estimate**: ~2 weeks  
**Priority Order**: ESL data ‚Üí Native data expansion ‚Üí Validation

**Quick Start**:
```bash
# 1. Download ESL data
./scripts/download_esl_datasets.sh

# 2. Extract ESL data
python scripts/extract_esl_comprehensive.py

# 3. Expand native data
python scripts/extract_detectrl_data.py --all-files

# 4. Extract remaining datasets
python scripts/extract_human_detectors.py
python scripts/extract_ghostbuster.py

# 5. Create final balanced dataset
python scripts/prepare_tinker_data.py --target-esl-ratio 0.40

# 6. Validate
python scripts/validate_dataset.py data/processed/balanced_40esl/
```

---

### üî• IMMEDIATE PRIORITY (Week 1)

#### Action 1: Download ICNALE Corpus

```bash
# Manual download required from: https://language.sakura.ne.jp/icnale/
# Target files: Essays from multiple proficiency levels
# Expected: ~5,600 ESL essays
```

**Expected Output**: `data/esl/icnale.jsonl` with ~5,600 samples

#### Action 2: Download ELLIPSE Corpus

```bash
# Download from Kaggle:
# https://www.kaggle.com/competitions/feedback-prize-english-language-learning
# Files: train.csv, test.csv
```

**Expected Output**: `data/esl/ellipse.jsonl` with ~6,000 samples

#### Action 3: Create Comprehensive Extraction Script

Create `scripts/extract_esl_comprehensive.py`:
- Extract from ICNALE
- Extract from ELLIPSE  
- Consolidate with existing TOEFL data
- Output unified ESL corpus

**Target**: 11,782 total ESL samples (182 + 5,600 + 6,000)

### üü° HIGH PRIORITY (Week 1-2)

#### Action 4: Extract All DetectRL Data

Modify `scripts/extract_detectrl_data.py`:
- Remove file restrictions (currently only 4 files)
- Process all 23 JSON files
- Extract all suitable academic/professional text

**Target**: 15,000+ native samples (currently 5,600)

#### Action 5: Process Human Detectors Dataset

Create `scripts/extract_human_detectors.py`:
- Parse human_detectors.json
- Extract human and AI versions
- Convert to required format

**Target**: ~500-1,000 additional native samples

#### Action 6: Process Ghostbuster Dataset

Investigate and extract from Ghostbuster:
- Check CSV files in results/
- Extract any human-AI pairs
- Document format for future use

**Target**: ~1,000-2,000 additional samples

### üü¢ MEDIUM PRIORITY (Week 2-3)

#### Action 7: Explore DIPPER Dataset

Deep investigation of ai-detection-paraphrases:
- Find actual data files
- Document structure
- Extract if useful for training

#### Action 8: Consider Additional ESL Sources

If still need more ESL data:
- **EFCAMDAT**: Cambridge learner corpus (requires application)
- **Lang-8**: Language learning platform data
- **TOEFL iBT public datasets**: Additional TOEFL essays

---

## Expected Outcomes After Full Curation

### Projected Dataset Size

| Category | Current | After Actions | Improvement |
|----------|---------|---------------|-------------|
| **ESL Samples** | 182 | **11,782** | **64x increase** üéâ |
| **Native Samples** | 5,903 | **~18,000** | **3x increase** |
| **Total Dataset** | 6,085 | **~30,000** | **5x increase** |
| **ESL Ratio** | 3% | **39%** | **Hits target!** ‚úÖ |

### Training Dataset Options

After full curation, you'll have:

1. **Balanced ESL Dataset** (for fairness research):
   - ~11,782 ESL samples (40%)
   - ~17,673 native samples (60%)
   - Total: **29,455 samples**
   - 80/20 split: **23,564 train, 5,891 test**

2. **Maximum Dataset** (for model performance):
   - All ~30,000 samples
   - 80/20 split: **24,000 train, 6,000 test**

3. **Small Balanced** (for quick experiments):
   - Sample down to 2,000 total
   - Maintain 40% ESL ratio
   - 1,600 train, 400 test

---

## Validation Criteria

### Data Quality Checks

For each extracted sample, verify:
- ‚úÖ `ai_text` field present and >50 words
- ‚úÖ `human_reference` field present and >50 words  
- ‚úÖ `is_esl` field correctly labeled
- ‚úÖ `domain` field appropriate (academic, professional, etc.)
- ‚úÖ `metadata` includes source information

### Dataset Balance Checks

- ‚úÖ ESL ratio between 35-45% (target 40%)
- ‚úÖ Train/test split preserves ESL ratio (¬±5%)
- ‚úÖ Multiple ESL source diversity (not just TOEFL)
- ‚úÖ Text length distribution similar across ESL/native
- ‚úÖ Domain distribution balanced

---

## Implementation Scripts Needed

### Scripts Already Created ‚úÖ

1. **`scripts/download_esl_datasets.sh`** ‚úÖ
   - Downloads ELLIPSE from Kaggle
   - Provides instructions for ICNALE
   - Verifies downloads
   - **Status**: Ready to use

2. **`scripts/extract_detectrl_data.py`** ‚úÖ
   - Extracts DetectRL data
   - Currently processes 4 files (5,600 samples)
   - **Needs modification**: Process all 23 files
   - **Status**: Working but incomplete

3. **`scripts/convert_chatgpt_bias_direct.py`** ‚úÖ
   - Extracts ChatGPT-Detector-Bias data
   - Processes TOEFL, CS224N, College essays
   - **Status**: Complete, already extracted 485 samples

### New Scripts to Create

#### 1. `scripts/extract_esl_comprehensive.py` (HIGH PRIORITY)

**Purpose**: Unified ESL extraction from all sources

**Pseudocode**:
```python
#!/usr/bin/env python3
"""
Extract ESL data from ICNALE, ELLIPSE, and TOEFL.
Output: data/esl/{icnale,ellipse,toefl11}.jsonl
"""

import json
import pandas as pd
from pathlib import Path

def extract_icnale():
    # Find all .txt files in data/raw/icnale/W_PTJ_1.2/
    # Parse filename for metadata (proficiency level, L1 background)
    # Read text content
    # Generate AI version using GPT API (or skip if paired human/AI not available)
    # For RL training, we need human text only (as reference)
    # Output to data/esl/icnale.jsonl
    pass

def extract_ellipse():
    # Read data/raw/ellipse/train.csv and test.csv
    # Column 'full_text' contains essays
    # Use proficiency scores for metadata
    # Similar to ICNALE: human text as reference
    # Output to data/esl/ellipse.jsonl
    pass

def extract_toefl():
    # Already have data/esl/toefl11.jsonl (182 samples)
    # Just verify format and copy if needed
    pass

if __name__ == "__main__":
    extract_icnale()   # Target: 5,600 samples
    extract_ellipse()  # Target: 6,000 samples
    extract_toefl()    # Already: 182 samples
    print("Total ESL samples: ~11,782")
```

**Key Challenge**: ESL corpora have human text only, not human-AI pairs. Two approaches:

**Option A**: Use human ESL text as reference only
- Pro: Authentic ESL data
- Con: No AI version to train on

**Option B**: Generate AI versions of ESL text
- Use GPT-4 to rewrite ESL essays
- Pro: Creates training pairs
- Con: AI-generated, not authentic detection evasion

**Recommended**: Use Option A. The model learns to preserve human-like characteristics during RL training. The human ESL text serves as a quality/fairness reference.

#### 2. `scripts/extract_human_detectors.py`

**Purpose**: Extract news articles from Human Detectors dataset

**Input**: `data/raw/human_detectors/human_detectors.json`

**Structure Investigation**:
```bash
python3 -c "import json; data=json.load(open('data/raw/human_detectors/human_detectors.json')); print(f'Keys: {list(data.keys())[:5]}'); print(f'Sample: {data[\"0\"]}')"
```

**Expected Format**:
```json
{
  "0": {
    "title": "News article title",
    "text": "Article content...",
    "generation_model": "human" or "gpt-3.5",
    "source": "cnn",
    "author": "John Doe"
  }
}
```

**Extraction Logic**:
```python
# Group by title or content similarity
# Find human-AI pairs for same article
# Output to data/native/human_detectors.jsonl
```

#### 3. `scripts/extract_ghostbuster.py`

**Purpose**: Extract from Ghostbuster benchmark CSV files

**Input**: `data/raw/ghostbuster/results/*.csv`

**Investigation Needed**:
```bash
# Check CSV structure
head -20 data/raw/ghostbuster/results/ghostbuster.csv

# Check what columns exist
python3 -c "import pandas as pd; df=pd.read_csv('data/raw/ghostbuster/results/ghostbuster.csv'); print(df.columns.tolist()); print(df.head())"
```

**Expected**: CSV with human/AI text pairs and detector scores

#### 4. `scripts/validate_dataset.py`

**Purpose**: Comprehensive dataset validation

**Checks**:
```python
def validate_format(jsonl_file):
    # Check all required fields present
    # Verify data types
    # Check text length >50 words
    pass

def validate_balance(train_file, test_file):
    # Check ESL ratio (target: 40% ¬±5%)
    # Check train/test split preserves ratio
    # Check domain distribution
    pass

def validate_quality(jsonl_file):
    # Check for duplicates
    # Verify text completeness
    # Check language (English only)
    # Measure text length distribution
    pass

def generate_report():
    # Create markdown report with:
    # - Sample counts
    # - ESL ratio
    # - Domain distribution
    # - Quality metrics
    # - Example entries
    pass
```

### Scripts to Modify

#### 1. `scripts/extract_detectrl_data.py` (NEEDS UPDATE)

**Current State**: Processes only 4 files
- `data/raw/DetectRL/generations/arxiv/abstract/chatgpt_paraphrase.json`
- `data/raw/DetectRL/generations/arxiv/abstract/llm.json`
- `data/raw/DetectRL/generations/writing_prompts/story/chatgpt_paraphrase.json`
- `data/raw/DetectRL/generations/writing_prompts/story/llm.json`

**Required Changes**:
```python
# Remove hardcoded file list
# Find ALL .json files in data/raw/DetectRL/generations/
# Process all domains: arxiv, writing_prompts, xsum, yelp_review, etc.
# Process all data types: abstract, article, story, review, etc.
# Add progress tracking
# Target: Extract 15,000+ samples instead of 5,600
```

**Specific Code Change**:
```python
# OLD (line ~250):
files_to_process = [
    "data/raw/DetectRL/generations/arxiv/abstract/chatgpt_paraphrase.json",
    "data/raw/DetectRL/generations/arxiv/abstract/llm.json",
    "data/raw/DetectRL/generations/writing_prompts/story/chatgpt_paraphrase.json",
    "data/raw/DetectRL/generations/writing_prompts/story/llm.json",
]

# NEW:
from pathlib import Path
files_to_process = list(Path("data/raw/DetectRL/generations").rglob("*.json"))
print(f"Found {len(files_to_process)} JSON files to process")
```

#### 2. `scripts/prepare_tinker_data.py` (NEEDS UPDATE)

**Current State**: Creates fixed train/test split

**Required Changes**:
```python
# Add argument: --target-esl-ratio 0.40
# Add argument: --max-samples 30000
# Balance ESL/native to target ratio
# Add progress tracking
# Better memory efficiency for large datasets
# Add dataset statistics report
```

### Script Execution Order

```bash
# Phase 1: Download ESL data (manual + automated)
./scripts/download_esl_datasets.sh

# Phase 2: Extract ESL data
python scripts/extract_esl_comprehensive.py
# Output: data/esl/icnale.jsonl, data/esl/ellipse.jsonl

# Phase 3: Expand native data extraction
python scripts/extract_detectrl_data.py  # Modified version
# Output: Updated data/native/detectrl_native_large.jsonl (15,000+ samples)

python scripts/extract_human_detectors.py
# Output: data/native/human_detectors.jsonl (500-1,000 samples)

python scripts/extract_ghostbuster.py
# Output: data/native/ghostbuster.jsonl (1,000-2,000 samples)

# Phase 4: Create balanced datasets
python scripts/prepare_tinker_data.py --target-esl-ratio 0.40 --max-samples 30000
# Output: data/processed/balanced_40esl/{train,test}.jsonl

# Phase 5: Validate
python scripts/validate_dataset.py data/processed/balanced_40esl/
# Output: DATASET_VALIDATION_REPORT.md
```

---

## Timeline Estimate

| Phase | Duration | Deliverables |
|-------|----------|--------------|
| **Download ESL data** | 2-3 days | ICNALE + ELLIPSE downloaded |
| **Extract ESL data** | 2-3 days | 11,782 ESL samples ready |
| **Extract remaining datasets** | 3-4 days | All datasets processed |
| **Validation & cleanup** | 1-2 days | Quality checks passed |
| **Prepare training splits** | 1 day | Final datasets ready |
| **TOTAL** | **~2 weeks** | **30,000 sample dataset** |

---

## Success Metrics

**Must Achieve**:
- ‚úÖ ESL samples: >10,000 (target: 11,782)
- ‚úÖ Total samples: >25,000 (target: 30,000)
- ‚úÖ ESL ratio: 35-45% (target: 40%)
- ‚úÖ Multiple ESL sources: ‚â•3 (TOEFL, ICNALE, ELLIPSE)

**Stretch Goals**:
- üåü ESL samples: >15,000
- üåü Total samples: >40,000
- üåü Additional languages: Non-English ESL data

---

## Conclusion

**Current Assessment**: üî¥ **DATA CURATION INCOMPLETE**

**Key Issues**:
1. Critical ESL data shortage (182 vs. 11,000+ needed)
2. Massive underutilization of downloaded data
3. Wrong prioritization (detection benchmarks over ESL corpora)

**Required Actions**:
1. **URGENT**: Download ICNALE and ELLIPSE
2. **HIGH**: Extract all DetectRL data
3. **HIGH**: Process Human Detectors and Ghostbuster
4. **MEDIUM**: Investigate DIPPER dataset

**Expected Outcome**: 
- 30,000 total samples (5x current)
- 11,782 ESL samples (64x current)
- 39% ESL ratio (hits 40% target!)
- Publication-ready dataset for fairness research

**Without These Improvements**: 
- ‚ùå Cannot meet research objectives
- ‚ùå ESL fairness evaluation invalid (only 182 samples)
- ‚ùå Results not publishable
- ‚ùå Wasted 2.87 GB of downloaded data

---

## Next Steps

### For the Data Curator

**Start Here**:

1. **Understand the requirements** (30 mins)
   - Read [Project Context](#project-context)
   - Review [Data Format Requirements](#data-format-requirements)
   - Check [Success Metrics](#success-metrics)

2. **Download ESL datasets** (2-3 days)
   ```bash
   ./scripts/download_esl_datasets.sh
   ```
   - Set up Kaggle API for ELLIPSE
   - Register and download ICNALE manually
   - Verify downloads (see verification commands in doc)

3. **Create extraction scripts** (2-3 days)
   - `scripts/extract_esl_comprehensive.py` (see pseudocode above)
   - `scripts/extract_human_detectors.py`
   - `scripts/extract_ghostbuster.py`
   - Test each script on small sample first

4. **Modify existing scripts** (1 day)
   - Update `scripts/extract_detectrl_data.py` to process all files
   - Update `scripts/prepare_tinker_data.py` for balancing

5. **Extract all data** (1 day)
   - Run all extraction scripts
   - Monitor progress and fix errors
   - Check output format matches requirements

6. **Create balanced dataset** (1 day)
   ```bash
   python scripts/prepare_tinker_data.py --target-esl-ratio 0.40
   ```

7. **Validate and document** (1 day)
   - Run validation checks
   - Create validation report
   - Update knowledge_base/DATA_CURATION_ANALYSIS.md with results

### Deliverables Checklist

**Code**:
- [ ] `scripts/extract_esl_comprehensive.py` created and tested
- [ ] `scripts/extract_human_detectors.py` created and tested
- [ ] `scripts/extract_ghostbuster.py` created and tested
- [ ] `scripts/validate_dataset.py` created and tested
- [ ] `scripts/extract_detectrl_data.py` updated to process all files
- [ ] `scripts/prepare_tinker_data.py` updated for balancing

**Data**:
- [ ] `data/esl/icnale.jsonl` (target: 5,600 samples)
- [ ] `data/esl/ellipse.jsonl` (target: 6,000 samples)
- [ ] `data/native/detectrl_native_large.jsonl` (target: 15,000+ samples)
- [ ] `data/native/human_detectors.jsonl` (target: 500-1,000 samples)
- [ ] `data/native/ghostbuster.jsonl` (target: 1,000-2,000 samples)
- [ ] `data/processed/balanced_40esl/train.jsonl` (target: 23,564 samples)
- [ ] `data/processed/balanced_40esl/test.jsonl` (target: 5,891 samples)

**Documentation**:
- [ ] DATASET_VALIDATION_REPORT.md created
- [ ] knowledge_base/DATA_CURATION_ANALYSIS.md updated with final results
- [ ] README.md in data/ directory explaining structure

**Success Criteria**:
- [ ] Total ESL samples: >10,000
- [ ] Total dataset size: >25,000
- [ ] ESL ratio: 35-45% (target: 40%)
- [ ] All samples pass format validation
- [ ] No duplicates
- [ ] Train/test split preserves ESL ratio

### Getting Help

**Common Issues**:

1. **"Kaggle API not working"**
   ```bash
   pip install --upgrade kaggle
   chmod 600 ~/.kaggle/kaggle.json
   ```

2. **"ICNALE download unclear"**
   - Visit: https://language.sakura.ne.jp/icnale/
   - Look for "Download" tab
   - Request "ICNALE Written" component
   - Check spam folder for registration email

3. **"Don't know how to generate AI versions of ESL text"**
   - Use Option A: Human text as reference only (recommended)
   - The RL training process will learn from human references
   - No need to generate AI versions manually

4. **"DetectRL extraction too slow"**
   - Process files in parallel
   - Add progress bar (tqdm)
   - Cache processed files

5. **"Dataset too large for memory"**
   - Process in batches
   - Use generators instead of loading all data
   - Stream write to JSONL files

**Contact**:
- For technical questions: Check existing scripts in `scripts/` directory
- For format questions: See [Data Format Requirements](#data-format-requirements)
- For priority questions: ESL data is always highest priority

### Critical Reminders

‚ö†Ô∏è **DO NOT**:
- Skip ESL data downloads (blocks entire project)
- Mix train/test data (causes overfitting)
- Forget to validate format (causes training failures)
- Ignore duplicate detection (inflates metrics)

‚úÖ **DO**:
- Prioritize ESL data above everything else
- Validate format after each extraction
- Check ESL ratio frequently
- Document any data quality issues found
- Keep backups of intermediate files

---

This is critical infrastructure for the research project. **Without proper ESL data (40% ratio), the fairness component cannot be evaluated and results are not publishable.**

**Questions?** Review this document thoroughly - it contains all context needed for data curation.
