{"id": "cs224n_0000", "text": "Title: Effect of Character- and Subword-Embeddings on BiDAF Performance\nAbstract: Systems trained end-to-end have achieved promising results in question answering the past couple of years. Many of the deep-learning based question answering systems are trained and evaluated on the Stanford Question Answering Dataset (SQuAD), where the answer to every question is either unanswerable or a segment of text from the corresponding reading passage [4]. In this work, we investigate the effectiveness of different embeddings in improving the performance of the baseline Bi-Directional Attention Flow model on solving SQuAD 2.0. The first model improves upon the baseline with character-level embeddings; the second model improves with subword-level embeddings; the third improves with both character-level and subword-level embeddings. Our best model, which incorporates word-level and subword-level embeddings, achieves an EM score of 57.70 and F1 score of 61.26 on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0001", "text": "Title: Building a QA system (IID SQuAD track)\nAbstract: Question Answering is a interesting machine learning task which shows how machine can understand the relationship and the meaning of the words. There are lots of existing models built to solve this task. This paper draws inspiration from the paper Bidirectional Attention Flow for Machine Comprehension and dive deeper into the effect of character level embedding on the performance of the model. Through experimenting on different CNN model for character level embedding, we have concluded that a more complex CNN model does not result in a better performance metrics. However, through manually evaluate the model's prediction, we have found that a more complex model does perform better in certain cases.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0002", "text": "Title: Improving QA System Out of Domain Performance Using Data Augmentation\nAbstract: In recent years question and answering (QA) systems have become widely used in many modern technology applications, such as search engine querying and virtual assistants. However, despite recent advances in QA modeling, these systems still struggle to generalize to a specific domain without specialized training data and information about that domain's distribution. For this reason, we investigated the effectiveness of different data augmentation and sampling techniques to improve the robustness of the pre-trained DistilBERT QA system on out of domain data. We trained the DistilBERT model on the in domain data and then experimented with fine-tuning using augmented versions of the out of domain data. To generate the additional data-points we performed random word deletion, synonym replacement, and random swapping. We found that all the fine-tuned models performed better than the baseline model. Additionally, we found that our optimal synonym replacement model performed the best on the out of domain test set, and that the combination model of synonym replacement and deletion also led to increased performance over the baseline. Overall, we conclude that data augmentation does increase the ability of our question answering system to generalize to out of domain data and suggest that future work could look further into applying combinations of these data augmentation techniques.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0003", "text": "Title: RobustQA\nAbstract: In recent years, question-answering (QA) models have vastly improved and achieved superhuman standards in several benchmarks. Yet, these same superhuman models often do not perform well on out-of-distribution (OOD) datasets or tasks. In contrast, humans appear to easily and quickly generalize to new unseen domains. In this project, we aim to train a QA model that is able to perform well across different datasets, especially on OOD datasets. Specifically, we experiment with the use of adversarial training applied to a pretrained DistiIBERT model. The adversarial training takes the form of a critic model that tries to classify the origin domain of the QA embedding. In addition to the regular QA loss, the QA model has the additional objective of fooling the critic model. This encourages the QA model to learn a domain-agnostic embedding, which we hope to help with generalization and robustness to OOD datasets.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0004", "text": "Title: Building a QA system (IID SQuAD track)\nAbstract: In this project, we are dealing with building a Question Answering System that is expected to perform well on SQuAD. Our approaches to this task include the retraining of baseline model, improvement on embedding (BiDAF), modification of attention (Dynamic Coattention Model), replacement of LSTM with GRU and application of transformer (QANet). After experiments with different models and modifications, both BiDAF and QANet outperform the baseline model, with QANet being our best model. It takes some advantages of various features in other modifications mentioned before, and it consists of four layers: (1) Embedding layer where the combination of character-level and word-level embedding uses the pre-trained word embedding model to map the input into vector space. (2) Contextual embedding layer where the encoder block utilized contextual cues from surrounding words to refine the embedding of the words. (3) Attention flow layer where the coattention-like implementation produces a set of query-aware feature vectors for each word in the context. (4) Modeling and output layer where a stack of encoder blocks with fully-connected layers are sued to scan the context and provide an answer to the query. By submitting our best model to the test leaderboard, we have obtained satisfying results with F1 of 66.43 and EM of 62.45.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0005", "text": "Title: Fine Grained Gating on SQUAD\nAbstract: The purpose of this project is to implement an embedding mechanism on top of the BiDaf model that serves as a compromise between word-level embeddings and character-based embeddings that can compete with a simple concatenation of word and character level embeddings. In particular, the mechanism is what is called a fine-grained gating method, in which, given a character level embedding $c$ and a word-level embedding $w$, a parameter $g$ is learned such that final embedding of a given word is $g \\odot c + (1-g) \\odot w$, where $\\odot$ represents termwise multiplication. After various experiments varying the methods by which the parameter $g$ is learned, results ultimately show that none of the fine-tuned gating methods perform better than mere concatenation of the word and character embeddings.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0006", "text": "Title: Domain Adversarial Training for QA Systems\nAbstract: In our CS224N project, we examine a QA model trained on SQuAD, NewsQA, and Natural Questions and augment it to improve its ability to generalize to data from other domains. We apply a method known as domain adversarial training (as seen in a research paper we reviewed by Seanie Lee and associates) which involves an adversarial neural network attempting to detect domain-specific model behavior and discouraging this to produce a more general model. We explore the efficacy of this technique as well as the scope of what can be considered a \"domain\" and how the choice of domains affects the performance of the trained model. We find that, in our setting, using a clustering algorithm to sort training data into categories yields a performance benefit for out-of-domain data. We compare the partitioning method used by Lee et al. and our own unsupervised clustering method of partitioning and demonstrate a substantial improvement.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0007", "text": "Title: Robust Question Answering with Task Adaptive Pretraining and Data Augmentation\nAbstract: Existing research suggests that task adaptive pretraining (TAPT) with data augmentation can enhance classification accuracy on a wide array of natural language processing (NLP) tasks. This project aims to evaluate whether TAPT improves performance on a robust question answering (QA) system. The baseline model, which finetunes DistilBERT on SQuAD, NewsQA, and Natural Questions datasets, achieves an EM score of 33.25 and F1 score of 48.43 when validated on the out-of-sample DuoRC, RACE, and RelationExtraction datasets. Applying TAPT to the out-of-domain unlabeled training datasets using masked language modeling (MLM) without data augmentation, we do not observe an increase in either metric of performance. However, not using TAPT, our model performance is enhanced when we use backtranslations to augment only a small portion of the training data for finetuning, achieving an EM of 36.91 and F1 score of 50.16 on the out of domain validation set. This model also achieves an EM of 41.628 and F1 of 58.91 on the out of domain test set. These results thus suggest that data augmentation alone, even to a highly limited extent, may account for the improvements in model performance.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0008", "text": "Title: Task-Adaptive Pretraining, Domain Sampling, and Data Augmentation Improve Generalized Question Answering\nAbstract: To create a deep-learning question answering (QA) system that generalizes to unseen domains, we investigate the use of three techniques: task-adaptive pretraining (TAPT), domain sampling, and data augmentation. We train a single DistilBERT model in three phases (shown in the flowchart). First, during TAPT, we pretrain with masked-language modeling (MLM) on our QA datasets. Second, we fine-tune on our QA data. We employ domain sampling during both pretraining and fine-tuning, which preferably samples data that lead to better downstream performance. Finally, for our data augmentations, we use synonym replacement and random deletion to increase the size and variety of our out-domain data, before additionally fine-tuning on these augmented data. During evaluation, we found significant EM/F1 performance improvements by fine-tuning on augmented out-domain data. We found modest, yet non-trivial, performance improvements with TAPT and domain sampling. Using these three techniques, our model achieved EM/F1 scores of 37.44/51.37 on the development set and 40.12/58.05 on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0009", "text": "Title: Robust Question Answering using Domain Adversarial Training\nAbstract: While recent developments in deep learning and natural language understanding have produced models that perform very well on question answering tasks, they often learn superficial correlations specific to their training data and fail to generalize to unseen domains. We aim to create a more robust, generalized model by forcing it to create domain-invariant representations of the input using an adversarial discriminator system that attempts to classify the outputs of the QA model by domain. Our results show improvements over the baseline on average, although the model exhibited worse performance on certain datasets. We hypothesize that this is caused by differences in the kind of reasoning required for those datasets, differences which actually end up being erased by the discriminator.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0010", "text": "Title: Question Answering with Self-Attention\nAbstract: Question Answering (QA) is an increasingly important topic in NLP with the proliferation of chatbots and virtual assistants.  In this project a QA system is built by exploring two end-to-end models: Firstly, the baseline BiDAF model was improved by adding a character embedding layer with multiple convolutional layers, an extra embeddings attention layer which captures the \"summary\" of the embedding vectors, a context-to-context self-attention layer, gated recurrent units (GRU) and Swish activation. Secondly, the QANet model was re-implemented from scratch and successfully explored some hyperparameter finetunings to improve performance.\nThe improved BiDAF model (SA-BiDAF++) incorporating self-attention, achieved 65.3 EM / 68.8 F1 scores on the test set of the SQuAD 2.0. That is a clear indication that architecture fine-tunings and optimizations can improve significantly the performance of non-PCE models.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0011", "text": "Title: An Unsupervised Pretraining Task for the BiDAF Model\nAbstract: Over the past few years and particularly since \"Attention is All You Need\" was published, the NLP community has moved away from LSTM-based architectures because of the benefits seen by attention-only networks with extensive unsupervised pre-training. This project demonstrated that EM, F1 and AvNA scores can be improved on a BiDAF model simply by pretraining on a similar task to that used in the original BERT paper. While the BERT paper used a Masked Language Model (MLM) and Next Sentence Predictions (NSP), this paper utilizes a novel variant of MLM, termed Obscured Replacement Language Model (ORLM), to enable the strict input-output mappings of a BiDAF model to learn from an unsupervised task. Specifically, this paper shows that performance gains over the baseline BiDAF model can be achieved using ORLM, as judged by the EM and F1 scores. Furthermore, pretraining the BiDAF model with this method decreases the amount of training required on the SQuAD 2.0 training dataset to achieve similar performances, while boosting task-specific metrics such as the AvNA score. As the community concretely moves away from LSTM-based architectures, there is room to ask whether the true top-end performance of those architectures was explored, even if they continue to fall short of state-of-the-art.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0012", "text": "Title: Building a Robust QA system using an Adversarially Trained Ensemble\nAbstract: Despite monumental progress in natural language understanding, QA systems trained on giant datasets are still vulnerable to domain transfer. Evidence shows that language models pick up on domain-specific features which hinders it from generalizing to other domains. In this project, we implore the use of adversarial networks to regularize the fine-tuning process which encourages the generator model to learn more meaningful representations of context and questions. We then construct an ensemble of these models based on each model's performance on specific subgroups of questions.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0013", "text": "Title: QANet for SQuAD 2.0\nAbstract: QANet model was one of the state-of-the-art models for SQuAD 1.1. Does its top-notch performance transfer to the more challenging SQuAD 2.0 dataset containing unanswerable questions? How does the model size affect performance? Is the bi-directional attention layer really necessary in a transformer-style architecture? These are the questions, I tried to answer in this project. Compared to the three baselines derived from the BiDAF model, QANet achieved substantially higher F1 and EM scores of 67.54 and 63.99 respectively. However, these scores are significantly lower than those of the current state-of-the-art models, mainly because the model couldn't correctly handle unanswerable questions. Next, experiments with model size showed no performance degradation with smaller-sized QANet variants. In fact, these variants slightly outperformed the base QANet. Lastly, a new model built entirely using QANet's building blocks (without an explicit bi-directional attention layer) outperformed all of the baseline models even without finetuning. Its performance is still below the base QANet model most likely because the model started overfitting roughly midway through training. I believe adding more regularization and further finetuning would bring its performance close to that of the base QANet model.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0014", "text": "Title: Extending QANet with Transformer-XL\nAbstract: This project tackles the machine reading comprehension (RC) problemon the SQuAD 2.0 dataset.  It involves inputting a context paragraph and aquestion into a model and outputting the span of the answer from the contextparagraph.  This project aims to extend the QANet, so that it can effectivelyperform RC on SQuAD 2.0. The segment-level recurrence with state reuse fromTransformer-XL is integrated into QANet to improve its ability of tacklinglong context paragraph (referred to as QANet-XL). In addition,  character embeddings and a fusion layer after context-query attention are used to extend BiDAF. Experiments show that QANet-XL underperforms the vanillaQANet and outperforms the extended BiDAF. The segment-level recurrence mech-anism from Transformer-XL is proven not a proper improvement for QANet on theSQuAD 2.0 dataset, since segmenting context paragraph is somewhat harmful. For the dev set, The extended BiDAF achieved EM/F1 = 62.16/65.98, the vanilla QANet achieved EM/F1=66.81/70.38, and the QANet-XL achieved EM/F1 = 63.12/66.67. A majority voting ensemble model based on previous mentioned models achieved EM/F1=66.85/69.97 on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0015", "text": "Title: An Analysis on the Effect of Domain Representations in Question Answering Models\nAbstract: Studies of robust reading comprehension models have included both learning domain specific representations and domain invariant representations. This project analyzes the effectiveness of each of these approaches using Mixture-of-Experts (MoE) and adversarial models. In the domain specific approach, MoE's form a single expert model for each input domain (Guo et al., 2018, Takahashi et al., 2019). In contrast, domain invariant models learn a generalized hidden representation that cannot distinguish the domain of the input (Ma et al., 2019, Lee et al., 2019). Additionally, models are assessed to determine their level of understanding of natural language against learning simple linguistic bias heuristics.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0016", "text": "Title: Improving QA Robustness through Modified Adversarial Training\nAbstract: We improved the domain generalizability of a DistilBert Question Answering (QA) model by implementing adversarial training. By putting a conventional QA model in competition with a discriminator, we were able to generate domain invariant features that improved the QA model's robustness. We augmented this strategy by retraining our model on all of our available datasets to gain the best performance. Our model performed better than the baseline with unseen out of domain datasets.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0017", "text": "Title: Reformed QANet - Optimizing the Spatial Complexity of QANet\nAbstract: The feed-forward QANet architecture replaced the bidirectional LSTMs of traditional question and answering models by using encoder components with convolution + self-attention to increase the speed of the model without sacrificing accuracy. We achieved scores of 64.5 EM/67.9 F1 on the dev set and 61.64 EM/65.30 F1 on the test set. While the parallel nature of QANet's CNN architecture allows for a significant speed boost, it means that minimizing GPU memory usage is crucial to attain these benefits. In this report we perform an exhaustive study investigating changes to spatial complexity, speed, and performance on the QANet architecture by replacing components in the encoder block with memory-efficient alternatives such as LSH Self Attention, reversible residual networks, and reformer blocks. The image above depicts the QANet encoder block where the self-attention and feed-forward layer are replaced with a reformer, a stack of reversible LSH Self Attention and feed-forward layers. We found that implementing LSH attention successfully decreased memory usage on long sequences while maintaining reasonable performance. While the other modifications did not quite maintain the original QANet model's EM and F1 scores, they significantly decreased GPU memory usage. Additionally, we used data augmentation to enrich training data through back translation and found slight improvements on our larger model.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0018", "text": "Title: DistiIBERT Augmented with Mixture of Local and Global Experts\nAbstract: Few-shot systems are valuable because they enable precise predictions using small amounts of expensive training data, making them particularly cost-efficient. In this paper, we explore a technique to improve the few-shot question answering capabilities of a pre-trained language model. We adjust a pre-trained DistilBERT model such that it leverages datasets with large amounts of training data to achieve higher question-answering performance on datasets with very small amounts of available training data using a novel inner- and outer-layer Mixture of Experts (MoE) approach.\n\nPractically, we first connect pre-trained DistilBERT models and an MoE layer in sequence (inner-layer) and train them on all high-availability data and on a single dataset with low data availability. Then we use several of these DistilBERT-MoE models in parallel to predict observations from multiple datasets with low data availability (outer-layer). We find that the noise reduction achieved by training designated DistilBERT-MoE models for different datasets with low data availability yields greater prediction benefits than the (possibly) increased transfer learning effects achieved by training a single DistilBERT-MoE model on all high- and low-availability datasets together. Both our inner-outer-MoE method and a single DistilBERT-MoE model outperform the baseline provided by a finetuned DistilBERT model, suggesting that the mixture of experts approach is a fruitful venue to enabling robust predictions in contexts with few training examples.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0019", "text": "Title: Domain-agnostic DistiIBERT for robust QA\nAbstract: In this project, we worked on improving the robustness of DistilBERT to out-of-distribution data in a question answering task by employing multi-phase continued pre-training and data augmentation. The in-domain datasets included SQuAD, NewsQA, and Natural Questions, while the out-of-domain datasets included DuoRC, RACE, and RelationExtraction.\nFor multi-phase pre-training, we first analyzed the domain similarity between the in-domain and out-of-domain datasets and found NewsQA to be the most similar dataset to the downstream task of question answering based on examples from DuoRC, RACE, and RelationExtraction datasets. We then first trained the model on in-domain datasets and called it the second-phase continued pre-training. After using NewsQA for third-phase continued pre-training, we used data augmented with synonym and antonym replacement to perform the fourth-phase pre-training. The best model achieved performance, as evaluated by EM/F1 score, of 35.60/51.23 on validation datasets and 40.39/59.42 on test datasets in comparison to the baseline of 29.06/46.14 on validation datasets.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0020", "text": "Title: DAM-Net: Robust QA System with Data Augmentation and Multitask Learning\nAbstract: If the machine can comprehend a passage and answer questions based on the context, how to upgrade a QA system to generalize to unseen domains outside the training data? In this project, we propose DAM-Net, a robust QA model that can achieve strong performance even on test examples drawn beyond their training distributions. Specifically, we perform data augmentation on our training data, expand training with the auxiliary task (i.e. fill-in-the-blank), and utilize multi-domain training with additional fine-tuning. DAM-Net has shown strong performance on the robust QA benchmark and sometimes it even outperforms humans in terms of the comprehensiveness and accuracy of the answers!", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0021", "text": "Title: Building a QA system (IID SQuAD track)\nAbstract: The goal of the project is to build a question answering system that works well on SQUAD dataset. The system should be able to read a paragraph and answer a question correctly related to the paragraph. This is an interesting task because it measures how well the system can interpret text. Reading Comprehension is an important field and being able to develop systems that can interpret text at human level will be able to lead us to the next revolution in Artificial Intelligence.  The input to the system is a paragraph and a question related to the paragraph and the output from the system is the answer to the question based on the text in the paragraph. We have developed a system implementing character-level embedding using 1D Convolutions on top of the provided baseline code to mimic the BiDAF (Bidirectional Attention Flow) model. By adding the character-level embedding to the baseline starter code has given a lot of improvement to the EM and F1 scores. After running a lot of experiments, we found the best performing model to the one using an Adam optimizer with one char CNN embedding layer with Batch Normalization, learning rate of 0.0003 and dropout of 0.13. The scores received in the test leader-board are as follows: F1 - 66.174 and EM - 63.077.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0022", "text": "Title: Examining the Effectiveness of a Mixture of Experts Model with Static Fine-tuned Experts on QA Robustness\nAbstract: While much progress has been made in recent years on modeling and solving natural language understanding problems, these models still struggle to understand certain aspects of human language. One of the most difficult areas for current models is generalization. While humans can easily generalize beyond a training data set, computers often have difficulty developing non-superficial correlations beyond the provided data. In this project, we tackled this concept of computer generalization through the development of a robust question answering (QA) system that is able to generalize answers to questions from out-of-domain (OOD) input. Here, we applied a modified Mixture of Experts (MoE) model, where gating and expert training are handled seperately, over the 6 datasets in order to create robustness through specialization of the various expert models. We also applied few-sample fine-tuning to large and small components of the model to try to better account and generalize for cases where there is little data. Ultimately, from the results of the model, we observed that this modified MoE architecture has several limitations through its expert and training method and was unable to improve significantly on the baseline of the model. In addition, we also observed that the few-sample fine-tuning techniques greatly improved the performance of the small, out-of-domain expert but barely improved, and sometimes harmed, models with a larger dataset. As a whole, this paper illustrates the potential limitations of applying a simple MoE model and few-sample fine-tuning to the complex task of generalization and may suggest the implementation of more advanced structures and techniques are necessary for strong performance.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0023", "text": "Title: BiDAF Question Ansering with Character Embedding, Self-Attention, and Weighted Loss\nAbstract: Machine question answering remains a central problem in natural language processing. In this work, we build upon the default bidirectional attention flow model and explore the effect of adding character embeddings, self-attention, and a weighted loss function compared with the baseline. While character embeddings and self-attention have been demonstrated to improve the performance of language models, the motivation for a weighted loss function comes from the nature of the SQuAD dataset itself. We note that about half of the samples of the SQUAD dataset have no-answer, and is thus denoted by a start and end-pointer value of zero. Because the problem is effectively being treated as a classification problem (where the pointer locations are the classes to be predicted), this results in a ground truth distribution that is heavily skewed toward start and end-pointer class 0. To address this imbalance, we also propose the use of a weighted loss function, which down-weights no-answer examples, discouraging the model from simply guessing no-answer as a default choice. With a combined model, we achieve 62.11 EM and 65.54 F1 on the test set. We discover that a great deal of the error of the model comes from false-positives, and over-reliance on token matching.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0024", "text": "Title: Invertigation of BiDAF and implementation of QANet for Question Answering\nAbstract: In this project, I build two question answering system that have relatively good performance on SQuAD 2.0 dataset.\nThe baseline model is Bi-Directional Attention Flow (BiDAF), which achieved 59.21 F1, 55.92 EM and 65.85 AvNA on Dev dataset.\nFirstly I implement a CNN-based character embedding to it which achieved 60.192 EM, 63.480 F1 on Dev dataset.\nThen I re-implement QANet with Pytorch which is basically the same as the original paper proposed one.\nIt achieved 59.973 EM, 63.403 F1 on Dev dataset, which is less than the first one.\nUltimately, I got 59.307 EM and 62.761 F1 on test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0025", "text": "Title: Gaining More from Less Data in out-of-domain Question Answering Models\nAbstract: We propose text augmentation techniques for Question Answering task in NLP that involves using synonyms with stochasticity on out-of-domain datasets (DuoRC and RACE and RelationExtraction) that are set to be 400 times smaller than the in-domain datasets (SQuAD, NewsQA, NaturalQuestions). We illustrate QSR, SIBA, SIAA, CCS and CD augmentation strategies above, that help improve extraction of generalized information from out-of-domain or less available datasets from large pre-trained models BERT variant DistilBERT being able to benefit from producing QA applications across domains. It is found that augmenting less available QA datasets in a way described, indicate improvement in generalization, but not all augmentations strategies are equally good, a combination of 3x QSR, 3x SIBA, 3x SIAA, 3x CCS performed the best (as illustrated above) with exclusion of CD (this negatively impacted scores). We also define a metric EM+ (exact match plus) that is a binary measure if prediction is a superset of the answer, EM+ = 1, else 0; provides a less overfit-perspective as a performance metric than EM. We conjecture from analysis done in the paper that increasing unique words in OOD that aren't present in ID, help improve with performance.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0026", "text": "Title: BiDAF with Dependency Parse Tree for Question Answering in SQUAD 2\nAbstract: One of the key areas of interest in Natural Language Processing is building systems capable of answering questions in our native language. The task is called Question Answering (QA) and is the focus of this paper where we explore our idea to enhance an existing solution called BiDAF (Seo et al, 2016). Our intuition is that language understanding involves at least two broad capabilities. First one has to understand what words individually mean. And second, based on the structure of the sentences one has to make sense of the complete sentence. Individual word are usually represented by word embeddings in most solutions. But the second piece is where different approaches diverge greatly. To address this part, we were interested  to see, if syntactic information  can help. Specifically, we explored the idea of using dependency parse trees (DPT) to enrich the embedding of individual words. DPT provides a representation of syntactic relationships between words in a sentence. We defined the relationship between words as the path between them in the dependency tree. We hypothesized that even though grammatical structure doesn't enable a system to do a lot of things such as reasoning, the best a model could do with a limited dataset is to learn the patterns between syntax of questions with that of the answer phrases. This inspired us to augment the input word embeddings to the model with dependency parse tree based information. Our model  not only scored significantly higher (+7% on F1 & EM) compared to the baseline, it also learned almost twice as fast even with the extra preprocessing time. DPTs are produced by deep learning model, so end to end there is in no manual feature engineering. We find this idea particularly interesting  as it could be potentially added to other QA models with minimal adaptation.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0027", "text": "Title: Exploring First Order Gradient Approximation Meta Learning for Robust QA Systems\nAbstract: Reptile is a meta learning approach that searches for initial model parameters to allow a model to be fine tuned with a small dataset. However when fine tuning a language model on a small set of tasks and low learning rate, Reptile may still over-fit on training batches. RandEPTILE adds additional noise to initial model parameters to efficiently search for areas of lower validation loss in the parameter domain. This project explored the effects of RandEPTILE with a distilBERT pre-trained model for question answering using small fine-tuning datasets. While the improvement on final test accuracy was inconclusive, adding additional noise to model parameters could be worth exploring in future meta learning techniques.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0028", "text": "Title: Self-Attention in Question Answering\nAbstract: For the default final project, our task was to build a model that performs question answering over the Stanford Question Answering Dataset (SQuAD). Our goal was to improve on the baseline BiDAF model's F1 and EM scores on the task. To do so, we made two additions to the model: character embeddings and a self-attention layer, both which were used in R-Net. We found that while these additions improved the F1 and EM scores, it also required significantly more memory and training time.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0029", "text": "Title: Faster Attention for Question Answering\nAbstract: In this project (a default final project on the IID track), I built a question-answering system for SQuAD 2.0 by exploring both the BiDAF model through modifications of the default baseline as well as a from scratch implementation of QANet, a self-attention-based question-answering architecture. The BiDAF modifications which added character embeddings achieved a small, but significant improvement over the baseline model on the test set. However, the QANet models only nearly matched the baseline BiDAF scoring with character embeddings. Curiously, not only did my QANet under-perform the baseline in model performance, it also turned out to be significantly slower to train and at inference time on GPUs. Though profiling, I found that the QANet model is indeed faster on CPUs, however significantly under-performs the baseline BiDAF model on GPUs because the BiDAF model's slowest component, the RNN, is implemented as a highly optimized CuDNN routine on GPUs that the custom QANet encoder block did not benefit from. Finally, this profiling also shows that faster attention mechanisms, as explored in the literature, are unlikely to improve performance on this particular SQuAD 2.0 workload as additional instruction overhead would likely wash out any performance gains absent better operation compilation for GPUs or a custom GPU kernel.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0030", "text": "Title: Efficiency of Dynamic Coattention with Character Level Embeddings\nAbstract: Question answering has long been a difficult task for computers to perform well at, as it requires a deep understanding of language and nuance. However, recent developments in neural networks have yielded significant strides in how well computers are able to answer abstract questions; concepts like dynamic coattention and character level embeddings have helped machines with abstract tasks like reading comprehension. Despite these strides, training models utilizing these techniques remains cumbersome and exceedingly time consuming.\n\nWe explored a handful of different approaches on improving the SQuAD evaluation score within the context of coattention models. Immediately, we noticed character-level embeddings increase evaluation metrics by a few points and decided to explore coattention models with character-level embeddings. The performance of our coattention models without a dynamic decoder performed significantly worse than the baseline. We noted how removing the modeling layer reduced the training time in half while achieving a similar performance.\n\nWe hypothesized that the coattention model did not perform as well because the character-level embeddings introduced unnecessary and irrelevant similarities between the question and context embedding. Furthermore, we noted that there were some variance in the training runs especially in the F1 score. Some potential avenues for future work can explore  removing character-level embeddings, reintroducing a dyamic decoder and observing the performance between a coattention model with and without a modeling layer to see if there are still improvements in training time. Furthermore, it would also be interesting to further explore the QANet model to understand how they intended to improve on training time.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0031", "text": "Title: Question Answering on SQuAD2.0\nAbstract: We chose the default project to build a Question Answering system on the SQuAD 2.0 dataset. Our initial approach to solve this problem focused on implementing the default baseline model that is based on a variant of Bidirectional Attention Flow (BiDAF) with attention. We explored performance after adding character level embeddings to the baseline along with exploring various attention mechanisms. Additionally, we also explored the impact of tuning the hyper-parameters used to train the model. Finally, we studied the effect of using multiple variants of RNN as building blocks in the neural architecture. We improved the model performance on both dev and test sets by at least 4 points. The baseline F1 and EM scores without character embedding were 60.65 and 57.13 while our best improvements with BiDAF, Character Embedding, Self-attention with LSTM were 65.80 and 62.99 respectively. The scores would have been better with pre-trained models however, for our track it was prohibited. Even if we could improve the performance by a bit, question answering remains a challenging problem with a lot of scope of improvement. Also, we need to make sure that the current model generalizes beyond SQuAD dataset.\nThis course was our first foray in the field of NLP and we have developed a deeper understanding about the advances and challenges in Natural Language Understanding and processing and hope to keep improving it with time.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0032", "text": "Title: Improving Out-of-Domain Question Answering with Mixture of Experts\nAbstract: Question answering (QA) is an important problem with numerous applications in real life. Sometimes, the resource of certain QA tasks is limited. Our work aims to build a robust QA system that can generalize to novel QA tasks with few examples and gradient steps. We propose a Mixture-of-Experts (MoE) style training framework, where we learn a gating network to construct the embeddings by performing a weighted sum of the base \"expert\" models with fixed parameters. We find that using the mixture of expert models improves generalization performance and reduces overfitting, especially when using \"expert\" models trained with data augmentation. We use meta-learning methods, specifically the MAML algorithm, to train the gating network for domain adaptation. Training the gating network with the MAML algorithm and finetuning on out-of-domain tasks improved out-of-domain QA performance of baseline models on all metrics. We also discovered a correlation between expert-model performance and the weight the MoE framework puts on each of them. Our approach achieves a F-1 score of 60.8 and EM score of 42.2 on the out-of-domain QA testing leaderboard.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0033", "text": "Title: Tackling SQuAD 2.0 Using Character Embeddings, Coattention and QANet\nAbstract: Question Answering (QA) systems allow users to retrieve information using natural language queries.  In this project, we are training and testing QA models on SQuAD 2.0, a large dataset containing human-labelled question-answer pairings, with the goal of evaluating in-domain performance.  Using a Bidirectional Attention Flow (BiDAF) model with word embeddings as a baseline, we identified, implemented and evaluated techniques to improve accuracy on the SQuAD task. Our initial experiments, which added character embeddings and a coattention layer to the baseline model, yielded mixed results. Therefore, we started over with a new model using Transformer-style encoder layers, based on the QANet. This model posed many challenges, particularly in adapting to the unanswerable component of the SQuAD 2.0 dataset, and thus did not come close to achieving the performance of BiDAF-based models.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0034", "text": "Title: Improving Out-of-Domain Question Answering with Auxiliary Loss and Sequential Layer Unfreezing\nAbstract: The proliferation of pretrained Language Models such as BERT and T5  has been a key development is Natural Language Processing (NLP) over the past several years. In this work, we adapt a DistilBERT model, pretrained on masked language modeling (MLM), for the task of question answering (QA). We train the DistilBERT model on a set of in-domain data and finetune it on a smaller set of out-of-domain (OOD) data, with the goal of developing a model that generalizes well to new datasets. We significantly alter the baseline model by adapting an auxiliary language modeling loss, adding an additional DistilBERT layer, and undergoing training with sequential layer unfreezing. We find that adding an additional layer with sequential layer unfreezing offered the most improvement, producing a final model that achieve 5% over a naive baseline.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0035", "text": "Title: Exploring Combinations of Character Embeddings and Coattention\nAbstract: In this project, I attempt to build a model for the Stanford Question AnsweringDataset (SQuAD) v.  2.0 [1].  I consider 3 different models, the baseline model,or Bi-directional Attention Flow (BiDAF) without character level embedding [2],BiDAF with character level embedding, and a Dynamic Co-attention Network [3]with character level embedding. Some conclusions drawn from my experiment wasthat implementing character level embedding in the BiDAF model significantlyimproved EM and F1 scores over the baseline. However, even though the DynamicCo-Attention Network with character level embedding was an improvement overthe baseline, it scored lower on both F1 and EM scores than BiDAF with characterlevel embedding. On the development set, the BiDAF with character embeddinghas an F1 score of 63.030 and EM score of 59.839.  The Dynamic Co-attentionNetwork with character embedding has an F1 score of 61.54 and an EM of 57.81.My best result on the SQuAD testing set was the BiDAF with character embeddings,achieving an F1 score of 62.266 and an EM score of 58.952.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0036", "text": "Title: Question Answering on SQuAD 2.0 using QANet with Performer FastAttention\nAbstract: Transformers are excellent but scale quadratically with sequence length, resulting in bottlenecks with long sequences. Performers introduce a provably accurate and practical approximation of regular attention, with linear space and time complexity. In this project, we implement the QANet model for the SQuAD 2.0 challenge, then replace self-attention layers in the encoders with Performer Fast Attentions to improve training speed by 18%.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0037", "text": "Title: Question Answering by QANet and Transformer-XL\nAbstract: Question answering is a classic and interesting NLP task, although the pre-trained contextual embedding models (like BERT) have dominated the leaderboards, in order to gain a deep understanding of transformers, I chose to re-implement QANet/1] architecture and integrate it with Transformer-XL|2] attention calculation method in this project. My hope is by introducing the recurrent structure into the attention computation, the combined model (QANet-XL) could learn better since it can take an unlimited length context all at once and it should be able to look further when finding answers. Despite my experiments didn\u2019t show a clear performance improvement with Transformer-XL, but the DEV NLL comparison suggests that QANet-XL might outperform QANet with proper tuning and longer training time.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0038", "text": "Title: Extending BiDAF and QANet NLP on SQuAD 2.0\nAbstract: By exploiting self-matching attention in BiDAF and multihead attention in QANet, our project demonstrates that attention helps to cope with long term interactions in the neural architecture for question answering system. Our addition of self-matching attention in BiDAF matches the question-aware passage representation against itself. It dynamically collects evidence from the whole passage and encodes the evidence relevant to the current passage word. In QANet, convolution and self-attention are building blocks of encoders that separately encode the query and the context. Our implementation of multihead attention in QANet, ran through the attention mechanism several times in parallel. The independent attention outputs are then concatenated and linearly transformed into the expected dimension. Multiple attention heads allow for attending to parts of the sequence differently, so longer-term dependencies are also taken into account, not just shorter-term dependencies.\n\nWe saw some interesting trends while doing Qualitative error analysis of our output. Model was able to answer \"who\" questions better than \"what\" questions. When the \"what\" question was framed differently, like \u201cEconomy, Energy and Tourism is one of the what?\u201d Even though the passage contains the answer, the model could not predict. Also, we observed wrong predictions in general  for questions involving relationships, like: \"Who was Kaidu's grandfather?\" The passage did not mention it explicitly \"Kaidu's grandfather was ...\", however it had the clue: \"Ogedei's  grandson Kaidu ...\", but it could not interpret the correct answer from the passage and instead provided a wrong answer. We also noticed the model could not predict at all a lot of \"which\" questions. Further analysis revealed that those \"which\" questions require a bit more contextual understanding. It was a good learning experience and the model prediction provided a lot of clues as to how we can improve the model to the next level.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0039", "text": "Title: Building a Robust QA System that Knows When it Doesn't Know\nAbstract: Machine Learning models have a hard time knowing when they shouldn't be confident\nabout their output. A robust QnA module should not only be able to do a good job at out of context data, but also be able to do a good job of knowing what data it can't handle. The goal of our project is to build a robust QnA model with an architecture that relies on a base of DistilBERT, improve on it through model fine-tuning, better optimization, and then augment the predictions of the model with a confidence score\n\nOur approach for this project was forked in two directions.\n1. Focus on fine-tuning the model through approaches like transfer learning, longer epochs, mix-out and re-initializing layers.\n2. Augment the model by providing a confidence score to enhance the model's reliability in real world usage.\n\nBERT models use the base weights from pre-training and then fine-tune on specific datasets. They are pre-trained on a variety of tasks making it easier to generalize but it needs to be further fine-tuned for specific task. Also, the fine tuning process is susceptible to the distribution of data in the smaller datasets.\n\nWe aim to improve on this by training on larger epochs, freezing all but the last layers of the BERT model, re-initializing the pre-trained model weights, using a regularization technique called mixout, use the bias correction and finally add additional layers to the model.\n\nThe learnings from the experiments were:\n1.    Bias correction doesn't have any significant impact on the performance\n2.    Freezing the initial layers of DistilBERT doesn't impact the performance but it does speed up the training time\n3.    Re-initializing the lower layers have a positive impact on the performance of the model\n4.    Applying regularization in form of mixout increases the overall accuracy of the model", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0040", "text": "Title: Improving Domain Generalization for Question Answering\nAbstract: Domain generalization remains a major challenge for NLP systems. Our goal in this project is to build a question answering system that can adapt to new domains with very few training data from the target domain. We conduct experiments on three different techniques: 1) data augmentation, 2) task-adaptive pretraining (TAPT), and 3) multi-task finetuning to tackle the problem of producing a QA system that is robust to out-of-domain samples.  We found that simply augmenting the in-domain (ID) and out-of-domain (OOD) training samples available to us, specifically using insertions, substitutions, swaps and back-translations, boosted our model performance with just the baseline model architecture significantly. Further pretraining using the masked LM objective on the few OOD training samples also proved to be helpful for improving generalization. We also explored various model architectures in the realm of multi-task learning and found that jointly optimizing the QA loss with MLM loss allowed the model to generalize on the OOD samples significantly, confirming existing literature surrounding multi-task learning. Hoping that these gains from data augmentation, adaptive pretraining, and multi-task learning would be additive, we tried combining the techniques but found that the sum of the techniques performed only slightly better and sometimes worse than the smaller underlying systems alone. Our best model implements data augmentation on both ID and OOD train datasets with the DistilBERT base model and achieved EM/F1 scores of 35.34/51.58 on the OOD dev set and 42.32/60.17 on the held-out test set. We infer that we've comfortably met our goal of beating the baseline model's performance as the baseline model achieved 32.98/48.14 on the OOD dev set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0041", "text": "Title: Improving Out-of-Domain Question Answering Performance with Adversarial Training\nAbstract: In this project, we aim to investigate the effectiveness of adversarial training on improving out-of-domain performance of question answering tasks. We show that finetuning a pretrained transformer with adversarial examples generated with Fast Gradient Method (FGM) using in-domain training data consistently improves the out-of-domain performance of the model. We also analyze the performance difference in terms of computation cost, memory cost and accuracy between a variety of hyperparameter configurations for adversarial training.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0042", "text": "Title: Building Robust QA System with Few Sample Tuning\nAbstract: In this study we aim to modify three sub-optimal general practices of DistilBERT fine-tuning specifically for the question-answering language task, in order to improve both the predicting stability and performance of the model trained by the out-of-domain few samples datasets. We have implemented bias correction for the optimizer, re-initialization of the last transformer block and increase of the training iterations. With smaller sample datasets in the repeated experiment, the major finding is that the F1 score of the model performance has been improved by re-initialization but not by the other two implementations. It is also shown that the stability of finetuned model performance is improved by these implementations even though the improvements are not all statistically significant. In addition, we carry out an additional augmentation step of synonym substitutions for training datasets and show that both F1 and EM (Exact Match) scores are improved in the repeated experiments, with or without last layer re-initialization. Finally, we build a robust ensemble model based on six models that includes data augmentation with and without last layer re-initialization. Our model achieved performances of 43.096/62.205 (EM)/(F1) on out-of-domain test datasets.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0043", "text": "Title: Comparing Mixture of Experts and Domain Adversarial Training with Data Augmentation in Out-of-Domain Question Answering\nAbstract: Generalization is a major challenge across machine learning; Question Answering in Natural Language Processing is no different. Models often fail on data domains in which they were not trained. In this project, we compare two promising, though opposite, solutions to this problem: ensembling specialized models (a Mixture of Experts approach) and penalizing specialization (Domain Adversarial Training). We also study the supplementary effects of data augmentation. Our work suggests that Domain Adversarial Training is a more effective method at generalization in our setup. We submit our results to the class leaderboard where we place 20th in EM.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0044", "text": "Title: Rediscovering R-NET: An Improvement and In-Depth Analysis on SQUAD 2.0\nAbstract: Question-answering is a discipline within the fields of information retrieval (IR) and natural language processing (NLP) that is concerned with building systems that automatically answer questions posed by humans. In this project, we address the question-answering task by attempting to improve the R-NET model. Specifically, our goals are to 1. reproduce R-NET and evaluate its performance on  SQuAD 2.0 compared to that on the original SQuAD dataset and 2. change certain features of the R-NET model to further improve its accuracy on SQuAD 2.0. We present an implementation of R-NET using LSTM's instead of GRU's, larger embedding and hidden dimensions, higher dropout, and more layers that achieves an improvement in performance from our baseline R-NET model.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0045", "text": "Title: Reimplementing Dynamic Chunk Reader\nAbstract: Some SQuAD models calculate the probability of a candidate answer by assuming that the probability distributions for the answer's start and end indices are independent. Since the two do depend on each other, it should be possible to improve performance by relaxing this assumption and instead calculating the probability of each candidate answer span's start and end indices jointly. We do so by reimplementing the Dynamic Chunk Reader (DCR) architecture proposed in Yu et al.\\cite{yu2016end}, which dynamically chunks and ranks the passage into candidate answer spans using a novel Chunk Representation Layer and Chunk Ranker Layer. We implemented this model on the SQuAD 2.0 dataset instead of Yu et al.'s SQuAD 1 implementation. Our results performed more poorly than the baseline, which may indicate that the DCR architecture may not apply well to the SQuAD 2.0 task, or that we may have misinterpreted certain implementation details from the original paper.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0046", "text": "Title: ALP-Net: Robust few-shot Question-Answering with Adversarial Training, Meta Learning, Data Augmentation and Answer Length Penalty\nAbstract: While deep learning has been very successful in the question answering tasks, it is very easy for models trained on a specific data to perform badly on other dataset. To overcome this, In our paper, we proposed ALP-Net to build a robust question answering system that can adapt to new tasks with few-shot learning using answer length penalty, data augmentation, adversarial training and meta learning.\n1. First, We proposed a new answer length penalty that penalizes the model if the predicted answer is too long, as the baseline QA model tends to generate very long answers. This simple optimization is proved to be very effective in shortening the answers and improving Exact Match.\n2. We also applied data augmentation to generate new data for low-resource datasets by doing synonym replacement and word addition. With data augmentation, the model is more unlikely to learn brittle features such as the occurrences of certain words and fixed answer positions, leading to improved F1.\n3. ALP-Net also adopted adversarial training. We applied a discriminator to determine whether the features learned by the model are domain specific. With adversarial learning, models can learn domain agnostic features that could be applied to unseen domains. We found that while being effective in the few-shot learning task, adversarial training should not be used on out-of-domain training data to keep its domain knowledge.\n4. We also tried meta learning to adopt the mean of different sets of model parameters learned from data of different domains. However, it did not perform well and we found that it is hard to learn general knowledge across domains for question answering tasks.\nAmong these approaches, data augmentation and answer length penalty contribute the most to our model performance, allowing us to achieve 60.962 F1 and 43.005 EM score on out-of-domain datasets test data.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0047", "text": "Title: Improving Question Answering on SQuAD 2.0: Exploring the QANet Architecture\nAbstract: In this project, we investigated QANet - an end-to-end, non-recurrent model that is based on the use of convolutions and self-attention. Our first goal was to reimplement the QANet model from scratch and compare its performance to that of our baseline BiDAF - a model that relies on recurrent neural networks with attention. Both of the QA answering systems were tested on SQuAD 2.0 which includes both questions that are answerable given a context and questions that are not answerable given the context. Finally, after evaluation of our \"vanilla\" QANet and investigation of related work, we implemented an extended model called EQuANT. The model adds an additional output to explicitly predict the answerability of a question given the context. Our best model (QANet with tuned hyper-parameters) achieves F1 = 57.56 and EM = 54.66 on the developmental set, and F1 = 56.76 and EM = 53.34 on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0048", "text": "Title: Bidirectional Attention Flow with Self-Attention\nAbstract: I extended the BiDAF model with varies optimization techniques on the SQuAD 2.0 dataset. With character embedding and multi head self attention been added to the model, my results shows an improvement of +4 point on the EM and +4 point on F1 score compared with the default project. The performance is as expected, but there are also rooms for improvements. One notable finding is I could also generate a masking for each word while training to force the attention computation not focus on the current word but other words of the given inputs.Right after the completion of the project report, i have noticed that other findings reported that a pure  Self-Attention is not that helpful without the bias and rank collapse. It seems a pure self attention layer can be converted into a shallow network", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0049", "text": "Title: QANet without Backtranslation on SQUAD 2.0\nAbstract: This paper investigates two different approaches to the question answering problem on the SQuAD 2.0 dataset. We explore a baseline model based on the BiDaF architecture, and improve its performance through the implementation of character embeddings and hyperparameter tuning. Further, we implement variations on the convolution and self-attention based QANet architecture. While the original QANet architecture uses backtranslation to do data augmentation, we explore a simple and effective method that does not have dependencies on machine translation systems to do augmentation. This involves concatenating contexts together and reusing the same query/answer to generate a new answerable query, and dropping an answer span from the context of an answerable query to create an unanswerable query. The effectiveness of this approach demonstrates the importance of data augmentation for the QANet model. Finally, we form an ensemble model based on our different experiments which achieves an F1 score of 70.340 and an EM score of 67.354 on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0050", "text": "Title: \"Pointed\" Question-Answering\nAbstract: Machine reading comprehension through question-answering is one of the most interesting and significant problems in Natural Language Processing because it not only measures how well the machine 'understands' a piece of text but also helps provide useful answers to humans. For this task, given a paragraph and a related question, the machine's model must select the span from the paragraph that corresponds to the answer using a start index prediction and end index prediction.  My baseline model for this task is a Bidirectional Attention Flow (BiDAF) end-to-end neural network, with embedding, encoder, attention, modeling and output layers. Significantly, the output layer involves the probability distribution of the start index token and end index token to be generated independently. However, in order for the model to learn how the end of an answer can depend on the start of an answer, I implement a boundary model of an Answer Pointer layer (introduced by Wang et al, 2017) based on the notion of a Pointer Network (Vinyals et al, 2015) as a replacement for the output layer of the baseline. This enables us to condition the prediction for the end token on the prediction for the start token of the answer in the input text. Further, since a Pointer Network outputs a probability distribution exclusively over locations in the input paragraph (context) at each step instead of outputting a probability distribution over the entire vocabulary, it allows us to improve the model's efficiency in addition to its accuracy. On testing this new model, I obtain an F1 score of 59.60 and an EM score of 55.01 on the development set, which is an improvement on the performance of the baseline - involving both F1 and EM scores of 52.19 on the development set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0051", "text": "Title: SQuAD: To QANet and Beyond\nAbstract: One of the important topics in NLP domain is machine reading comprehension through automated question answering. In this project we research and implement from scratch a question answering system based on QANet [1] neural network model. We compare the performance of QANet neural network architecture to one of the previous recurrent neural network, in particular a baseline based on BiDAF [2] architecture. Then we experiment by modifying components of QANet model in a novel way and observe the impact of architectural modifications to model\u2019s performance on SQUAD v2.0 [3] dataset.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0052", "text": "Title: Experimenting with BiDAF Embeddings and Coattention\nAbstract: We are motivated by the task of question answering, which is a natural application of language models and helps evaluate how well systems understand the meaning within text. Our primary goal is to improve upon the baseline BiDAF model provided to us on the SQuAD 2.0 dataset, namely by experimenting with character-level embeddings, conditional end pointer predictions (Answer-Pointer network), self-attention, and coattention. We think that each of them leads in some way to an intuitive representation of language, linking it to larger aims within the field. Surprisingly, the coattention and self-attention modified models each score comparatively to or below the baseline model. Perhaps this hints at the importance of multiple layers for self-attention and word-to-word token interactions, as we only used one layer and a vectorized form of the original RNet self-attention paper. Our character-level embeddings + Answer-Pointer modified BiDAF performs best, scoring EM: 60.23 and F1: 63.56 on the dev set and EM: 58.715 and F1: 62.283 on the test set (compared to the baseline model with EM: 56.61 and F1: 60.24 on the dev set). The improvement might be attributed to a better understanding of out-of-vocabulary words and patterns in the grammatical structure of subsequence phrases. Compared to the baseline, the final model better predicts \"No Answer\"s and outputs semantically more logical context subsequences. However, the model still struggles with \"why\" questions and questions that contain different keywords than the context but have synonymous meaning (ex. \"extremely short\" in the context, \"not long enough\" in the question). Based on this error analysis, in the future we would love to explore euclidean distance between words and better beam search approaches to improve performance, as well as further analyze the failure cases of our self-attention / coattention implementations.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0053", "text": "Title: Adversarial Training Methods for Cross-Domain Question Answering\nAbstract: Even though many deep learning models surpass human-level performance on tasks like question answering when evaluated on in-domain test-sets, they might perform relatively poorly on out-of-domain datasets. To address this problem, domain adaptation techniques aim to adapt models trained for a task on in-domain datasets to a target domain by using efficiently samples from the latter. On the contrary, domain generalization techniques aim to incentivate the model to learn domain-invariant features directly from in-domain data to generalize the model for any out-of-domain dataset, pushing to learn task-relevant features and preventing overfitting on in-domain data. We like to compare this approach the way humans learn a task, as they can generally perform the same task on different domains from only a few examples. However, domain generalization is often performed by augmenting in-domain data by applying semantic-preserving transformations to challenge the model during training, leveraging some kind of rules or domain knowledge. Contrarily, in this project our goal is to explore domain generalization techniques applied to question answering based on adversarial training without leveraging any set of rules or domain knowledge but using adversarial terms to make more robust the regular loss with or without adopting task-agnostic critic networks. Such extremely general methodology does not suffer from the limitations of synonym replacement approaches and can be applied to other NLP tasks. Our best variant combines two different and complementary approaches of adversarial training on a DistilBERT baseline, achieving >3% F1-score improvement over the regular fine-tuning process, outperforming several other adversarial and energy-based approaches.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0054", "text": "Title: Context Demonstrations and Backtranslation Augmentation Techniques For a More Robust QA System\nAbstract: Because many real-world NLP tasks rely on user data that is not necessarily guaranteed to be in-distribution, it is critical to build robust question answering systems that can generalize to out-of-domain data. We aim to build a question answering system using context demonstrations and dataset augmentation via backtranslation on top of DistilBERT that is robust to domain shifts. Our method replicates one of the two approaches described in Gao et al. (2020), sampling and appending out-of-domain demonstrations to each training example when finetuning the model. Our method also augments the out-of-domain dataset from which demonstrations are sampled using backtranslation to generate in-distribution training examples. We find that the basic approach of simply appending randomly sampled out-of-domain demonstrations to in-domain contexts does not improve model F1 and EM score performance, but supplementing this approach by adding separator tokens between each demonstration and augmenting the out-of-domain training dataset using backtranslation improves model performance.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0055", "text": "Title: Building a QA System (IID SQuAD track)\nAbstract: In this project, we explored different techniques in the encoding layer, the attention layer and the output layer of an end-to-end neural network architecture for question answering. Experiment results show that better performance can be achieved with different enhancements on top of the baseline model. Especially, with extra character embedding and deep residual coattention, we can achieve EM of 61.17 and F1 of 64.97 in comparison to EM of 58.32 and F1 of 61.78 of the baseline BiDAF model. To better understand the behavior of the best performed model, we broke down the F1 score distribution for the development set and examined the performance across different context lengths, answer lengths, and question types. Furthermore, by inspecting some of the error examples, we found that the model performs poorly mainly when it involves reasoning or advanced/complicated sentence structures.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0056", "text": "Title: CS224N Default Final Project Report: Building a QA System Using BiDAF and Subword Modeling Techniques\nAbstract: In our project, we attempted to answer the question: How can we best adapt a baseline Bi-Directional Attention Flow (BiDAF) network to answer questions in the SQuAD dataset? Our baseline model achieved 57.54 EM and 60.90 F1 in the dev set. Based on this, we experimented with concatenating character embeddings with word embeddings and other forms of subword modeling, such as manually constructing a subword vocabulary of size 10,000 by using the Byte-Pair Encoding algorithm and splitting words into subwords. We found that using our subword embedding layer actually decreased performance, likely to due confusion generated when encountering out of vocabulary words. Our final system and best-performing model is the BiDAF network with the character embedding layer, where character and word embeddings are concatenated in equal part (50/50). Our best results achieved 60.595 EM and 63.587 F1 on the dev set and 59.222 EM and 62.662 F1 on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0057", "text": "Title: SQuAD 2.0: Improving Performance with Optimization and Feature Engineering\nAbstract: In this project, we significantly improved baseline performance on the SQuAD 2.0 question answering task through optimization and feature engineering. Instead of overhauling the original BiDAF network architecture, we focused on extracting as much information as possible from the input data, taking inspiration from the DrQA document reader. We first constructed character-level word embeddings via a 1D Convolutional Neural Network, and then added token and exact match features for both the context and question words. We also conducted thorough hyperparameter searches and experimented with various encoding methods, projection, and drop-out layers. Ensembling our best models by majority vote achieved validation set F1 and EM scores over 7 points higher than the baseline with comparable test set performance (F1=68.753, EM=65.714). Our findings suggest that feature engineering is a particularly effective approach to improve model performance in the absence of pretraining.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0058", "text": "Title: Building a Robust QA System Via Diverse Backtranslation\nAbstract: While question answering (QA) systems have been an active topic of research in recent years, these models typically perform poorly on out-of-domain datasets. Thus, the goal for our project was to build a question answering system that is robust to distributional shift. Utilizing a pretrained DistilBERT model as our baseline, we tested two adaptation methods: backtranslation and few-sample fine-tuning. Backtranslation, which involves translating input data into an intermediate language before translating back to the original language, is a common data augmentation technique in many NLP tasks.  We found that implementing standard backtranslation on out-of-domain training examples yielded significant increases in Exact Match (EM) and F1 scores over our baseline model. We compared these results to several modified backtranslation schemes including one in which we combined backtranslation with techniques from few-sample fine-tuning. Ultimately, we found that combining few-sample fine-tuning techniques with backtranslation did not improve performance. Our best model achieved an EM of 42.225 and F1 of 59.162 on the test set, and an EM of 38.74 and F1 of 51.19 on the development set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0059", "text": "Title: Question Answering with Binary Objective\nAbstract: We added a secondary binary objective of predicting answerability to QANet. As shown in the picture, this objective is computed using the three outputs from the modeling layer in QANet. More specifically, we concatenate the 0th words of m0, m1, m2 (these are the outputs of the first, second, and third pass of the modeling encoder) and pass it through a single feed-forward layer with sigmoid activation. Our results showed that adding this secondary objective resulted in meaningful improvements in both EM and F1 over our implementation of QANet, which mostly follows the official QANet but we added a project layer on the output of the context-query attention layer to reduce memory usage. We also were able to produce the performance gains from adding character-level encoding, replacing RNN with multi-head self-attention and convolutions, and applying layer-wise dropout (stochastic depth).", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0060", "text": "Title: Extended BiDAF with Character-Level Embedding\nAbstract: With the rise of NLP and ML, we've seen much progress in regards to the task of machine comprehension and building robust question answering systems. we want to focus on investigating and improving the BiDAF model, starting from extending the baseline model by including character-level word embeddings. We then ran experiments using the improvements recommended in section 5.11 of the default project handout. Two major goals were accomplished: we implemented character-level embeddings and adjusted dropout rate and learning rate in addition to other hyper-parameters in order to improve our model. On our best model, we were able to achieve an F1 score of 65.106 and a EM score of 61.369 in the non-PCE division.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0061", "text": "Title: SQuAD - Refined Implementation of Contextually Enriching Passage Sequences (SQUAD-RICEPS)\nAbstract: Our default project took on the task of SQuAD 2.0 Question Answering using inspiration from an approach described in Christopher Clark's 2017 paper, \"Simple and Effective Multi-Paragraph Reading Comprehension\". We combine the embedding, encoding, and bi-attention of BiDAF with an additional two layers of self attention. Our findings see an improvement when using a TriLinear attention layer on top of a Multiheaded Scaled Dot Product Self Attention layer. While we had promising results with character embeddings on the dev set, we were unable to refine our implementation of character embeddings to improve our model. We were able to produce an EM score of 59.5 and an F1 score of 62.7 which improved on the BiDAF baseline's score of 56.3 and 59.4.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0062", "text": "Title: Building a Robust QA system with Data Augmentation\nAbstract: Pre-trained neural models such as our baseline model fine-tuned on a BERT based pre-trained transformer to perform nature language question and answering prob- lems usually show high levels of accuracy with in-context data, but often display a lack of robustness with out-of-context data. We hypothesize that this issue is not primarily caused by the pre-trained model's limitations, but rather by the lack of diverse training data that might convey important contextual information in the fine-tuning stage. We explore several methods to augment standard training data with syntactically informative data, generated by randomly replacing the grammatical tense of data, removing words associated with gender, race, or economic means, and only replacing question sentences with synonym words from a lexicon of words. We found that the augmentation method that performed the best was changing the grammar of more and one word in every question. Although it only made less than 1 point increase in the F1 and EM scores, we believe that if we also applied this method to the context and answers training data we would be able to see even more significant improvements. We were also surprised that the method of removing associations with gender, race, or economic status performed relatively well given that we removed a lot of words from the dataset.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0063", "text": "Title: Implementations of R-NET and Character-level Embeddings on SQUAD\nAbstract: While there have been many new and exciting developments in solving the SQuAD challenge over recent years, I decided to focus on the fundamentals in my final project approach. What better way to practice and reinforce classical deep learning concepts such as recurrent neural networks, convolutional networks and self-attention than implementing R-NET with added character-level word embeddings? My experiments showed that character-level emebeddings enrich the understanding of word components and provide improvement on key evaluation metrics. My implementation of R-NET also exhibits an additional lift in model performance on SQuAD 2.0. However, the limitations of R-NET are also highlighted as it struggles to identify unanswerable questions especially when similar phrases exist in both question and passage.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0064", "text": "Title: Stanford CS224N SQuAD IID Default Project\nAbstract: Being able to answer questions about a given passage marks a significant advancement in artificial intelligence. This task also has incredible practical utility, given the great need to have a personal assistant on our phones that can answer simple questions about world facts. In this project, we attempt to build a state-of-the-art model for question answering on the SQuAD 2.0 dataset via combining several different deep learning techniques. We iterated off of the baseline BiDAF model with various improvements such as feature engineering, character embeddings, co-attention, transformer models, and more. We had mixed success in getting all of these methodologies to fully run as anticipated and found many to not work as well as we had hoped. But we still managed to make significant improvements over the baseline by combining some of what we had implemented and performing a hyperparameter search. Our final model was quite successful on this front, achieving an F1 score of 63.517 and an EM score of 59.966 over the baseline's 58 F1 score and 55 EM score.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0065", "text": "Title: Building a QA system (Robust QA track)\nAbstract: While there have been great strides made in solving fundamental NLP tasks, it is clear that the models which tackle these problems fail to generalize to data coming from outside the training distribution. This is problematic since real-world applications require models to adapt to inputs coming from previously unseen distributions. In this paper, we discuss our attempt to create a robust system for extractive question answering (QA). We use a BERT variant as our baseline, and attempt four methods to improve upon it. Our first method is a model that uses the Mixture-Of-Experts (MoE) technique described in the \"Adaptive Mixtures of Local Experts\" paper and the Robust QA Default Project handout. The second is an original inference-time procedure which predicts the answer span that maximizes the expected F1 score. The third approach is to produce more out-of-domain training examples via data-augmentation. Our final and best-performing method is an Adversarial Training model described in \"Domain-agnostic Question-Answering with Adversarial Training\". The MoE model and expected-F1-maximization strategy fail to outperform the baseline's F1 score of 47.098, achieving F1 scores of 44.870 and 44.706  on the validation set respectively. Training the baseline with augmented data produces an F1 score of 48.04. Domain Adversarial Training gives the best results when coupled with data augmentation, yielding an F1 score of 51.17 on the validation set. However, we see that on the test set, none of our models were able to the beat the baseline's F1 score of 60.240.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0066", "text": "Title: Building a Robust QA system\nAbstract: Researchers today prioritize their time by building increasingly complex models that are harder to interpret and debug. The goal of this project is for us to discover how noninvasive techniques can be equally as effective.  We explore how accuracy improves with hyperparameter tuning, various different methods of learning rate decay, and layer freezing.  We also analyze the effects of data-side augmentations such as backtranslation, synonyms, masked learning, and upsampling. The last area of exploration is an altered loss function that biases against length. Our main conclusions support that fine tuning and data augmentation methods were the most critical in improving performance on question answering systems under domain shifts. We see that data augmentation (back translation and synonym translation) however can sometimes be too noisy depending on how many sequences of languages we filter through, suggesting that future work looks into understanding an optimal number of languages. We have inconclusive results on the quality of MLM and upsampling our dataset as we see marginal improvement at best from these methods, potentially suggesting that they are not worthwhile pursuing for such few sample finetuning. Lastly, we see that for future work further investigation into our added loss function could be potentially useful in regularizing response length.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0067", "text": "Title: RobustQA: Benchmarking Techniques for Domain-Agnostic Question Answering System\nAbstract: Despite all the hype about performances from large pretrained transformers like BERT and ROBERTA, it has been shown that Question Answering (QA) tasks still suffer challenges when there exists a large discrepancy between the training and testing corpus. The goal of our project is thus to build a question answering system that is robust to out-of-distribution datasets. We approach this challenge through data augmentation, where we hope to add label preserving invariances to the fine-tuning procedure to reduce the learned features specific to the in-domain data while increasing the number of the out-of-domain data that our QA model can generalize more broadly. Specifically, we paraphrased both the in-domain and out-of-distribution training sets by back-translating each query and context pair to multiple languages (Spanish, Russian, and German) using architectures that include a two-layer neural machine translation (NMT) system and pretrained language transformers. After back-translation, we iterate over all continuous subsets of words in the context sentence to find an approximate answer span that is the most similar to the original gold answer, and we filtered out examples with Generalized Jaccard similarity scores below 0.65 to ensure data quality. By fine-tuning the DistilBERT baseline on these augmented datasets, our best model achieved 51.28 F1 and 35.86 EM on the development set and 59.86 F1 and 41.42 EM on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0068", "text": "Title: Dataset Augmentation and Mixture-Of-Experts Working In Concert For Few-Shot Domain Adaptation Transfer Learning\nAbstract: Despite the significant improvements in NLP in the last few years, models can still fail to work well on test sets which differ, even a small amount, from their training sets. Few shot learning is an important goal in creating generalizable neural network models. In this paper we explore ways to increase the few shot learning performance of a model by implementing a few variations meant to improve generalizability; specifically we measure the effects of data augmentation and mixture of experts on a pre-trained transformer BERT model. Mixture of experts is a technique in which separate models are trained to be responsible for different sub tasks within a problem. We find that this change is able to remove the interference between out-of-domain datasets during training and increase performance from F1 48.43 to 51.54. Data augmentation applied for NLP is a technique in which words within a piece of text are added, removed, or replaced in an effort to increase the variance in training data. This method was found to be a valuable tool in further improving expert learning, increasing the overall F1 score further to 52.07, however it did not improve the baseline model when used on its own.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0069", "text": "Title: Longer-term dependency learning using Transformers-XL on SQuAD 2.0\nAbstract: I propose an application of the Transformer-XL attention model to the SQuAD 2.0 dataset, by first implementing a similar architecture to that of QANet, replacing the RNNs of the BIDAF model with encoders, and then changing out the self-attention layer to that of Transformer-XL. In traditional transformers, there exists an upper dependency length limit equal to the length of this context. The Transformer-XL addresses these issues by caching the representations of previous segments to be reused as additional context to future segments, thus increasing the context size and allowing information to flow from one segment to the next. This longer-term dependency capture can be particularly useful when applying transformers to domains outside of natural language. Only a small improvement is shown with the Transformer-XL / QANet combined model compared to the baseline BIDAF, but increased performance is expected with additional parameter finetuning.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0070", "text": "Title: BiDAF with Character and Subword Embeddings for SQuAD\nAbstract: In this paper, we have implemented subword embeddings and character-level embeddings on top of the word embeddings in the starter code.\nFor the character embeddings, we followed the approaches outlined in the BiDAF paper[1]. The character's representation vectors were randomly initiated and then passed through a convolutional neural network. We then applied the ReLu function, as well as downsampling it using the maxpool function to get the representation vector for every word.\nFor the subword embeddings, we utilized the implementation of the Byte Pair Encoding algorithm[2]. It segments the word by grouping character sequences that occur most frequently in its training data. We then looked up the representation vector for each subword, which is trained using the GloVe algorithm(The segmentation and vector representation are both implemented in the Python library bpemb)[3].  We utilized the maxpool function to get the representation vector of each word, and then used linear transformation to convert the input features to match the hidden layers. Finally, we concatenated the three types of embeddings and passed them through the Highway Networks.\nAmong the different types of models we have experimented with, the model with the concatenation of word embeddings and character-level embeddings performs the best on the SQuAD v2.0 dev set: EM=61.39, F1=65.05.\n\nReferences\n[1]Minjoon  Seo,  Aniruddha  Kembhavi,  Ali  Farhadi,  and  Hannaneh  Hajishirzi.   Bidirectionalattention flow for machine comprehension.arXiv preprint arXiv:1611.01603, 2016.\n[2]Benjamin Heinzerling and Michael Strube.   Bpemb:  Tokenization-free pre-trained subwordembeddings in 275 languages.arXiv preprint arXiv:1710.02187, 2017.\n[2]Jeffrey Pennington, Richard Socher, and Christopher D Manning.  Glove:  Global vectors forword representation.  InProceedings of the 2014 conference on empirical methods in naturallanguage processing (EMNLP), pages 1532-1543, 2014.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0071", "text": "Title: Improved QA systems for SQUAD 2.0\nAbstract: We worked on the default project: Building a question-answering system (IID SQuAD track). Motivated by recent publications (such as \"Attention is All You Need,\"\" \"Machine Comprehension Using Match-LSTM and Answer Pointer,\" and \"Convolutional Neural Networks for Sentence Classification\"), we decided to extend the baseline BiDAF model with implementations of a character embedding layer, an answer pointer decoder in place of the original output layer, and a self-attention layer immediately after the bidirectional attention flow layer. We experimented with two versions of character embedding layers, and found that back-to-back convolutional layers allowed for better performances. Our implementations dramatically improved learning speed in the training process. Through multiple rounds of training with various hyperparameters, we achieved F1 scores of 64.83 on the dev set and 63.37 on the test set. We anticipate that this work will aid in the continuing development of efficient question answering systems.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0072", "text": "Title: Meta Learning on Topics as Tasks for Robust QA Performance\nAbstract: A key pain point of current neural QA-focused NLP systems is the lack of generalization \u2014 often these systems learn parameters that fail to generalize to neverbefore-seen data domains, unlike how humans can take previous knowledge and build accurate inferences beyond \"training\" data distributions. Clearly, advances in meta-learning have shown promise in improving model resiliency and adaptability across many AI domains, and thus we hope to modify our given Transformer QA model to improve performance on out-of-domain QA tasks and data. Specifically, we hope to use the Reptile meta-learning algorithm applied to multiple prelearning tasks \u2014 which we interpret to be topics from within a single dataset \u2014 to create a metalearner on which we test out-of-domain QA, in order to hopefully show that this model would be more robust than baseline (higher EM and FI scores).", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0073", "text": "Title: Building a QA System (IID SQuAD Track)\nAbstract: I implemented three NLP models : (a) a 4-layer 6 attention heads transformer encoder model, (b) QANet model and (c) extending the baseline BiDAF model with character embeddings for the question-answering task on the SQuAD dataset. The transformer encoder model (Fig (a)) is fed the sequence: \"\" where  and  are two special tokens indicating the start of the question and start of context respectively. To allow the model to predict no-answer, the context is prepended with a special  (out-of-vocabulary) token. The output of the 4-layer transformer encoder is fed to a feedforward layer which is again fed to two different feedforward layers each followed by softmax, to predict the start and end position of answer in the context. The QANet Model (Fig (b)) replaces the LSTM encoder in BiDAF with self-attention and depthwise separable convolution. The model uses an encoder block (on right in Fig (b)) which contains multiple depthwise separable convolution layers followed by self attention and feedforward layer. The embedding layer (with character embeddings) and Context-Query attention are same as in BiDAF. The output of Context-query attention is fed to a stack of three encoder blocks, where the output of first two and first & third are used to predict start and end position of answer respectively through a projection layer followed by softmax. The transformer encoder model achieves EM and F1 score of 52.19 and 52.19 respectively while for the QANet model the scores are 57.28 and 60.59 respectively on the dev set. The QANet model was trained for 28 epochs and I believe that training it for longer (like 40 epochs) is likely to improve its performance. Adding character embedding to the baseline BiDAF model improves the EM and F1 scores from 55 and 58 to 59.6 and 63.14 respectively on dev set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0074", "text": "Title: Building QA Robustness Through Data Augmentation\nAbstract: While question and answering (QA) models have achieved tremendous results on in-domain queries, recent research has brought into question the ability of these Q&A models to generalize well to unseen data in other domains. To address this,  we aim to build a robust question answering system, which trained on a set of in-domain data can then be adapted to unseen domains given few training samples. Our main approach is the field of data augmentation. In this work, we conduct a survey of existing data augmentation methods, including backtranslation, synonym replacement, and synonym insertion, as well as introduce a mixed data augmentation method (MDA) combining the previous three. For examples of backtranslation, synonym replacement, and synonym insertion, please see the displayed figure. The figure displays three examples for how one sentence might be augmented using each data method. In particular, we explore the efficacy of data augmentation in the task of question answering. We find that data augmentation provides moderate gains on our out of domain validation and test sets and that certain methods such as backtranslation and synonym replacement provide larger improvements compared to others. Overall, we confirm that data augmentation is a simple, generalizable technique with a wide variety of different methods that can effectively aid in improving the robustness of Q&A models in the face of unseen domains with few training examples.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0075", "text": "Title: The Efficient BiIDAF\nAbstract: In recent years, The massive pre-trained Language models have dominated the State-of-the-Art leaderboard across many NLP tasks including the Question Answering task on SQuAD 2.0. In this project, we travel back to a successful traditional approach known as Bi-Directional Attention Flow (BiDAF) which uses a sequence-to-sequence network. We identify the shortcomings of this model and implement a multi-stage hierarchical end-to-end network that solves the shortcomings of BiDAF.\n\nMore specifically, the original model uses a sequence-to-sequence network like RNN to encode information of query/context into a vector. Even though RNNs' are known to be quite effective, they have few huge bottlenecks, namely, non-parallelizability of the network due to its seq-to-seq/time-step based computation, lack of transfer learning support, and vulnerability to vanishing/exploding gradient. We handle these shortcomings of RNN by replacing them with transformer encoders.\n\nAdditionally, we implement few recent techniques to improve the vanilla encoder network, namely, Spatial Positional Encoding instead of traditional Absolute Positional Encoding, ScaleNorm instead of traditional LayerNorm, Feedforward Network with Gated Linear Unit instead of traditional Feedforward Network with RELU.\n\nLooking outside RNN, we replace the query-to-context and context-to-query Attention flow with Cross-Attention using a Multi-headed Attention mechanism. We show that multi-headed Cross-Attention works better than the traditional Attention Flow layer.\n\nFinally, we introduce pre-trained character embedding vectors that were extrapolated from the existing Glove pre-trained word embeddings. We also show that this improves the baseline BiDAF model by a considerable amount.\n\nLastly, we show the results of our final model on the validation set and compare its performance with the baseline BiDAF model. Evidently, we can observe that our model is performing better than the original BiDAF in terms of latency, and accuracy. Our Model is also highly extensible since we use encoders and multi-head attention and they don't suffer from traditional seq-to-seq bottlenecks and are available to the use of transfer learning.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0076", "text": "Title: Embedding and Attending: Two Hearts that Beat as One\nAbstract: Neural attention mechanisms have proven to be effective at leveraging relevant tokens of the input data to more accurately predict output words. Moreover, incorporating additional embedding information significantly boosts performance and provides greater granularity of tokens at the character and word level. For these reasons, we focused on implementing various models that concern primarily the embedding layer and attention layers. In our project, we implemented three different attention mechanisms (co-attention from Dynamic Coattention Networks, key-query-value self-attention, and R-Net self-attention) in the domain of the Question-Answering (QA) paradigm. Our goal was to produce a model that is highly performant compared to the baseline BiDAF model on the Stanford Questioning Answering Dataset (SQuAD 2.0). We combined these attention mechanisms with character-level embeddings to provide more local contextual information, and finally enhanced these embeddings by including additional input features (part-of-speech and lemmatized forms of words). Lastly, we conducted a series of hyperparameter tuning experiments to determine the ideal hyperparameters that result in the greatest F1/EM scores. Augmenting the baseline with these techniques produced a significant improvement compared to the baseline. Our most performant model obtained an F1 score of 65.27 and EM score of 61.77 (an increase of 5.6% and 5.5%, respectively).", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0077", "text": "Title: Investigating the effectiveness of Transformers and Performers on SQuAD 2.0\nAbstract: In this project, I explored aspects of the Transformer architecture in the context of question answering on SQuAD 2.0, the Stanford Question Answering Dataset. I split this exploration into several phases, which built upon each other.\nIn Phase 1, I gained familiarity with the default baseline (based on BiDAF, a recurrent LSTM-based algorithm) by upgrading it to support character-level embeddings, in addition to the existing word-level embeddings.  This resulted in a 2-point performance increase on all scoring metrics.\nIn Phase 2, I incrementally refactored the baseline from BiDAF into QANet, a question answering architecture which is similar in structure but uses convolution and Transformers instead of recurrent neural networks. After hyperparameter tuning, I found this improved performance by an additional 3.5 points on all scoring metrics.\nIn Phase 3, I replaced the Transformer with an architectural variant, the Performer, which aims to solve the issue of quadratic scaling in vanilla Transformers'runtime and memory usage by using kernel methods to approximate the self-attention calculation. I found that this was effective within QANet, enabling linear scaling from hundreds to tens of thousands of tokens, with minimal impact to performance.\nIn Phase 4, I prepared to make use of this scale to support open-domain question answering. I wrote a TF-IDF based document retriever, which returned the most similar Wikipedia page to the current context passage. I found this to be reasonably effective in locating similar passages.\nFinally, in Phase 5, I fed this new input into QANet via a new, large Background input, which supplemented the existing Context and Question inputs. I upgraded QANet to support this by adding a Context-Background attention and a Query-Background attention layer to the current Context-Query attention layer. This appears to start training correctly, with training and validation loss both decreasing over time.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0078", "text": "Title: DA-Bert: Achieving Question-Answering Robustness via Data Augmentation\nAbstract: Pretrained models are the basis for modern NLP Question-Answering tasks; however, even state-of-the-art models are heavily influenced by the datasets they were trained on and don't generalize well to out-of-domain data. One avenue for improvement is augmenting the training dataset to include new patterns that may help the model generalize outside of its original dataset. In this paper, we explore improving model robustness in the question-answering task, where we have a query, a context (i.e. passage), and an answer span that selects a portion of the context. We utilize various data augmentation techniques including adding noise to our contexts and backtranslating (translating text to a pivot language and then back) both the queries and contexts. We find that leveraging the technique of backtranslation on the queries, both on in-domain and out-of-domain training datasets, greatly improves model robustness and gives a 3.7% increase in F1 scores over our baseline model without data augmentation. Further, within this approach of backtranslation, we explore the linguistic effect of particular pivot languages and find that using Spanish adds the greatest robustness to our model. We theorize that Spanish and potentially other Romance languages' linguistic similarity to English gives clearer and more helpful translations than other high-resource languages with different roots.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0079", "text": "Title: Exploring the Architecture of QANet\nAbstract: Before the advent of QANet, dominant question-answering models were based on recurrent neural networks. QANet shows that self-attention and convolutional neural networks can replace recurrent neural networks in question-answering models. We first implemented a version of QANet using the same architecture as that of the original QANet model, and then we conducted experiments on hyperparameters and model architecture. We incorporated attention re-use, gated self-attention, and conditional output into the QANet architecture. Our best QANet model obtained 59.3 EM and 62.82 F1 on the evaluation set. The ensemble of the two best QANet models and one BiDAF model with self-attention mechanism achieved 62.73 EM and 65.77 F1 on the evaluation set and 60.63 EM and 63.69 F1 on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0080", "text": "Title: Question Answering with Co-attention and Transformer\nAbstract: in this project, we implemented several improvements of question answering system based on SQuAD database including: 1) QANet 2) coattention 3) RNet. We built the models from scratch and evaluated against the EM and F1 scores. Our main goal is to explore through various techniques in the Question Answering System. In this process, we were able to practice our skills of implementing complex models according to their descriptions  in literatures.\n\nWe first implemented the co-attention layer, which did not improve the model performance. We then added character-level embeddings to the baseline model which improved the EM score to 60.59 and F1 score to 64.17.\n\nAfter that we implemented QANet which used convolutions to capture the local structure of the context and self-attention mechanism to model the global interactions between text. We built the QANet incrementally and implemented several model components. We eventually saw major improvements in both EM and F1 scores (64.49 and 69.62) compared to the baseline BiDAF model and BiDAF with character-level embeddings.\n\nAt the same time, we implemented the Self Matching layer and the Pointer Network described in the RNet paper. The self-matching mechanism helps refine the attention representation by matching the passage against itself, which effectively encodes information from the whole passage.  This is implemented on the top of character-level embeddings and the baseline. We tested several modifications of the RNet architecture including different gate attention recurrent network and output layer. While Self Matching improved the performance, the Pointer Network caused vanishing gradients. The self-matching layer combined with character-level embeddings improved the performance to 62.06(EM) and 65.53(F1).\n\nAmong all techniques, QANet gives the best performance, and to our understanding, the reason is that the QANet can capture the local and global interaction at the same time with its complex model architecture containing both convolutions and attention-mechanism.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0081", "text": "Title: Meta-learning with few-shot models Analysis Final Project\nAbstract: This project focuses on understanding the various elements of Meta-learning and few-shot models and the effectiveness of the different detailed implementation approaches.  Using the default RobustQA project as a baseline, we explored the different implementations of the Meta-learning algorithm, LEOPARD, and evaluate the impact on performance of the prediction accuracy.  We have also experimented with the eval-every parameter to understand how fast each implementation can learn when presented with the out of domain questions initially.  We found that the multiple datasets implementation of the Leopard algorithm yields the best few-shot result. On the first evaluation at step 0 (after 1 batch of data for learning) this implementation already achieving a result of a EM score of 34.55 (on the validation set) compared to the ~32 EM scores that the other implementation and the baseline are getting.  However, after the model is trained for a longer time, we found that the baseline can actually achieve a better EM score overall with 42.202 on the test set.  Although, the difference in the overall accuracy of the test set score are very small for different implementations, we found the more simple implementation yields better accuracy in the long run.\nOur key finding is that the design of few-shot learning algorithm or model is actually a trade off between few-shot accuracy and the overall highest achievable accuracy.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0082", "text": "Title: Extending a BiDAF model with DCN for Question Answering\nAbstract: Our goal in this project is to improve the performance of the Bidirectional Attention Flow (BiDAF) model for the NLP task of question answering on the SQuAD 2.0 dataset. To do this, we 1) integrate character-level embeddings into the baseline BiDAF model and 2) replace the default attention layer with a coattention layer. While adding character-level embeddings has shown to improve the baseline BiDAF model's EM and F1 scores substantially, their addition to the DCN model actually decreased its scores slightly. Moreover, transforming the BiDAF model into a Dynamic Coattention Network (DCN) decreased the model's performance. Thus, the best model architecture we found is BiDAF with character-level embeddings. Future work includes tuning hyperparameters, experimenting with data processing techniques, adding optimizations like the Adam optimizer, and exploring different forms of attention.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0083", "text": "Title: QANet for Question Answering on SQuAD2.0\nAbstract: In this project, we study the application of a QANet architecture to question answering on the SQuAD2.0 dataset. Question answering consists in training models to answer questions provided in natural language from either prodided or general context. The QANet architecture, originally presented in 2018, was a top performer on the original SQuAD dataset before the advent of pre-training. While the original SQuAD dataset only contained answerable questions, the creators of the dataset published the updated SQuAD2.0 dataset that contains unanswerable question and demonstrated that while it had little effect on human performance, it greatly reduced the effectiveness of existing models. We study how the QANet model fair on this dataset compared with a BiDAF baseline model, another high-performing model. We show that QANet's effectiveness drops, but that simple modifications to the original architecture allow significant improvements in overall performance. We also study the benefits of ensembling different architectures to improve final performance. We achieve EM and F1 scores of 63.415 and 66.734 on the test dataset.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0084", "text": "Title: Robust QA with Model Agnostic Meta Learning\nAbstract: One model, called BERT (Bidirectional Encoder Representations from Transformers), has achieved current state-of-the-art on metrics such as GLUE score, MultiNLI accuracy, and F1 score on the SQuAD v1.1 and v2.0 question answering datasets. BERT is pre-trained using unlabeled natural language data via a masked language model (MLM) method, it is then fine-tuned for next- sentence prediction and question answering tasks.\n\nSuccessfully adapting BERT to low-reource natural language domains remains an open problem. Previous approaches have included using multitask and meta-learning fine-tuning procedures. Using a variant of the Model Agnostic Meta Learning (MAML) algorithm from, researchers were able to show that meta learning procedures had a slight advantage in low-resource domain adaptation than multitask models. However the researchers experimented with only a few task distributions p(T) for the MAML algorithm, and while the results did show an improvement over multitask models, performance for certain task distributions on specific tasks was somewhat counterintuitive.\n\nIn this paper, suggestions from a recent paper in the International Conference on Learning Representations (ICLR) are implemented to stabilize training of a MAML-type algorithm on a pre-trained variant of BERT called DistilBERT. Several task distributions and other MAML-specific hyperparameter initializations are implemented and analyzed and a classifier is trained to predict out-of-domain dataset type to better leverage task-specific fine-tuning. The image included indicates that certain tasks, like predicting for the race and relation extraction datasets, are distinguishable and that a MAML algorithm might not be able to leverage data from one to help the other. However, another task, like predicting on the duorc dataset that is shown to be fairly indistinguishable from the other two datasets, might be able to help the other two tasks out during training.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0085", "text": "Title: Exploring Improvements to the SQuAD 2.0 BiDAF Model\nAbstract: We have explored different deep learning based approaches to the question answering problem on SQuAD 2.0 using an improved version of the BiDAF model. Our baseline was provided by the default project starter code, and is a modified BiDAF that has only word embeddings and performs on SQuAD 2.0. We explored three areas of improvements: character embeddings, conditioning the end prediction on the start prediction, and adding a self-attention layer. We found that the biggest improvement was from the Condition End Prediction on Start Prediction and Self-Attention with an F1 and EM score of 65.285 and 61.758 on the test set respectively. The model with character embeddings scored a 59.96 on EM and a 63.24 on F1, and the model with character embedding and self attention scored a 63 on EM and a 66.2 on F1 (both for the dev set). In our error analysis, we discovered that generally, all models performed well on questions that began with \"When\", and performed poorly on questions that begin with \"What\" and \"The\". Our future work includes investigating how further extensions, like transformers, co-attention, and different input features affect performance. Overall, this project was very educational, as it allowed us to read through numerous papers that outlined breakthrough improvements to this problem, and enabled us to implement ourselves the methods described in the papers.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0086", "text": "Title: Domain-Adversarial Training For Robust Question-Answering\nAbstract: In this project, we created a domain-adversarial model to improve upon the baseline DistilBERT model on the task of robustly answering reading comprehension questions across domains. The way the adversarial model works is by creating a discriminator, which is trained to decide based on the last layer of our question-answering model which domain the question came from. Then, our question answering model is trying to not only answer questions correctly but also to trick the discriminator as much as possible, which forces it to prioritize features of the question and context which are not domain-specific in this final hidden layer. Our model got an EM score of 41.353 and F1 score of 59.803 on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0087", "text": "Title: Sesame Street Ensemble: A Mixture of DistiIBERT Experts\nAbstract: In this project, I attempt to finetune a pre-trained DistilBERT model to better handle an out of domain QA task. As there are only a few training examples from these outside domains, I had to utilize various techniques to create more robust performance: 1) implemented a mixture of local experts architecture and 2) finetuned a number of hyperparameters to perform best over this few shot learning task. Specifically, a separate DistilBERT model was finetuned on each of the in-domain datasets to act as an expert. The finetuning approaches focused on reinitializing a variable amount of final transformer blocks and training for a longer period. These two approaches were then synthesized to produce the final model. The results were negative. I speculate that this is because the domains covered by the experts were too distinct from that of the out-of-domain datasets. In future work, I would like to use data analysis to group similar training examples (across predefined datasets) to hopefully lead to more focused experts.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0088", "text": "Title: QA System with QANet\nAbstract: Question answering system has always been an active field in the Natural Language Processing (NLP) researches. In the past few years, the most successful models are primarily based on Recurrent Neural Networks (RNNs) with attention. Though a lot of progress has been made, due to its sequential nature, RNN's operations are unparallelizable, which makes both training and inference slow. In addition, with linear interaction distance, RNNs have difficulty in learning long dependencies. This is a severe problem in QA system, since the context are usually long paragraphs.\n\nBased on these problems, in this project, we implemented a QA model based on Transformer, hoping to achieve both accurate and fast reading comprehension. We focused on reading comprehension among all QA problems, which is to select a part of text from the given context to answer some certain question. Instead of LSTM, this model used convolution layers and self-attention to form encoders. Given a paragraph of context and a question, it will output the probability of each context word being the start or end of the answer. However, against our expectation, this model did not perform very well. The speed is low due to its large amount of parameters, and the accuracy cannot match that of BiDAF because of overfitting.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0089", "text": "Title: Improving the Robustness of QA Systems through Data Augmentation and Mixture of Experts\nAbstract: Despite the stunning achievements of question answering (QA) systems in recent years, existing neural models tend to fail when they generalize beyond the in-domain distributions. This project seeks to improve the robustness of these QA systems to unseen domains through a combination of Easy Data Augmentation (EDA) and Mixture of Experts (MoE) techniques.  As baseline, we finetuned a pre-trained DistilBERT model with Natural Questions, NewsQA and SQuAD datasets using the default configurations and evaluated the model performance on the out-of-domain datasets, including RelationExtraction, DuoRC, and RACE. After obtaining our second baseline by including a small number of training examples from our out-of-domain datasets, we ran two rounds of hyperparameters tuning through random search. Based on the best performing set of hyperparameters, we then augmented our out-of-domain datasets using the EDA techniques and analyzed the effects of each technique through a series of experiments. Finally, we implemented an MoE model with three experts and a two-layer bi-directional LSTM followed by a linear layer as the gating function.  Both the data augmentation technique and the mixture-of-expert approach demonstrated capability to improve the robustness of DistilBERT-based QA systems, and a combination of the two methods brings even further improvement. The combined approach increased the F1 and EM scores on the dev set by 15.03% and 14.87%, respectively, compared to the baseline, and achieved an F1 score of 62.062 and an EM score of 42.317 on the test leaderboard.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0090", "text": "Title: Towards a Robust Question Answering System through Domain-adaptive Pretraining and Data Augmentation\nAbstract: Large pretrained language models have shown great success over a bunch of tasks in the past few years. These large language models are trained on enormous corpus, and it now becomes a question whether they are robust to domain shift. We find in this paper that the domain of question answering (QA) problems has significant impact on the performance of these fine-tuned LMs and these fine-tuned QA models are still sensitive to domain shift during test time. This potentially causes problems in many real-word applications where broad or evolving domains are involved. So, how can we improve model robustness? In this paper, we offer two potential solutions. First, we propose to continue pretraining on the objective domains. This second-phase of pretraining helps model focus on information that is relevant to the problem. We find that domain-adaptive pretraining helps improve out-of-domain test performance. In some cases, we might have additional small amount of training data on the test domain. We propose to use data augmentation tricks to maximally utilize these data for domain adaptation purpose. We find that data augmentation tricks, including synonym replacement, random insertion and random deletion, can further improve the performance on out-of-domain test samples. Our work shows that the improvements in performance from domain-adaptive pretraining and data augmentation are additive. With both methods applied, our model achieves a test performance of 60.731 in F1 score and 42.248 in EM score. The experiments and methods discussed in this paper will contribute to a deeper understanding of LMs and efforts towards building a more robust QA system.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0091", "text": "Title: QA System Using Feature Engineering and Self-Attention (IID SQuAD track)\nAbstract: Machine reading comprehension is an exceedingly important task in NLP and is a desired feature in many of the latest consumer and research projects. Therefore, using this task as motivation, we set out to build a reading comprehension model that performed well on the SQuAD 2.0 question answering dataset. To do this, we built upon the existing BiDAF  machine comprehension model given to us through the CS224n staff. Our contributions to this model are a character embedding layer on top of the existing word embedding layer, a self attention layer, and added features to the character and word embeddings which include Part of Speech tags (POS), named entity recognition (NER) tags, and dependency tags. As a result of implementing these layers we found that character embedding with additional input features performed the best with an F1 dev score of 64.38 and an EM dev score 61.29. On the test set we achieved F1 and EM scores 62.17 and 59.04 respectively.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0092", "text": "Title: Coattention, Dynamic Pointing Decoders & QANet for Question Answering\nAbstract: The task of question answering (QA) requires language comprehension and modeling the complex interaction between the context and the query. Recurrent models achieved good results using RNNs to process sequential inputs and attention components to cope with long term interactions. However, recurrent QA models have two main weaknesses. First, due to the single-pass nature of the decoder step, models have issues recovering from incorrect local maxima. Second, due to the sequential nature of RNNs these models are often too slow for both training and inference. To address the first problems, we implemented a model based on Dynamic Coattention Network (DCN) that incorporates a dynamic decoder that iteratively predicts the answer span. To improve the model efficiency, we also implemented a transformer based recurrency-free model (QANet), which consists of a stack of encoder blocks including self-attention and convolutional layers. On the Stanford Question Answering Dataset (SQuAD 2.0), our best QANet based model achieves 68.76 F1 score and 65.081 Exact Match(EM) on dev set and 66.00 F1 and 62.67 EM on the test set. A high level model comparison of DCN and QANet is illustrated in the image.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0093", "text": "Title: Default Final Project: RobustQA Track\nAbstract: Our goal is to build a question answering system that can adapt to unseen domains with only a few training samples from the domain.. We experimented with several approaches, including mixture of experts approach and various techniques to fine tune the pre-trained model better. Although we are able to to outperform the baseline, we found that model architecture is less important when it comes to improving performance. Relevant training data is by far the most important factor. Various fine tune techniques also help to some extend", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0094", "text": "Title: Robust Question Answering Through Data Augmentation and TAPT\nAbstract: In this project, we aimed to improve on the given baseline model, which is a DistilBERT pretained transformer, as much as possible in order to make it more robust to out-of-domain data for the task of QA. In order to do this, we experimented with a variety of extensions to the baseline, among which are Task-Adaptive Pretraining and data augmentation. We found that data augmentation was able to improve the results of the baseline the best out of our various attempts. Our best model performed better than the baseline by 0.287 points for the F1 score and 0.941 points for the EM score on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0095", "text": "Title: Transformer Exploration\nAbstract: In this project we we build a question answering model for the SQuAD 2.0 dataset. Beginning with a baseline BiDAF model we make two extensions to improve the model. In the first extension we add character embeddings to match the model in the original BiDAF paper. Next we swap out the LSTM encoder for, the more parallelizable, Transformer block. After creating our word and character embeddings we add in positional encodings. Next we apply a single transformer encoder block featuring convolution and self attention to the embeddings of the context and the query. We then perform BiDirectional attention, before applying three more transformer blocks in the modeling layer. Finally we output a prediction of the answer or no answer if one does not exist.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0096", "text": "Title: Extended QA System on SQuAD 2.0\nAbstract: Our motivation is to build a Question Answering (QA) system that gives answers as specific and as accurate to queries, which is in itself an art but based on the science of Natural Language Processing (NLP). The main goal of our project is to produce a QA system that works well on SQuAD 2.0 dataset that performs better than the baseline Bidirectional Attention Flow (BiDAF) model. To better capture the context from a more expressive set of answers and understand the interactions between the question and the document, we utilized the coattention mechanism by encoding the two-way attention outputs together through a bidirectional reccurrent neural network (RNN). We experimented with enriching the embedding layer with concatenating character embeddings with existing word-level embedding, modifying the attention layer with coattention from Dynamic Coattention Networks (DCN), adding an Answer Pointer, which conditions the ending of the answer span on the starting position, to the output layer. Our best performing single model obtained F1/EM scores of 63.40/59.87, which both achieved better results than the baseline. Adding character embeddings and the answer pointer gave us a successful performance boost compared with the BiDAF baseline model. On the other hand, dynamic coattention from DCN did not beat the attention and modeling layer combined in the baseline BiDAF model but was worth trying. To further improve the performance of our model, we built ensemble models which finetune on the dropout rates, and the best one achieved F1/EM scores of 64.21/60.81.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0097", "text": "Title: Character Embedding and Self Attention Mechanism with SQuAD\nAbstract: In this project, we have demonstrated the effectiveness of character embedding. According to our experiment results, adding Context2Context self attention mechanism can not improve the performance of the BiDAF model. The BiDAF model with character embedding performs well with its Context2Query attention and Query2context attention. Adding self attention to this model will include additional interference when the context words attend not only to the query words, but the context words itself, which slightly reduced the model performance. For the future work, we can add additive attention to the BiDAF model to see how it compares to the two attention implementations we use. In addition, there are plenty of modern techniques, including Transformer and Reformer, can be further explored to find the best performing model on SQuAD challenge.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0098", "text": "Title: Domain Adaptive Adversarial Feature Disentanglement for Neural Question Answering\nAbstract: Learning-based Question Answering systems have achieved significant success with the help of large language models and pre-trained model weights. However, existing approaches assume that data is drawn i.i.d from the same distribution, which violate the more realistic scenario that test-time text and questions are under different distributions. Deep networks have been used to learn transferable representations for domain adaptation, which has shown success in various vision tasks.  In this project, we study the problem of domain adaptive question answering leveraging various techniques, ranging from Data Augmentation, Layer Re-initialization and Domain Adversarial Alignment.\n\nSpecifically, we propose to use a wasserstein-stablized adversarial domain alignment scheme on the distilBert backbone with last layer reinitialized, to train on both the data-rich in-domain QA datasets and data augmented out-of-domain (OOD) datasets, following a finetuning stage on data-augmented OOD datasets. We have conducted extensive experiments to demonstrate the effectiveness of our proposed method in bringing significant performance boost for the task of domain-adaptive Question Answering.  We also conducted carefully-designed ablation studies to show the performance gain resulted from each of the proposed components. Our proposed model addresses the problem of domain-adaptive question answering from various perspectives, including data, model architecture, and training scheme. The evaluation results on the provided OOD validation datasets show that our proposed method is able to bring 8.56% performance improvement, compared to the vanilla baseline using DistilBert without any of such domain adaptive designs.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0099", "text": "Title: Data Augmentation for Robust QA System\nAbstract: In this project, we identify the trade-off between different data augmentation strategies for Robust QA System. For in-domain datasets, we need to sample the datasets first to avoid overfitting and then use more advanced data augmentation techniques, such as back-translation and abstract summary augmentation, to generate more diverge datasets in order to help the model learn the unseen data. For out-of-domain datasets, we need to use data augmentation technique that could generate similar datasets, such as spelling augmentation and synonym augmentation. Also, we need to iterate the data augmentation for multiple times in order to increase the proportion of out-of-domain datasets. The iteration number needs to be carefully designed because it may also slightly affect the final performance of the Robust QA System.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0100", "text": "Title: Improving the Performance of Previous QA Models\nAbstract: Question answering is a challenging problem that tests language processing models the ability to comprehend natural languages. In this project, we implemented two models, BiDAF and QANet, to solve the Stanford question answering dataset (SQuAD) 2.0. We experienced different methods to improve the performance of these models, including adding character embedding layers, data augmentation, and ensemble modeling. Finally, we compared the result across different experiments and gave an analysis of our models. In the end, our best model achieved F1/EM score of 68.71/65.38 in the test leaderboard.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0101", "text": "Title: Building a QA System using R-net\nAbstract: Question-answering task is an important problem for research in natural language processing, for which many deep learning models have been designed. Here we implement R-Net and evaluate its performance on SQuAD 2.0. While the performance of R-Net itself is worse than BiDAF, it showed a strong capability of its attention mechanism compared to BiDAF as shown in the image. We have also experimented with an ensemble model using BiDAF and R-Net that achieved better performance than the baseline BiDAF. Our study suggests that a promising future direction is to combine BiDAF and R-Net for building better models.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0102", "text": "Title: Robust QA System with Task-Adaptive Pretraining, Data Augmentation, and Hyperparameter Tuning\nAbstract: Despite their significant success, transformer-based models trained on massive amounts of text still lack robustness to out-of-distribution data. In this project, we aim to build a robust question answering system by improving the DistilBERT model. To accomplish this goal, we implement task-adaptive pretraining (TAPT), model tuning such as transformer block re-initialization and increasing the number of training epochs, and ensemble methods. We also use data augmentation techniques to enable the model to generalize well even with limited data in the domains of interest.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0103", "text": "Title: RobustQA: Adversarial Training with Hyperparameter Tuning\nAbstract: In this project, I used adversarial training and hyperparameter tuning to build a question answering system that can adapt to unseen domains with only a few training examples from the domain.  From a high-level perspective, there are two model architectures: the baseline model provided by the starter code and my own adversarial model.  To compare the performance of the two model architectures, I experiment with ADAM debiasing, various batch sizes, and weight decay tuning.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0104", "text": "Title: Multi-Task Learning and Domain-Specific Models to Improve Robustness of QA System\nAbstract: In CS224N course project, we develop a Robust Question Answering (QA) language model that works well on low resource out-of-domain (OOD) data from three domains. Our approach is to take the pre-trained DistilBERT model on high-resource in-domain dataset and then perform multi-task training. We implement multi-task training model that uses unlabeled text from OOD data for Masked Language Model Objective as well as labeled QA data from high-resource setting. The model jointly trains on unlabeled text and QA data to preserve the QA representation from high-resource data and adapt to low-resource OOD. We also explore data augmentation techniques such as synonym replacement, random word deletions and insertions, word swapping, and back-translation to expand our out-of-domain dataset. Finally, we use Domain-Specific Models to have separate models for different datasets and observe that we get the best result on different datasets using different strategies. As a result we achieved the score of 59.203 F1 and 42.362 EM on the test set, 54.41 F1 and 41.62 EM on the validation set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0105", "text": "Title: Building a QA system (IID SQuAD track)\nAbstract: In order to improve our baseline model, we have experimented many approaches and methods. We have started by adding a \"Character Embedding Layer\", which allows us to condition on the internal morphology of words and better handle out-of-vocabulary words. Then we have focused on improving our attention layer by trying different approaches.\nWe developed a \"Co-Attention Flow Layer\", which involves a second-level attention computation, attending over representations that are themselves attention outputs. Furthermore, we added a \"Self-Matching-Attention\" from the R-Net consisting on extracting evidence from the whole passage according to the current passage word and question information. Besides, we experimented an idea from the \"QANet\" by adapting ideas from the Transformer and applying them to question answering, doing away with RNNs and replacing them entirely with self-attention and convolution. Then, we tried a new idea consisting on adding another BiDAF layer, this layer accounts not only for the interactions between the context and question and for the ones within the context. We wanted some-how to account also for the Context-to-Context interaction, this is will provide valuable information about the co-dependence between different words in the context.\nTo put this idea into practice we have added another BiDAF layer performing a self-attention process like the one between the context and the query. The input to this layer will be the representation we get from the first BiDAF attention layer and the words context representations we get from the first encoder. The output of this layer will successfully account not only for the interactions between the context and question and for the ones within the context. This is the model that provided the highest score. We have also being experimenting with additional gates and nonlinearities applied to the summary vector after the attention step. These gates and nonlinearities enable the model to focus on important parts of the attention vector for each word.\nOur devised model \"Double BiDAF\" achieved the best score of 63.03 on the validation set. This is exceptional because we have only made a small change to the model architecture and it yielded such improvement.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0106", "text": "Title: Robust QA with Task-Adaptive Pretraining\nAbstract: It is often hard to find a lot of labeled data to train a QA (question answering) model.\nOne possible approach to overcome this challenge is to use TAPT (task-adaptive\npretraining) in which the model is pretrained further using the unlabeled data from\nthe task itself. We implement the TAPT technique to make a QA model perform\nrobustly on a task with low-resource training data by first pertaining on the larger unlabeled data set. We then fine tune the model with a smaller labeled dataset. The results are mixed. Although a preliminary model that is pretrained on just the  out-of-domain train data performed better than the baseline, additional pretraining using more out-of-domain data performed worse than expected.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0107", "text": "Title: Mixture of Experts and Back-Translation to improve QA robustness\nAbstract: This work improves the generalization of a DistilBERT-based Question Answering (QA) model with the addition of a Mixture of Experts (MoE) layer as well as through data augmentation via back-translation. QA models generally struggle to perform in contexts that differ from those present in the model's training data. As a step towards addressing this limitation, our MoE implementation effectively learns domain-invariant features without explicitly training each expert on individual subdomains. We also apply top-k sampling back-translation and introduce a new technique to more effectively retrieve the answer span from the back-translated context. We find that the addition of the MoE layer yields an improvement of 3.19 in F1 score on an out-of-domain validation set, with back-translation granting a further 1.75 in F1 score. This represents a net improvement of 10.1% over the DistilBERT baseline.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0108", "text": "Title: A Dynamic Chunk Reader with Character Level Embeddings for Question Answering\nAbstract: In 2016, Yu et. al. proposed an  end-to-end neural reading comprehension model, know as a Dynamic Chunk Reader (DCR), for question answering. In this model they chose to input word embeddings as well as several other semantic and linguistic features such parts of speech and capitalization into their initial encoding layer. A natural follow-up to this is to experiment with different inputs to the encoding layer. One possibility is to input character embeddings in addition to the word embeddings. This paper describes a model that re-creates the DCR model from scratch and the creation of a character level embedding using CNNs to feed into the DCR model.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0109", "text": "Title: Robust QA System with xEDA: Final Report\nAbstract: We present xEDA: extended easy data augmentation techniques for boosting the robustness of question answering systems to shifts in data domains. xEDA extends existing data augmentation techniques by drawing inspirations from techniques in computer vision. We evaluate its performance on out-of-domain question answering tasks and show that xEDA can improve performance and robustness to domain shifts when a small subset of the out-of-domain data is available at train time. xEDA consists of masking, extended random deletion, extended random insertion, and simple extended random insertion. We discovered that xEDA can help build a question answering system that is robust to shifts in domain distributions if few samples of out-of-domain datasets are available at train time. In particular, by applying xEDA to out-of-domain datasets during training, we were able to increase the performance of our question answering system by 6.1% in terms of F1 and by 14.9% in terms of EM when compared to the provided baseline on the dev set. Moreover, using 40% of the out-of-domain train datasets augmented via xEDA achieved the same performance as using 100% of the out-of-domain train datasets. Our analysis also suggests that an augmented data of smaller size may lead to better performance than non-augmented data of larger size in some cases. Given the simplicity and wide applicability of xEDA, we hope that this paper motivates researchers and practitioners to explore data augmentation techniques in complex NLP tasks.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0110", "text": "Title: Robust QA on out of domain dataset over pretraining and fine tuning\nAbstract: We have seen tremendous progress on natural language understanding problems over the last few years. Meanwhile, we face issues that models learnt from a specific domain couldn't be easily generalized to a different domain. I explored different models to build robust question answering system that can be applied to out-of-domain datasets. Models explored are baseline with and without fine tuning, adding dataset prefix in question with and without fine tuning, switching question and context in question answering system with and without fine tuning, and shorter question and context in model input with and without fine tuning. Different fine tuning techniques like changing epochs, batch size and Adam optimization learning rate were explored to find the best model performance. The best model achieved 40.367 EM and 58.467 F1.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0111", "text": "Title: Recurrence, Transformers, and Beam Search - Oh My!\nAbstract: Question answering on the IID SQUAD 2.0 dataset is a proving ground for natural language processing systems. In this project, we explore recurrent and transformer-based architectures for SQuAD 2.0. We implement several improvements on the baseline BiDAF and the canonical transformer QANet. Our best model, BiDAF with character embeddings and beam search output, scores F1 62.291 and EM 59.493. Finally, we suggest further directions for research in self-attention and modeling/predicting NA answers.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0112", "text": "Title: BiDAF with Explicit Token Linguistic Features\nAbstract: How do you do reading comprehension? When I learned reading comprehension with English as my second language, I was taught a few tricks. One important trick is to find word correspondences between the text and the question. Another trick is to use information such as part of speech and sentiment of known words to infer meaning of other unknown words. In this project, I explore the effectiveness of those tricks when applied to SQuAD, by supplying BiDAF with explicit linguistic features from the tokenizer as part of the input. I found that although effective at improving the scores, using those features is prone to overfitting if not regulated.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0113", "text": "Title: Building a QA system (IID SQuAD track)\nAbstract: Question answering is an intriguing NLP task, as it provides a measurement for how well the model can understand the text and perform  different kinds of logical reasoning. This project aims to build a question answering system based off BiDAF model that works well on Stanford Question Answering Dataset 2.0 (SQuAD 2.0). We examine the effect of character-level embedding, self-attention mechanism, answer-pointer, and transformer blocks. After model comparison and hyperparameter search, our best model with character-level embedding, self-attention, and GRU layers achieves an F1 Score of 63.408 and a EM Score of 60.456 on CS224N internal test set of SQuAD 2.0.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0114", "text": "Title: SQuAD 2.0 with BiDAF++ and QANet\nAbstract: In this project, we produced a question answering system on SQuAD 2.0. To enhance the task performance, we explored two kinds of models. One is baseline BiDAF model, we modified the baseline by adding character embeddings and implementing Co-Attention layers. We conducted the experiments thoroughly to evaluate the effects of each component. The other is QANet, which is a Transformer-based model, only including convolutional and self-attention layers and free of RNN component. We implemented the model from scratch and got some results during the experiments. We found our best result is from the BiDAF-related model and achieved F1 score 64.96, EM score 61.70 in validation set and F1 score 64.712, EM score 60.997 in test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0115", "text": "Title: Meta Learning with Data Augmentation for Robust Out-of-domain Question Answering\nAbstract: Natural language understanding problems has gain much popularity over the yearsand current models often has poor generalizability on the out-of-domain tasks. This robust question answering (QA) project aims to remedy this situation by using Reptile, a variant of meta learning algorithms. In this project, the primary goal is to implement Reptile algorithm for question answering tasks to achieve a better performance than the baseline model on the out-of-domain datasets. After the Reptile implementation is validated, the secondary goal of this project is to explore how various hyper parameters affect the final performance.  After we believe that the Reptile is optimally tuned, we worked on the data provided for this project. First, we merged in-domain validation dataset to the training data, then we added data augmentation to further tap into the potential of the out-of-domain training data. Training results of Reptile outperforms vanilla BERT model and Reptile with data augmentation increases the score even further. The best F1 score is 59.985 and best EM score is 42.225. If we compare the performance on out-of-domain validation dataset, scores are more than 12% and 22% higher than the baseline score respectively.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0116", "text": "Title: BiDAF with Self-Attention for SQUAD 2.0\nAbstract: The primary goal of this work is to build a QA system that improves upon a baseline modified BiDAF model's performance on the SQuAD 2.0 dataset. To achieve this improvement, two approaches are explored. In the first one, the modified BiDAF model's embedding layer is extended with character-level embeddings. In the second approach, a self-attention layer is added on top of the existing BiDAF attention layer. The performance of these two approaches is evaluated separately and also when combined together into a single model. The model with character embeddings yielded the best performance on the test set, achieving an EM score of 56.872 and a F1 score of 60.652. The self-attention model performed below expectations overall, though it was the best model when it came to performance on unanswerable questions.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0117", "text": "Title: Better Learning with Lesser Data: Meta-Learning with DistiIBERT\nAbstract: While pre-trained transformer models have shown great success in recent years, it requires a large amount of task-specific data to finetune. In our project, we have experimented with the a variant of the MAML algorithm, namely Reptile, in a low resource QA program. In contrast to the normal training procedure, MAML algorithm trains the model with a double-loop structure. In the inner loop, the program goes through meta-batches, with T tasks in each. For each of the tasks in the inner-loop, a submodel is made and updates k times. After the k descents have been made for T submodels, they are collected and processed in the Metalearner Reptile, where the next descent on the meta-model is determined. From the first glance of this training protocol, it appears to be similar to the multi-task learning model, since they both expose the model to multiple tasks, which enables transfer learning. Aside from that, one major distinction of MAML is that it makes use of the k th gradients, which enables the SGD to access higher order terms in the loss function, thereby allowing the MAML algorithm to find a better initialization than the other methods and descends at much rapid rate in any tasks in the downstream, as shown in figure (1). Furthermore, the reason MAML can find better model initialization than multi-task learning is that it can avoid overfitting to any one task, which is known to be a tendency in multi-task learning. In the end of the study, we introduce a cost-to-improvement ratio, evaluating whether the additional accuracy gain in MAML can justify the increase in runtime. Despite there is a absolute gain in the accuracy by MAML, we express our reservation in regard to the comparative advantage of MAML, since this 1 point increase in the accuracy comes at large sacrifice of runtime.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0118", "text": "Title: Answer Pointer Inspired BiDAF And QANet For Machine Comprehension\nAbstract: Imagine that you are trying to find the answer for a question given a context paragraph. This kind of tasks fall into the category of one of the hottest topics in NLP - machine comprehension. With the help of emerging high-performance GPUs, deep learning for machine comprehension has progressed tremendously. RNN based methods, such as Match-LSTM and Bidirectional Attention Flow (BiDAF), and transformer-like methods, such as QANet, keep pushing the performance boundary of machine comprehension on the SQuAD datasets. Our team proposes to improve the performance of the baseline BiDAF and the QANet models on SQuAD 2.0. We replace the original output layer of BiDAF and QANet with Answer Pointer inspired output layers and add character level embedding and ReLU MLP fusion function to the baseline BiDAF model.  We achieve significantly better performance using ensemble learning with majority voting on modified BiDAF, QANet1, and QANet3 models. Specifically, the ensemble learning achieves a F1 score of 66.219 and a EM score of 62.840 on the test datasets and a F1 score of 68.024 and a EM score of 64.561 on the validation datasets.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0119", "text": "Title: Robust Question Answering: Adversarial Learning\nAbstract: In the NLP task of question-answering, state-of-the-art models perform extraordinarily well, at human performance levels. However, these models tend to learn domain specific features from the training data, and consequently perform poorly on other domain test data. In order to mend this issue, we adopt the adversarial training approach to learn domain invariant features in existing QA models. In this approach, the QA model tries to learn hidden features that the discriminator, which tries to classify the domain of the question-answer embedding from the hidden features, unsure of its prediction, thereby learning domain-invariant features. The intuition is that if the QA model can confuse the discriminator, then the features it has learned are not easily attributable to a specific domain. The QA model's loss depends on its own errors in answer prediction (the QA loss) as well as how well the discriminator predicts domain (the adversarial loss). We study modifications this model, in particular the impact of weights on the adversarial loss on the model's performance. We also study other techniques such as data augmentation and answer re-ranking in order to make our model more robust. Our work is limited in that we only train models on a subset of the training data available to us due to the cost of training time. However, we can conclude that changing the weight of the adversarial model results in marginal changes in performance. Furthermore, although the adversarial model exhibits improvements over our baseline, data augmentation proves to be a more effective technique in making the model robust on our of domain data given the subsampled training data.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0120", "text": "Title: Importance Weighting for Robust QA\nAbstract: Machine Reading Comprehension (MRC) Questions Answering (QA) systems are commonly used within conversational agents and search engines to support users information needs while saving users the effort of navigation in documents, when the information need is a question for which the user seeks an answer. While state of the art approaches have shown to be successful for QA on a general domain, enterprise retrieval problems where the information need for QA exists in domains that are specialized and have limited or none annotated data remain open.\n  In this work we address adaptation to new specialized domains with very little training data for MRC-QA, focusing on importance weighting. We propose two features for importance weighting that are applicable for an unsupervised setting, and present preliminary results comparing importance weighting with transfer learning.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0121", "text": "Title: Question-Answering with QANet for SQUAD 2.0\nAbstract: Our task for this project is to is to design a question-answering system for the SQuAD 2.0 dataset that improves upon the BiDAF baseline model. To do this, we experiment with QANet, a transformer-based architecture. We also reintroduce a character-level embeddings on top of the provided BiDAF model, as well as a self-attention layer. Our best QANet model achieved 61.47/64.81 EM/F1 scores on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0122", "text": "Title: Combining QANet and Retro-Reader Models\nAbstract: Our task is to design a machine reading comprehension (MRC) model that can\naccurately solve question answering problems from the Stanford Question Answering Dataset (SQuAD). For our model, we aimed to 1) implement the QANet\nmodel,  which is one of the highest performing non-pretrained models, and 2)\nextend QANet with a verification module inspired by Zhang et al. (2020) to better\nidentify unanswerable questions and improve performance on SQuAD 2.0.  We\nexplored variants on both the QANet architecture as well as the Retro-Reader\nArchitecture experimenting with different values for hyperparameters and our best single model achieved an F1/EM score of 66.10/62.28 on the development set and 64.422/60.659 on the test set. We explored a variant on the Retro Reader architecture that involved training one model to always predict an answer and training a separate model that does all the answerability prediction. Despite not significantly improving the performance of the model, through our error analysis, we gained deep insights into what components degraded model performance and developed potential hypotheses for future improvements. In particular when testing the Retro QANet model, we discovered that the Intensive QANet model was prone to false negatives and false positives thus we hypothesize that the main shortcoming of our model is its reading comprehension ability. Overall, we explored the application of retro reader and verification techniques to one of the highest performing non-PCE models and experimented with parameters and the architecture.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0123", "text": "Title: QaN I have Your Attention? Exploring Attention in Question-Answering Model Architectures\nAbstract: In this project, we build non-pre-trained models for the question-answering task on the Stanford Question Answering (SQuAD) 2.0 dataset, exploring on the effect of attention on the result. We explore the performance of deep learning model architectures that utilize attention: BiDAF (context-query attention), Dynamic Co-Attention (second-level attention) and QANet (self-attention). We explored the baseline BiDAF model, and improved it through character embeddings and co-attention, as well as re-implemented QANet. We ensembled results, and obtained highest performance of F1 67.96, EM 64.41 for single model dev, F1 70.66, EM 67.87 for ensemble dev, and F1 68.39, EM 65.44 for ensemble test. We performed analysis on the single model and ensembles to better understand the model mechanisms and performance.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0124", "text": "Title: Robust Question Answering via In-domain Adversarial Training and Out-domain Data Augmentation\nAbstract: How can a Question Answering model trained on Wikipedia solve examination questions correctly? The cross-domain Question Answering is challenging since QA models are usually not robust to generalize well on out-of-domain datasets. We would like to explore the effectiveness of domain-related information on QA model robustness. We leverage potential domain information, both domain-specific and domain-invariant, from the text data. During training on the in-domain training set, we explore the adversarial training by experimenting on three adversarial functions. We add a domain classifier to distinguish different domains. Meanwhile, the QA model fools the domain discriminator to learn domain-invariant feature representations from the in-domain training set. In addition to the domain-invariant learning from the in-domain training, we also propose a data augmentation method that can retain high-level domain information by using named entity recognition and synonyms replacement. Out -of-domain datasets are insufficient and we want to utilize them most. This augmentation method is applied on the oo-domain training set and we suppose that it will let the model learn domain specific information from the out-of-domain datasets. To give better insights on our adversarial training and augmentation methods, we conducted several experiments and provide our analysis in this report.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0125", "text": "Title: Comparing Model Size and Attention Layer Design Impact on Question-Answer Tasks\nAbstract: In this project, we explore the use of various Neural Language Models applied to Question Answer tasks from the SQuAD dataset. We're specifically interested in exploring the transition from RNN-based models to transformer-based models. RNN Neural Language Models were dominant in language tasks for many years, but the introduction of the transformer demonstrated that the fall-backs of RNN models could be overcome by using architectures that optimize for larger, more parallelizable models. In this work, we compare the impacts of expanding model size with the impact of changing attention layer implementations using a Bi-Directional Attention Flow baseline model. We find that model size has a significantly greater impact on model performance on the SQuAD dataset, but larger models fail to improve performance on unanswerable question-answer examples.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0126", "text": "Title: Pretraining of Transformers on Question Answering without External Data\nAbstract: Can recent Transformer-based pretraining approaches still perform effectively on question answering without external data and large computational resources? We find that an ELECTRA-style MLM objective can significantly reduce the computational cost of pretraining, and the train-test discrepancy can be reduced by using a small vocabulary size and question augmentation. These methods can boost the F1 score of a Transformer model on the SQuAD 2.0 task from (far below) 52.2 to just over 60.4 on a development set. However, the Transformer model relies mostly on textual similarity between the question and context, rather than on language understanding, to predict answers. The model still performs worse than a baseline BiDAF model, suggesting that the ability of current state-of-the-art training objectives and model architectures to learn effectively from limited data is still severely lacking. We hope that future methods, even with a general model architecture and objective, are able to perform well in a low-resource setting, and that this should also lead to approaches that learn more quickly, effectively, and generally by learning patterns, rather than correlations, that capture the meaning of language", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0127", "text": "Title: Data Augmentation: Can BERT Do The Work For You?\nAbstract: Data augmentation has been proved effective in analyzing a neural model's robustness and improving it by re-training with augmented data. Because text data's discrete feature space, most data augmentation techniques require querying multiple systems for language knowledge and meticulous augmentation rule design by researchers. This paper aims to explore the effectiveness of an automatic, black-box data augmentation method using language models, bert context rewriter, and to compare it with another augmentation algorithm, token reorderer, which uses Universal Sentence Encoder's semantic knowledge.  Given a baseline question answering model, we employ DistilBERT masked language model (mlm) to rewrite masked context data and evaluate whether re-training with the augmented data can improve the robustness of the baseline model. This augmentation relies on the existing language knowledge learnt by DistilBERT mlm and does not use additional hand-crafted rules. We also explore how different configurations, including masked token percentage and additional mlm fine-tuning, affect our method's effectiveness. Preliminary experiments show that both our methods obtain improved performance on out-of-domain dev set over the baseline and reduce the performance gaps between in-domain and out-of-domain datasets. However, token reorderer's performance is consistently better than bert context rewriter's in both out-of-domain evaluation (+2.9 F1/+2.9 EM versus +1.9 F1/+1.6 EM) and reducing in-domain out-of-domain gaps (-5.3 F1/-4.8 EM versus -1.7 F1/-2.5 EM) and therefore is more effective in improving the baseline model's robustness.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0128", "text": "Title: RobustQA Using Data Augmentation\nAbstract: This project aims to explore possible improvements and extensions to the RobustQA Default baseline provided by the CS224N Winter quarter staff. Our goal is to create a domain-agnostic question answering system given DistilBERT as a pre-trained transformer model. The main method attempted in this paper is that of Task Adaptive Fine Tuning (TAPT), which entails a pre-training step utilizing the Masked Language Modeling task. This method was combined with experimentation on hyperparameters (batch size, number of epochs, and learning rate) to produce the highest-achieving model. Specifically, a pre-trained MLM model with a batch size of 32 yielded an EM of 42.75 and F1 of 61.14, which are each around 2 points higher than the baseline metrics.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0129", "text": "Title: More Explorations with Adversarial Training in Building Robust QA System\nAbstract: In real world Question Answering (QA) applications, a model is usually required to generalize to unseen domains. It was found that an Adversarial Training framework where a conventional QA model trained to deceive a domain predicting discriminator can help learn domain-invariant features that generalize better. In this work we explored more discriminator architectures. We showed that by using a single layer Transformer encoder as the discriminator and taking the whole last layer hidden states from the QA model, the system performs better than the originally proposed simple Multilayer Perceptron (MLP) discriminator taking only the hidden state at the [CLS] token of the BERT QA model.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0130", "text": "Title: Probability-Mixing: Semi-Supervised Learning in Question-Answering with Data Augmentation\nAbstract: The probability-Mixing method proposed in this project consists  label guessing and label interpolation.  : We need to prepare three types of data for this semi-supervised problem: labeled data, mixed data, and unlabeled data. If we have labeled data \"The project is too hard\". We first use GLoVE to find similar words and replace them with something like \"That work is super difficult\", which is our unlabeled data. Then for each word, we randomly select either from word from both data and have \"That work is too difficult\". Then we can linearly interpolate the labels for the mixed data for both mean square loss and cross-entropy loss. In this project, our experiments demonstrate that sequential order information does not necessarily help query-context matching, and excessive sequential order information in BiDAF's RNN can lead to overfitting. To alleviate overfitting and add more variety to the training samples, we propose four data augmentation methods without introducing non-negligible label noise, which improves the F1 scores of BiDAF and the QANet with 8 heads by at least 2 points. We also propose the Probability-Mixing method to prevent the model from memorizing the context, which significantly improves its ability in query-context matching. This method reduces the FPR from 0.3 to 0.18 and increases F1(TP) by 4 points for the QANet model, making it a much better model in preventing the generation of misleading information for the question-answering system.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0131", "text": "Title: Gated Self-Attention for SQuAD Question Answering\nAbstract: Machine comprehension and question answering are central questions in natural\nlanguage processing, as they require modeling interactions between the passage\nand the question. In this paper, we build on the multi-stage hierarchical process\nBiDAF described in Seo et al. (2017)'s Bi-Directional Attention Flow for Machine Comprehension. We utilize tools from the R-Net model described in R-Net:\nMachine Reading Comprehension with Self-Matching Networks, testing different\ncombinations of model components. We experiment with different types of encoding, such as using a Gated Recurrent Unit (GRU) or a Convolutional Neural\nNetwork (CNN), and attention mechanisms, such as comparing context-query\nattention layers and contemplating the usage of gates. We ultimately introduce a\nmodified form of BiDAF which utilizes both an LSTM and a CNN in its encoding\nlayer, as well as BiDAF's context-query attention layer followed by R-Net's self-attention layer. We conduct various experiments on the SQuAD datasets, yielding\ncompetitive results on the CS224N SQuAD Leaderboard.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0132", "text": "Title: The Unanswerable Gap: An Exploration of Approaches for Question Answering on SQuAD 2.0\nAbstract: In this project, we implemented models that were trained and evaluated using the Stanford Question Answering Dataset (SQuAD). For a majority of our models, we incorporated character-level embeddings in order to strengthen the system's understanding of the semantics and syntax of each context and question. Our implementations fall into two main categories: modifying the baseline Bidirectional Attention Flow (BiDAF) model and implementing the Dynamic Coattention Network from scratch. We found that the baseline BiDAF model with character-level embeddings performed the best and received an EM/F1 score of  61.771/65.089 on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0133", "text": "Title: Self-attention and convolution for question answering on SQuAD 2.0: revisiting QANet\nAbstract: QANet was the first Question Answering model that combined self-attention and convolution, without any use of Recurrent Neural Networks. Convinced by the \"Attention is all you need\" motto (or, more accurately in this context, the \"You don't need RNNs\" motto), we were naturally interested in seeing how this applies to the specific task of Question Answering. In this project, we therefore tackle the Question Answering task on the SQuAD 2.0 dataset using different variations of the QANet architecture. We first re-implement the QANet model, and then explore different versions of the architecture, tweaking some parameters such as attention mechanisms and model size. We then propose 3 ensemble models with different inference methods: our best model, using a novel two-step answerability prediction based inference method, achieves 71.21 F1/ 68.14 EM on the development set, and 69.04 F1 / 65.87 EM on the test set.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0134", "text": "Title: Exploration of Attention and Transformers for Question and Answering\nAbstract: The project was intended to be an exploration of convBERT model without pretraining,\nbut after training a base BERT model (encoder only Transformer) and\nachieving very low performance, the objective shifted towards trying to understanding\ntransformers and attention for Question Answering. Experiments on both\nhyperparameters and network architecture was done on the BERT model, with\nconclusion that this model will either overfit, or not converge. A hypothesis is\nsuggested that without large corpus pretraining, simple self attention on a concatenated\ncontext and question has big difficiencies vs explicit cross attention to learn\nSQuAD. QAnet model was also trained for purposes of comparisons and analysis.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0135", "text": "Title: Building a Robust QA System\nAbstract: The robustness to domain shifts is very important for NLP, as in real world, test data are rarely IID with training data. This NLP task is to explore a Question Answering system that is robust to unseen domains with few training samples. In this task, three out-of-domain datasets show very different characteristics and they are trained with different in-domain datasets which are more beneficial for their challenges. Multiple transfer learning models are mixed in different ways: mixture of logits, mixture with custom output, and mixture with more features. Three majority vote strategies were taken to ensemble the models.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0136", "text": "Title: Attention-aware attention (A^3): combining coattention and self-attention for question answering\nAbstract: Attention has been one of the biggest recent breakthrough in NLP, paving the way for the improvement of state-of-art models in many tasks. In question answering, it has been successfully applied under many forms, especially with recurrent models (encoder-decoder fashion). Co-attention and multihead self-attention have been two interesting attention variations, but a larger study trying to combine them has never been conducted to the best of our knowledge. Hence, the purpose of this paper is to experiment different attention-based architecture types for question answering, as variations from one of the first successful recurrent encoder-decoder models for this task: BiDAF.  We implement a variation of the attention layer, starting with a multi-head self-attention mechanism, on both the query and the context tokens separately, as provided by the encoder layer. Then, these contextualized tokens, added to the input tokens through a skip connection, are passed to a trilinear cross-attention and used to compute two matrices: a context to query matrix and a context to query to context matrix. These two matrices are concatenated with the self-attended context tokens into an output matrix. In addition, we provide our model a character embedding, which proves to have an important positive impact on the performance, as well as a conditional output layer. We test the performance of our model on the Stanford Question Answering Dataset 2.0 and achieved a performance of EM = 62.730 and F1 = 66.283 on the dev set, and EM = 60.490 and F1 = 64.081 on the test set. This provides +7.26 EM score and +6.95 F1 score compared to our coattention baseline, and +4.72 EM score and +4.97 F1 score compared to our BiDAF baseline.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0137", "text": "Title: Improve DistilIBERT-based Question Answering model performance on out-of-domain datasets by Mixing Right Experts\nAbstract: In this work, we built a MOE model by mixing 7 DistilBERT-based QA expert models that are task-fine-tuned on in-domain training datasets. We built data insight by carefully examining performance correlation across in-domain datasets and out-of-domain datasets and found out domain-fine-tuning on small target out-of-domain dataset that has quite different distribution than in-domain training dataset does not necessarily translate into out-of-domain performance on target dataset. We carefully select a set expert models for each out-of-domain set by leveraging data insights aforementioned. We achieved F1 score of 61.7} (ranked 6th out of 74 in test leaderboard) and EM score of 44.4 (ranked 2nd out of 74 in test leaderboard) in out-of-domain test datasets as of March 19, 2021.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0138", "text": "Title: Improved Robustness in Question-Answering via Multiple Techniques\nAbstract: Question-answering models are one of the most promising research areas in NLP. There has already been much study and development on how to accurately search for the correct answer of unanswered questions when the question is in the training domain. The usage of pretrained language models, such as ELMo, GPT, BERT, etc., enables knowledge gained from pretraining to be transferred to the new model. Although some models might outperform human performance for in-domain data, when it comes to out-of-domain data, they have poor performances. For the real world applications, we want a QA model to be able to both cover various domains and generalizes well on the out-of-domain data, hence the idea of domain generalization is proposed. For most of the current QA models, additional data is required to learn the new domains, and models tend to overfit on specific domains. Since it's impossible for a QA model to train on all domains, it's crucial to apply different techniques to build domain-agnostic QA models that can learn domain-invariant features instead of focusing on the specific features when there's limited training data.\n\nIn this project, we are given three types of in-domain datasets: SQuAD, Natural Questions, NewsQA, and three types of out-of-domain datasets: DuoRC, RACE, RelationExtraction. By reading through papers, we've learned different techniques, such as adversarial training, data augmentation, task-adaptive pretraining, etc., that might help with domain generalization. We first apply them individually on the given baseline model, DistilBERT, compare their F1 and EM scores, and analyze their performances. Then, we apply several combinations of the techniques, and further explore the performances of their combinations. Eventually, the task-adaptive pretraining model gives us the best result, an increase of 2.46 in F1 score, and an increase of 3.92 in EM score compared to the baseline.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0139", "text": "Title: QANet on SQUAD 2.0\nAbstract: QANe\u00e9et achieved the state of the art prior to BERT on the SQUAD 2.0. The project aims to reimplemement QANet based on a model from the Attention is All You Need paper. We also revised the provided BiDAF model by adding a character embedding layer. We find that with the character embedding layer, BiDAF model is significantly improved, and we show that ensembling the QANet and BiDAF model can evidently improve the performance on the SQUAD 2.0 dataset.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0140", "text": "Title: Multi-Phase Adaptive Pretraining on DistilBERT for Compact Domain Adaptation\nAbstract: While modern natural language models such as transformers have made significant leaps in performance relative to their predecessors, the fact that they are so large usually means that they learn small correlations that do not improve the model's predictive power. As a result, such models fail to generalize to other data, thus hampering performance in real-world cases where data is not independently and identically distributed (IID). Luckily, the use of domain-adaptive pretraining (DAPT), which involves pretraining on unlabeled target domain data, and task-adaptive pretraining (TAPT), which entails pretraining on all of the unlabeled data of a given task, can dramatically improve performance on large models like RoBERTa when the original and target domain distributions have a small amount of overlap. Consistent with the Robust QA track of the default project, this report investigates and tests the hypothesis that TAPT in tandem with DAPT (also known as multi-phase adaptive pretraining, or MAPT) can improve performance on the target domain for smaller transformers like DistilBERT on the question answering task, especially in the presence of domain shift. The final results show that the use of TAPT can lead to a slight increase in Exact Match (EM) performance without DAPT. However, implementing DAPT, even with the use of word-substitution data augmentation, significantly degrades the performance of the model on the held-out target domain dataset.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0141", "text": "Title: QANet+: Improving QANet for Question Answering\nAbstract: In this work, we build a question answering (QA) system and apply it on the Stanford Question Answering Dataset, version 2.0. Our goal is to achieve strong performance on this task without using pre-trained language models. Our primary contribution is a highly performant implementation of the QANet model. Additionally, we experiment with various modifications to this architecture. Most notably, we show that modifying the output layer, such that answer span's ending position prediction is a function of the starting position prediction, yields significant improvements over the original design. Using a QANet ensemble, we reach an F1 score of 71.87 and an EM score of 68.89 on an unseen test set (rank #1 out of 100+ submissions to the test leaderboard for the IID SQuAD Track of CS 224N at Stanford, Winter 2021).", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0142", "text": "Title: Robust Question Answering System\nAbstract: Pretrained models like BERT achieves good performance when we fine-tune it to resourceful QA tasks like SQuAD. However, when we apply the model to out-of-domain QA tasks with different question and passage sources, the performance degraded badly. We discovered that the domain change in passage source is the main contributor to worse performance. We investigated ways to improve robustness of pretrained QA systems by experimenting on different optimizers, freezing and re-initializing model layers during training. We found that AdamW is the best optimizer for training on out-of-domain QA datasets, and freezing just the embedding block of DistilBERT improves model performance the most.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0143", "text": "Title: Augmenting BiDAF with Per-Token Features\nAbstract: The DrQA document reader showed that adding per-token features (e.g. part-of speech and  named entity recognition tags) to a question answering model significantly improves performance on the SQuAD benchmark. I add six features to a baseline BiDAF model and explore the benefit of applying attention to not only LSTM hidden state, but also these per-token features. I verify the benefit of applying self-attention to these features and find that the augmented model significantly improves upon the baseline in terms of metrics and train time. My best model achieves a test score of (62.06 EM, 64.89 F1) compared to a baseline of (59.33, 62.09), reaching an optimal model in half the training steps.", "source": "CS224N", "is_esl": false}
{"id": "cs224n_0144", "text": "Title: Improving Robustness of Question-Answering System Using Domain-adaptive Pretraining, Adversarial Training, Data Augmentation and Finetuning\nAbstract: From previous work, we know that Question-Answering (QA) system based on neural language models (NLM) is highly sensitive to the knowledge domain of training data and often has inferior performance when used for out-of-domain QA tasks. In this project, the authors attempt to combine a few published methods to improve the robustness of the QA system on out-of-domain data. We have tried methods including domain adversarial training, domain adaptive pretraining, finetuning on few samples, and data augmentation. We applied these methods through experimentation, improving the robustness of our baseline model on out-of-domain test datasets given two groups of training datasets: three large in-domain datasets and three very small out-of-domain datasets. We experimented and evaluated the effects of the above-mentioned methods both individually and combined, and found that while the individual method generates mixed results, the combination of them can improve the robustness of the baseline model in the QA task to the greatest extent on the out-of-domain datasets. We have also included a qualitative analysis of our results, shedding some light on the real capabilities of our model.", "source": "CS224N", "is_esl": false}
{"id": "college_0000", "text": "Contrary to popular belief, mini-golf is very challenging. The unforgiving, neon green turf and the jagged rock formations send my ball spiraling in the wrong direction and careen straight into the roaring waterfall every time. The irony of my inadequate skills, however, is not lost on my younger sister, who routinely avoids obstacles and sinks her ball straight into the hole. Her embarrassing victory dance follows soon after, much to my own dismay. Notwithstanding my mini-golf shortcomings, I am known as \u201cgolf girl\u201d by my peers and have learned much about myself and the game as the sole girl on my high school\u2019s golf team. Growing up hearing tales of the golf team that my father coached and watching the LPGA from my grandfather\u2019s couch instilled me with a passion for golf. Looking up to Annika S\u00f6renstam and other talented women who played with such grace and power ultimately gave me some dynamic, passionate role models to look up to. When the coach cut me from middle school golf tryouts, bright purple junior clubs in hand, I was determined to get better and committed to making myself and my role models proud. I began taking over 100 swings each night and spent countless hours on the putting green dreaming of that match winning putt. After being turned away, the sense of accomplishment in being one of the team\u2019s leaders in the following season was one of the best feelings in the world. For the past six years, I have become accustomed to the mannerisms, smell, and humor of teenage golf boys. However, arriving at the first match brimming with four teams full of tall, strong boys and not another girl in sight made me gulp. The shorter bathroom line was a bonus when I first arrived at the course, but all was forgotten when I went to take my first shot from the female tee box. My teammate, James, walked up to me, noticing my apprehension, and told me the most random, bizarre joke that I had ever heard. In that moment, I knew my teammates had my back, even if I did not always completely comprehend their humor. Over time, the team grew into a tight-knit group of friends who fit together like a puzzle. James can break a bad round with a laugh, Matt gives the best pep talks, and Drew is reliable for sound shot advice, while my niche emerged as bringing positivity and optimism after a bad shot. This team dynamic continued in school as well, as James comes to me after a bad test, while I see Matt before a big presentation. Whether we are on or off the course, we help each other to succeed. As the daughter of two teachers, country club simulators and memberships to the area\u2019s elite courses were not options for me. Two summers ago, I took matters into my own hands and got a job cleaning out dirty carts and taking out the trash at the local country club. Scrubbing the spilled adult beverages out of the cup holders and disposing of the deteriorating cigars was not how I pictured spending my summers, but was valuable for the free rounds I played. By the end of the summer, I realized my hard work leveled the playing field between myself and my more affluent opponents. This gentleman\u2019s sport has become such a significant part of my life. The amount of joy I receive from sinking a lengthy putt or driving my ball straight down the center of the fairway reminds me just how grateful I am to play this sport. My sister might still dance in the parking lot after we play a round of mini-golf, I will join her, because I know that I will continue to play golf, and learn from the game, for the rest of my life.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0001", "text": "\u201cHow many times did I wake up at 4:15 a.m. this summer?\u201d I found myself once again asking this question as I climbed endless stone steps with bruised shins and dirt-filled fingernails. The answer: twenty-two times. I was in a rush to finish the 48th peak before school began in order to fulfill a goal I set in fifth grade after meeting a wild pack of Appalachian Trail through-hikers. I marveled at their determination. Climbing all 48 four thousand foot peaks within New Hampshire is an ambitious goal that takes some people a lifetime to finish. There I was, at 6:15 a.m., gasping for air and wondering who I should blame for the pain. Maybe I had my parents to blame for my drive to be in the wilderness. They exposed me to the outdoors at a young age, sparking my passion for hiking and backpacking. Having lived in China for four and a half years and traveling the world, I always knew my childhood was unique. Unlike other expatriates, my family dismissed four-star resorts and instead chose to stumble through the alleyways of Hong Kong with an array of camping supplies. As a six-year-old, I was fortunate enough to find myself in Italy running from a wild herd of cattle in the Alps. During our summers in Oregon, instead of renting a car, we pedaled through the hilly streets on a three-person bike. These experiences, that made my family different, instilled in me a sense of adventure. The 48 strenuous climbs and endless miles also brought beautiful vistas. If we were lucky, we got to end the day at a high mountain hut where we drank endless cups of rich hot chocolate. I would sit in the corner of the dining room engrossed in books about rare lichen. At Mizpah hut, I had the chance to talk with a female naturalist about some of the endangered alpine flora. I sat and stared in awe. I didn't know that someone could have a job doing field studies in the mountains. I\u2019ve spent the last six years looking at the sides of the trails for the dwarf Cinquefoil she introduced to me. That\u2019s when I knew I wanted to become a hands-on environmentalist so I could spend more time doing the things I love. Maybe I have the naturalist to blame for all the blisters and early mornings on the trail.        Mount Isolation was my last peak. One last push. Number 48. 13.6 miles. After the first grueling thirty minutes, the path opened up and I could see all the way to the Atlantic Ocean. This is the way it always goes. First, the struggle, and then the reward. Mt. Washington glowed like amber. The wind nipped at my fingertips and shook the crooked trees. My heavy breathing competed with the sounds of the white-throated sparrows. I had the entire mountain to myself. Overwhelmed by emotion, I began to cry bittersweet tears. No more waking up at 4:15 a.m. but then again, no more celebratory Cokes at the top. I was done. I decided to let go of the blame for all the early mornings. Instead, I would love to give my fifth grade-self a big \u201cthank you\u201d.        The struggles only augmented the joy I felt on the car ride home with music playing and my feet wiggling in the wind. I felt that I had graduated from my childhood. Hiking over the past seventeen years with my family has created endless memories, yet it's time for me to start a new chapter of my life. Maybe I\u2019ll hike the Adirondack 46ers, explore sections of the Appalachian Trail, or guide others through the wilderness. But I know I will always continue to look around and search for rare specimens and marvel at the ordinary.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0002", "text": "The ground beneath me began to shake as an oil truck instantly burst into flames. A massive ball of fire flared into the sky, illuminating my awestruck eyes. Suddenly, hundreds of gallons of water rushed down onto the truck, safely extinguishing the blaze. \u201cCUT!\u201d a director yelled. I cheered, astonished by the scene I had just witnessed.        My love for Hollywood began with moments like these from my childhood. Disney\u2019s Hollywood Studios was home to attractions like The Great Movie Ride and The Studio Backlot Tour, both of which introduced me to the special effects, intricate illusions, and thrilling stunts seen in professional films. These two attractions were early indicators of my love for filmmaking, I just didn\u2019t know it yet.        Years later, I am still captivated by the magic of cinema. Whether it be a summer blockbuster, an Oscar-hopeful, or a cult classic, I\u2019ll take any opportunity I can get to experience an original film. For a few hours, I can forget about the world around me, becoming completely immersed in the universe on-screen. Characters come alive, their personalities and stories intertwining themselves with real-life experiences of my own. I\u2019ve always been what you would call a \u201ctomboy\u201d, a far-from-fragile girl who loves football and loathes dresses. Having strong female characters like Hermione Granger and Princess Leia to look up to on-screen has had a profound impact on my confidence as a young woman. Seeing another woman hold her ground and stand up for herself was truly inspiring to me. I may not wield a wand or a blaster, but I\u2019ve certainly used the strength of these characters as a personal inspiration to stay confident and secure in myself.        My passion for film does not end with characterization. I am just as invested in the technical, behind-the-scenes aspects of cinema. Cinematographers bring stunning landscapes and perfectly-framed shots to life, invoking awe and emotion in both casual moviegoers and film fanatics. Lighting designers shape a film\u2019s mood and tone, adding flares of emotion and rich symbolism to climatic scenes.        I still have so much to learn about filmmaking, and I cannot wait to tackle the challenges that come with producing a film. When I do, I know that I\u2019ll put my heart into it. Maybe my protagonist will defy the stereotypes that surround young women, choosing jeans over skirts and football over dance. Maybe she\u2019ll love brisk autumn mornings, and never understand the appeal of hot, sticky, summer afternoons. Maybe she\u2019ll discover her peculiar affinity for both science and cinema. Whichever direction I decide to take my characters and my story, my life experiences will have a huge impact on the final product. This is yet another thing that I love about movies; they are entirely unique to the individual who creates them. No two people could create the same exact film no matter how hard they tried \u2014 there\u2019s always a little bit of a director\u2019s soul woven into their work.        I\u2019m still unsure whether I\u2019ll follow my passion for film into a full-time career or a part-time hobby. If I decide to pursue filmmaking, I hope to use my platform to spread a message of hope, perseverance, and strength. Films can reach millions, possibly even billions of people, giving me the perfect opportunity to make a profound impact on someone\u2019s life. If just one person can be inspired by one of my characters, much like I was by Hermione and Leia, I\u2019ll be satisfied. Even if I never sell out theaters or break a box office record, I will have achieved success if I can make someone\u2019s life just a little bit better through my work. Through filmmaking, I hope to invoke the same sense of wonder and awe that I once felt as I experienced the magic of cinema for the very first time.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0003", "text": "These days, birds are losing the battle of favored domestic animal to dogs and cats. At best, they're an easily forgotten blot in the otherwise clear sky, and at worst, they're nasty pests associated with filth and disease. But for many years, birds were something much greater, the catalyst of folklore and tales for nearly every culture around the world.         We've all heard some iteration of a bird story before: Common characters you might recall include the wise owl, mischievous raven, vain peacock, and motherly hen. I was introduced to these stories early on, first captivated by the avian parables I listened to on CDs, and they became an integral part of my early years. I can still remember proudly reciting \"The Ant and the Magpie\" word for word to my parents, an important tale reminding listeners to save resources for a time in need, represented by the winter in the animal world. As I got older, my love for birds persisted, but the influence those childlike stories had on me waned. After all, none of my classmates proclaimed their love of dogs stemmed from a Danish fairytale or Chinese folklore. I figured the reason I loved birds was shallower: I enjoyed the startling, colorful plumage and the joyous calls I heard outside my window. No longer were birds a central part of my identity; instead, they became an answer when I had to state my favorite animal during a summer camp icebreaker.        It wasn't until I was well into high school, nearly a decade after I last closed the cover, that I found one of my favorite childhood books, \"Why Snails Have Shells,\" in the depths of my closet. Rediscovering this book reminded me of the importance I placed on the lessons I learned from the cherished bird characters. Leafing through the pages and rereading the familiar stories, I realized the straightforward teachings of the birds were more relevant to my current life than they ever were in my childhood. Birds once again were not simply my favorite animal, they guided the way I reacted in challenging situations, which - like for most of my peers - came in a barrage as I got older.        The lesson that permeates my life today is from an old Chinese proverb, famously summed up by poet Maya Angelou as \"A bird doesn't sing because it has an answer, it sings because it has a song.\" High school life, especially for my generation, is hyper-focused on the approval of others. Instagram is littered with polls asking if outfits are \"ok,\" popularity is measured by the average number of comments you get in response to your posts, and every joke uttered is followed by a scan of the room to make sure at least someone is laughing. Contrastingly, the bird doesn't focus on the answer it receives from its song; in fact, it doesn't even expect an answer. The bird sings because it wishes to, because of the joy it experiences when doing so.        It can be easy to get swept away in the desire to please, but the personal mantra I've adopted reminds me of the importance of doing things for the sake of making yourself happy, not others. I build relationships I genuinely value, I invest my time in activities I love to do, and I express myself in ways that bring me joy. Although the stories and proverbs I learned when I was younger originated from distant times and places, they have woven themselves into my values and shaped me into the person I am today.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0004", "text": "YouTube taught me everything, from simple tasks I was too insecure to ask about- such as how to correctly toast bread- to what defines me now, being a dancer. I remember one night, I was sitting on the guest room rug with my small Samsung phone, looking up videos. Trying to learn how to do a coffee grinder, a breakdance move. I remained there an hour, tirelessly attempting to learn this one move\u2014 that every break-dancer made seem so easy\u2014over and over again. After the extensive and what seemed to be an infinite hour. I did one, jumping up and down in the air with jubilance. I instantly went down for a second attempt, breaking the shackles of failure with maximum momentum. I continued, proceeding counter-clockwise, moving with a kind of elegance that can only be associated with a mindset for success. The rush of excitement blinded me, ending up in smashing the leg of the table. My mom rushed in frantically; she noticed the broken table. A look of disappointment is all I took away from that night. The shackles were fastened back on.        Growing up, I did not have much to pride myself on. All I could do was dream, imagine, and fantasize. Dream of being other people. Dream of being an incredible dancer. Dream of being an astounding drummer. Dream of being an amazing computer scientist. Dream of being anything at all, but myself. I began my late passion for dancing when I was 12. There was only one thing stopping me from starting early\u2014the shackled opportunities I was given. The opportunities for which I longed to be tangible, I could only dream of. Instead, I was left with nothing of the sort. I had to just teach myself with practice and mere experimentation. That is the root of my art. I only had YouTube to teach me the things I know today. It was a tough road. It still is a tough road. Nothing is changing.        I am faced with the challenge of competing against people from all around the world for the same position: people that have tutors, classes, workshops, equipment, and the opportunity to travel abroad to learn what they love. I stayed home and worked. I worked twice as hard to obtain only half the expertise they were able to acquire. I worked without aid, gripping onto my drive: the drive to show the world that you can make anything out of nothing.        Going into King\u2019s as a freshman was difficult, working with my first dance teacher; Mr. Ryuji Yamaguchi, who introduced me to styles of dance that are shameful in Arab culture. He encouraged me to experiment with all elements limitlessly. Months passed by with the Annual dance concert approaching slowly; practicing until the night was upon me. It was time. Time to show the worth of working from nothing but your own passion, time to break the shackles. From contemporary duets, group pieces, hip-hop solos, and Bollywood, I danced my heart out and completed the show with immense success. In the intense moment of the final bow of the show, in which emotions were already running high, I caught a glimpse of my mother\u2019s eyes: her hazy, teary eyes and a divine smile accompanied by the repeated motion of clapping. I came to the realization that the fight was decisively over, the shackles finally demolished. I was fazed. I still am. It is all borne in my head now. Utopia can be found in art. It is the most rewarding work anyone can do, working hours over hours to create something beautiful, something that was ceased to exist until created by you. After all the energy you have has been invested into expressing your thoughts and ideas, you have the sweet satisfaction of being able to finally take a step back, peruse, and say with pride, \u201cI created this\u201d.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0005", "text": "Like most teenagers, I am expected to do household chores I would rather avoid. I do my share of feeding the dogs and mowing the lawn, but growing up in a two hundred and thirty-four-year-old tavern has meant that my experiences and responsibilities go well beyond the usual fare\u2014like when I discovered my cats meowing and leaping at two chimney swifts that had fallen down the fireplace and were frantically circling my room. Once, during a Nor\u2019Easter, I woke up to find that snow was blowing through the seams of the house\u2019s original window panes. I swept up the little, swirling drifts on my bedroom floor, taped up the windows, and went back to bed. It was in times like these that I was just a bit envious of my friends\u2019 newer, weathertight homes, but deep inside, I knew I would not trade sleeping in extra layers in my quirky, old Harvard, Massachusetts home for any other place.        Since my parents bought it as a fixer-upper, I am often recruited to work on projects like glazing windows, spackling sheetrock, and painting rooms. This past summer, I begrudgingly agreed to help repair the mortar joints in the fieldstone foundation of our basement. I hauled an eighty-pound bag of cement and mixed it with water into a peanut butter-like consistency. I grabbed a gob from the wheelbarrow and got to work stuffing it into the deep crevices between the jumble of stones, troweling it smooth and brushing it to create a finished texture. The hours spent working, much of it on my hands and knees, gave me a lot of time for self-reflection. Undisturbed by text messages or buzzing FaceTime requests, I allowed my mind to wander to the far reaches of my imagination in the quiet solitude of the cellar. Sometimes I reflected on what I should have said in a conversation with a friend, thought through an argument around a current political issue, or pondered ways to frame my essays for summer reading assignments.        Working with my hands, I appreciated the art of forming and sculpting the cement into place, realizing that it was just as creative a process as writing, editing and reworking my essays and poems. It was an iterative and tiring process to get it right. Dripping with sweat, the grinding physical effort from having to work quickly before the cement hardened mirrored my exhaustion in a race I had rowed in last year\u2014 although the weather conditions had been very different. At the Head of the Fish Regatta, I had rowed for three miles through the cold, driving rain, facing a fifteen miles-per-hour headwind\u2014feeling as if my arms and legs were on fire\u2014in order to finish.        Good mortaring requires technical precision, speed and strength. I needed to mix the mortar in the correct proportions; work carefully so I did not miss any gaps; and most of all, I needed to persevere, working until the entire wall was repointed. Eventing requires a similar mastery of multiple skills in order to succeed in the three distinct phases of competition. In dressage, my buckskin horse Eli and I needed to work together as one, in calm precision and balance; in show jumping, we needed the focus and technical skills to count strides and launch at the right moment; and in cross-country, we needed the strength and endurance to gallop several miles over fences, across ditches, and through water obstacles.        Whether handling a bucket of wet cement or a green horse, I recognized that having the patience and determination to keep improving despite hardship, tedium or discomfort was essential to reach any mental or physical goal, be it winning a competition, writing an essay or rebuilding a wall. Standing back from the finished fieldstone wall, I basked in the accomplishment\u2014not just of finishing the chore\u2014but of discovering the zen in the art of mortar maintenance.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0006", "text": "The air thickened with red dust as I walked into the basement of Washington Studio School for my first sculpting class - a way to be creative after a stressful day. As I pulled back a thick curtain to enter, I looked around the room, examining the surfaces, all covered in a thin layer of that same dust. The bookshelves behind me were sporting a small collection of sculptures.        We were given a 4\u2019 by 6\u2019 block of clay to mold into a woman that was sitting in front of us. I stared at the block of clay, unable to imagine how to start. The woman next to me immediately started shaping her rust-colored slab. She took clumps from the bottom of the piece, adding it to the top, taking pieces away to form shoulders and arms. I spent more than an appropriate amount of time watching her work. I was amazed by the way she could see the woman inside her block of clay.                I turned back to my sculpture and gingerly shaved off a piece of clay from the top corner. I continued to work at that corner and that corner only as my instructor travelled around the room, visiting each of his students to offer tips and suggestions. When he made it to my table, he glanced at my piece. I had transformed the 4\u2019 by 6\u2019 rectangular prism into a pentagonal prism. He took one of my tools and started shaving away clay and suggested that I remove even more. He continued to visit the rest of his students as I continued to shave miniscule pieces of clay off of my now hexagonal prism.        I wanted to act on his advice, I wanted to take this opportunity to learn, but I did not want to do something wrong. I was afraid of the permanence of my choices. This fear continued to hold me back throughout the 3-hour lesson. By the end of the class, rather than my piece looking like the model sitting in front of me, my piece looked like Mario from the 1985 Super Mario Bros. I left the class, wondering when I started letting fear control my actions.        I remembered that I used to quite literally jump into new situations. The first time I went on a chair lift, for example, I had been so excited to \u201chit the slopes\u201d that instead of waiting for the chair lift to reach the end, I leaped off 8 feet too soon. Luckily, my dad caught me and held onto me until we reached the end of the lift.        The next week, I was determined to reclaim that feeling of fearlessness to make progress on my sculpture. This time, I took out clumps, rather than slithers. When my instructor reached my table, he pointed to plenty of problems with my piece. The arm was too high, the legs looked like a yeti\u2019s, and the head took the shape of a balloon. But I realized that at least I was doing it \u2014 and I was enjoying it, too.        My final piece was in no way a replica of the model who sat in front of me during those lessons: it was riddled with errors. But, while the person I was when I first entered the classroom may have hated the fact that she could see all the mistakes in her final structure, I now appreciate that I can see them, and that I can see how far I\u2019ve come since making them. No matter how deep under the surface of my sculpture the mistake might be, I know it is there. Every crack, air bubble, slip and score, is a working component in my sculpture. And I know that, like my sculpture, I\u2019ve been shaped by my mistakes, too: as long as I want to keep becoming myself, I\u2019ll need to keep making them.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0007", "text": "Had I written this essay three years ago, I would have written with utmost passion about my desire to be a cardiologist. I would have shared that cardiology had lifted the veil placed on my eyes to blind me from my true essence - saving lives. I would have continued to share that it exhibited two of my most accented strengths: my attention to detail and my ability to value each person if though their soul was a reflection of my own. However, most importantly, I felt it was my destiny to grant others what my mother\u2019s cardiologist had granted her: a healthier and rejuvenated life. It is three years later and I do not have a desire to be a cardiologist. The dream I had for cardiology was solely a fabrication of what I believed to be most just. I have a way with words, and I am lyrical. My sweet symphonies are the essence of my being, yet I am not an aspiring songwriter nor am I an aspiring musician. I am a writer. With each word I craft, a part of my soul lives on beyond my years. It turns out that the magic of my words was so powerful, my soul had been deceived. For years, I had been writing about cardiology and science as though the letters c-a-r-d-i-o-l-o-g-y were coursing through my blood, and were tattooed to my heart. Dreams consisted of me writing novels of my career as a cardiologist, sharing my encounters and experience of being a cardiologist. My love for writing had become so pronounced that the passion I had been composing with was mistaken as a passion for cardiology. As a child, I never acknowledged writing as anything more than a hobby. When I would put pen to paper I would solely describe it as just writing. It was never just writing. It was my life; it is who I am. Despite my undying love for this artform, I would tell myself that cardiology was what I wanted, even with the distance and disconnect I felt with cardiology. Regardless of how scholarly and recognized cardiology is, I had felt as though I was settling. However, that all changed. It was a single sentence that unlocked the volta of my life\u2019s story: If you do something you love, you never have to work a day in your life. This sentence, which I heard from an advisor, redirected my thoughts from who I was to who I wanted to be. It was in that moment that my initial thought was not of cardiology, it was of an image of life beyond its limits and a world of wonders, pen to paper, and the flight of young Lorena\u2019s dreams. It was an image of writing. I had always feared that no one would understand my love for writing, nor the bond I had formed with writing. When speaking with a person who does not possess my same passion, it\u2019s as though our conversation is not a conversation at all, but rather a sharing of different languages. They cannot grasp the idea that writing is not solely descriptive language, it is not \u201cred, yellow, blue,\u201d as my aunt would describe it. Writing is the core of my being. It is engraved in my soul. Without it, I would not exist. Writing could never restrain me, because the one thing it offers me that nothing else in the world ever could was the ability to not only think however I wanted to think, but to also be whatever I wanted to be. I had begun a story I had praised for ten years of my life; it was a story I thought I knew the words to like the back of my hand, but the words had drifted and my dream of cardiology had become blurred by my true love and destiny - becoming a writer.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0008", "text": "Piece by Piece: Building My Reality At this point in my life, I am used to the chuckles I receive upon telling my friends that I, in fact, love Legos. Growing up in a house of four children was a hectic environment to say the least; an escape from the chaos of siblings was much needed. As a kid, sitting down and concentrating on one task was never my intention, rather I was constantly energetic, chasing and being chased by my siblings. Building Lego sets had always been a way to minimize any stressors that were going on at the time, or to simply relax and enjoy the challenge. My first Lego set was given to me at a very young age, my seventh birthday, and although excited, I was puzzled with what I was supposed to accomplish. I knew that Luke Skywalker was going to need a little more assistance than I could offer at that age, so after countless hours of struggling and persisting, I inevitably succumbed to the numerous offers of help. Each birthday and holiday moving forward, I requested Legos in order to perfect my ability, and each time I gained expertise. Finally, I encountered my own \u201cEureka!\u201d moment, individually completing my first kit, a miniature replica of the Seattle Space Needle, solely on willpower and sheer excitement. My worn, but comfortable bedroom floor had become my safe haven for letting my mind wander and to create sculptures I would have never thought of if it hadn\u2019t been for my obsession with those miniscule, plastic blocks. I hadn\u2019t usually been the most creative, artistic person; however, when I sat down in my room next to my collection and freed my mind, I suddenly become an artist of my own definition. Soon, as I got older, more unique ideas for pieces flooded my mind rather than following strict instructions. These ideas had resulted in the possibility of designing and constructing certain buildings and entities, of course without any real-world consequences. My bedroom floor eventually turned into a skyline resembling that of New York City, skyscrapers grazing the top of my bed and Rockefeller Center spanning from my desk to my closet. Arriving home late from school or a strenuous practice, I was relieved to lay down next to my meaningful, personalized city. I rarely construct Lego structures nowadays; however, my obsession with those tiny bricks embedded a passion in me that will never cease to follow me. Arriving to a boarding school as a first-year student, I was extremely hesitant and nervous. Though I would soon be a part of a team, I sought an escape from my anxiety of being away from home and especially my bedroom. Though I hadn\u2019t brought along any of my Legos, (I\u2019m sure you can imagine why), I signed up for a new class which taught the basics of ceramics and sculpting figures. Ceramics was an entire new entity to me and I enjoyed every second of it. I had been constructing simple bowls and plates to ease myself into the new medium I was using. Soon, however, I became more confident and adventurous with my designs. After hours in the studio at school, I ultimately transferred my projects back to my personal studio, my bedroom, to join the company of my surrounding Lego projects. Not only providing me with entertainment, Legos left an everlasting mark on my capacity to experiment with new endeavors I would rarely attempt. Legos hold a special place in my mind and my heart due to the effect they have had on my curiosity, creativity and overall optimism. I will continue to design my sculptures, my essays, and my future, which is certainly guided by my imagination. Having constructed those guided, age appropriate sets and eventually designing unique pieces, I developed a knack for sculpting and imagining brand new ideas I transfer into my everyday life.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0009", "text": "Hurricane Maria devastated Puerto Rico, and my Massachusetts city had also been torn apart. In a city where nearly half of the population is Puerto Rican, the destination of people fleeing the island had immediately come into question, \u201cWhy are they coming here? Our schools already don\u2019t have enough books for our students, never mind Puerto Rican refugees.\u201d These are words out of my French and Irish uncle\u2019s mouth. As he looked in my brown eyes and proclaimed his son\u2019s lack of an AP English book was more important than the life and well-being of a child that looks like me. It is enlightening to begin to take notice of the ignorance that surrounds your identity. It is eye-opening to hear words of hate and intolerance spew from the mouths of people you love, people who claim to love you. I have heard people express how they really feel when they forget about my dark complexion and let a joke slip, to follow up with, \"Well not you, you're not really Puerto Rican.\" To be seven years old and shrouded in a feeling of discomfort for who you are; making an effort to sound and act \u201cwhite\u201d among my white family and friends. Thanksgiving with my blue-eyed and freckled cousins was an event that displaced me. My Abuela\u2019s house was where my Puerto Rican cousins flourished. They spoke fluent Spanish and shook their heads when I asked what they were saying. I \u201cdidn\u2019t care\u201d about my culture to them. It is in this limbo that I find myself more aware of the dubious eyes on me when I\u2019m asked if I am Muslim or Italian (as if Muslim is an ethnicity). When they compliment my \u201cdifferent\u201d name, their eyes widen when they learn that I am from the \u201cwhiter\u201d side of the city, but nod in understanding when I clarify that my Mother is white. I notice that these glances are consonant with the fact that the grocery store I work at in the neighboring town made thousands of dollars in their donation cups for Hurricane Harvey victims, but not one mention of Puerto Rico\u2019s disastrous conditions. It is from these glances that I realize both these adversities are not of equal importance to the store where I was one of four Hispanic employees. I am Puerto Rican and Irish and French and Polish and all these backgrounds have allowed me to see unique perspectives, but they are not a single definition of me. I am a daughter, a student, a friend, a sister. I am everything I love and every book I've read and all the people I've helped and all the places I've traveled. I am all of my passions and the closed minds I intend on opening and the thirst for life I intend on quenching. I have grown up with a feeling of exclusion from both sides of my heritage, yet in the process of fighting for a sense of belonging I have embraced myself for more than the color of my skin or the accent of my father. My identity is so much more than an uncomfortable glance from a person who can't place my nose with a nation. I am more than a prejudice comment. What I have truly come to understand by living at the intersection of two very different situations is how ignorance develops so easily from not being able to empathize. My white uncle will never know what it is like to be a minority. He will never feel the stares I have felt, he will never be called a spic, he will never be disadvantaged for his light complexion. It is only when people place themselves as close as possible to the reality of others do they begin to rid themselves of the subconscious prejudices our society places upon us.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0010", "text": "I began measuring my life in flipped pages, packed boxes, and school maps when I was 6. As my family and I flitted between states and coasts for my father\u2019s job over the last decade, I shielded myself with fantasy novels. With my head propped on the baseboard near my nightlight and a book held up in front of me by aching arms, I would dance in whimsical forests, fight daring battles, and rule dangerous courts long after dark. In my fantastic universe, I could take turns being the queen, the knight, the hero, and even the villain. These books helped me express the happiness, anger, sadness, and queerness I could not have even begun to imagine alone. The characters I discovered in novels as I toured libraries and Barnes & Noble stores in strip malls around the country taught me resilience and empowered me to nourish my strengths. Mare Barrow showed me the power of determined women, and I unapologetically strove for academic excellence and obtained a GPA of 4.4. Tane, from The Priory of the Orange Tree, inspired me to push the limits of my own body, so I\u2019ve traversed approximately 1,544 miles in cross-country races and practices. Evelyn Hugo\u2019s unapologetic character compelled me to want to embrace and feel free with my queerness rather than shelter it away in a shameful corner. Even further, this year I am adding a third dimension to my love of fantasy by interpreting Mrs. White in my school\u2019s production of Shuddersome and The Monkey\u2019s Paw with assistance from Anne of Green Gables, my first fictional idol, who massively influenced my personality and tendency for dramatics. But above all, Leigh Bardugu, my favorite author, gave me permission to even dare to write and to dream that I can. What began as a safety net in my adolescence has grown to something more, a true passion for English and all that it can express. Language is power and I wish to wield it like a mighty sword. I want to be the puppetmaster, the speaker, and the leader in a world that is crafted in ink. I want to be a New York Times bestseller and to know that whatever I do is impactful and that it creates a difference, no matter how small. I want to walk down a crowded street and see \u201cmy book\u201d spread open in a passing person\u2019s hands, as they refuse to put it down, just like I did so many times in the hallways of my middle school. A writer, a college professor, a publishing lawyer: I want it all, the riots of failure, and the pride of success. Without the assistance of literature, I wouldn\u2019t be who I am today. If I hadn\u2019t grown up fueled on library hauls I wouldn\u2019t have discovered that I love English. I wouldn\u2019t get shivers when I fret for a favorite character or celebrate their triumphs, be as ready to face obstacles, or be as adventurous as I am. Without the moves around the country and back, I wouldn\u2019t have become so resilient and open to change, so adaptable to life, but most importantly I wouldn\u2019t have become so in love with language. With every move I burrowed in books, and with every book I became me. Literature has made me in every way, and the only way I can repay it is to become the penman.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0011", "text": "I dreaded their arrival. The tyrannical cicadas swarmed DC and neighboring areas in 1987, 2004, and again in 2021. I was freaking about Brood X, the worst of them all. Brood X is a cluster of cicadas that descend on Washington, D.C., every 17 years. I live in the epicenter of their swarm. Cicadas battled with mosquitoes for first place in the top tier of the human annoyance pyramid. I hate these off-brand cockroaches. For 17 years, cicadas live underground feasting off of sap, running free of danger. Then, they emerge and face the real world. That sounds familiar. I have lived in the same house, in the same town, for 17 years, with my parents feeding me pasta and keeping me safe. Is it conceivable that I have more in common with cicadas than I previously thought? Cicadas have beady, red eyes. After a year of enduring Zoom classes, attending tele-health appointments, and spending too much time on social media and video games, I too feel a little blurry-eyed and disoriented. But what about their incessant hum and perpetual noise? That is not me. OK, maybe I do make protein shakes with a noisy blender at all hours of the day. Maybe I do FaceTime vehemently with friends, blare music while I shower, and constantly kick a ball around both inside the house and out. At least I do not leave damaged wings, shedded skin, or rotting carcasses everywhere. Smelly soccer socks on the clean carpet after a long practice? Check. Pools of turf in the mudroom after sliding all over the field? You got it. Dirty dishes and trail mix stains after accidentally sitting on a mislaid M&M are hardly as abhorrent as cicada remains, right? The more I reflected, the more I realized these bugs and I are more alike than different. After 17 years of being cooped up, we are both antsy to face new experiences. Of course, cicadas want to broaden their wings, fly, and explore the world, even if it means clumsily colliding into people\u2019s faces, telephone poles, and parked cars. Just like I want to shed my skin and escape to college, even if it means getting lost on campus or ruining a whole load of laundry. Despite all my newbie attributes, I am proceeding to the next phase of my life whether I am ready or not. Only the hardiest of cicadas survive their emergence and make it to trees to mate, lay eggs, and ensure the existence of their species. I want to be a tenacious Brood X cicada. I will know what it means to travel into the wrong classroom before getting laughed at, bump into an upperclassman before dropping textbooks everywhere, fail an exam after thinking I aced it. I may even become the cicada of the lecture hall by asking a professor for permission to go to the bathroom. Like cicadas, I will need time to learn how to learn. No matter what challenge I undergo that exposes and channels my inner-cicada, novice thought process, I will regroup and continue to soar toward the ultimate goal of thriving in college. When I look beyond our beady red eyes, round-the-clock botherment, and messy trails, I now understand there is room for all creatures to grow, both cicadas and humans. Cicadas certainly are on to something ... Seventeen years is the perfect amount of time to emerge and get ready to fly.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0012", "text": "I was born to two moms. One, my biological mom, Meredith. One, my mom who adopted me, Mary. Because they were a same-sex couple, the law required that Mary adopt me in order to be my parent. They used Sperm Donor 3311. All I know about my \u201cfather\u201d is that he didn\u2019t have a familial history of cancer, he has a twin brother who is 6'4\", and he studied math in school. This is all background information; I don\u2019t even know his name. He doesn\u2019t know mine, nor does he know that I even exist. People often ask \u201cWhat does your father do for a living?\u201d and I\u2019m forced to respond \u201cI actually have two moms,\u201d triggering reactions like that of my driving instructor, \u201cOh, well that must be different.\u201d I\u2019m 17-years-old and still don\u2019t know how to respond to these comments. When I was 5, Mary, who had been sick for a long time with leukemia, passed away, and my life was turned upside down. I was old enough to understand grief, and yet I still question why it happened. It was terrifying seeing my mom break down while saying, \u201cMom died last night.\u201d I wonder what I missed out on and carry guilt that I don\u2019t remember much about Mary, because we just didn\u2019t have enough time together. Many say grief gets easier with time, however, I think the way you grieve just changes over time. The world kept spinning and, in 2011, my biological mom met another woman, who soon became my stepmom. However, to me, Kerry is also my mom. No longer do I reveal the fact that I have two moms; now I get reactions to the fact that I have three. Not knowing my father doesn\u2019t leave a void in my life. \u201cDad\u201d didn\u2019t sing \u201cthere was an old lady who swallowed a fly\u201d and tickle me when the old lady swallowed the spider, my moms did. He didn\u2019t take me to Gunpowder Friends Meeting where I shook hands and spent time with 80-year-old friends from the retirement home, my moms did. He didn\u2019t console me when I began crying at the dry-erase board at school because it reminded me of white boards Mom wrote on when she was unable to talk. He didn\u2019t teach me that love is love. He didn\u2019t teach me who I was becoming, my moms did that. I\u2019ve never known my father or that I was supposed to have one, so why would I think my life is any different from the so-called \u201cnorm?\u201d If there\u2019s one thing I have learned from my parents, it\u2019s that I have developed a love for difference. I openly accept all those around me and excitedly anticipate the relationships that I will build in my future. There is no such thing as a normal family structure, and my upbringing has given me that greater world view. My moms have raised me to believe that I can accomplish anything. There are still limits, though. My family chooses not to travel to Jamaica because we aren\u2019t accepted there. Before each family vacation, we must research to see if it is a gay-friendly place. I don\u2019t know the answers to questions about my dad\u2019s side of the family. But I don\u2019t let those kinds of things get to me because instead I can talk about the people who raised me. The world is changing as we speak. \u201cNormal\u201d is fading, but it has already disappeared for me. I don\u2019t want anything different than the family I have, and I own that every day", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0013", "text": "\u201cThe difference between an anti-personnel and an anti-tank mine is not that complicated,\u201d I am told casually, in halting Russian, by a boy even younger than I am during a walk through the Chechen mountains. I am freshly 14 and visiting my father\u2019s homeland for the first time, unfamiliar with the harsh realities that kids half my age already know ironclad. My guide points out the areas where the grass is overgrown and the fruit trees abundant. People and animals alike know to avoid them; someone has learned of landmines the hard way. It shouldn\u2019t surprise me \u2014 the scars of war on this rugged country are omnipresent \u2014 but it is so jarringly different from my life in London that it is nevertheless hard to digest. It also differs from my father\u2019s rosy stories about his childhood in Katyr-Yurt, stories that made me wish to swim carefree in icy rivers, devour handfuls of fresh sour cherries straight from the tree, and see nights dense with stars. I still experience these beauties of place, but my eyes are now open to the less romanticized parts, both enriching and complicating my connection to my family\u2019s past. Suddenly, too, I am made uncomfortably aware of the conflicting layers of my familial identity. It is the Russian of my Muscovite, Jewish mother that I grew up speaking at home. Yet the Chechen children speak in broken Russian, and the grownups who are more fluent in it are not keen to communicate in the enemy\u2019s language. Seeing the ugly scars of war, both physical and psychological, I cannot help but feel like an intruder, ashamed not only of my Russianness but also of my city-boy naivete. Despite this shame, I yearn to discover what it means to be Chechen, to see their home through their eyes, and through this desire, I begin to feel a deep connection all of my own to this beautiful, fraught land. In Moscow, my new awareness of conflicting identities only intensifies, but now on account of the maternal side of my heritage. Relatives there largely see Chechens as terrorists and raise an eyebrow when they hear where I have spent my summer. Babushka\u2019s neighbour, a nurse who witnessed the carnage from the theatre siege in Moscow, turns away disgustedly when she overhears me relate the beauty of the mountains and the notable generosity of the people. Once again, I register the fear and distrust of \u201cthe other\u201d that reigns in the more homogeneous cultures in Russia, making me appreciate the diversity of London all the more. When I return there, I cannot slip back into life as normal as I have done after past summers. I find myself pondering the question of identity and the way people interpret their own past, informed just as much by collective emotion and memory as by fact. The cosmopolitanism of London is just as I remembered it, but the things I loved about it I now see in a new light. I had always revelled in the fact that, despite our differences in heritage, my peers and I had seen each other as the same \u2014 bound together by being Londoners first and foremost. Now I am interested in conversations that I would never have considered previously, wanting not only to share my newfound experiences but also learn about the personal histories of my friends, many of whom, like me, are the children of immigrants to the UK. When did they come to explore and interrogate their own complicated identities? How did these discoveries make them feel? What does it mean to carry the stories, the poetry, and the pain of so many places within them? Questions like these, which were so important for me to answer about myself, also became a powerful place from which to understand more deeply the people around me and the complex world we share.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0014", "text": "I know that I had prepared well for this moment. For two arduous months, I readied my fingers for an exciting concert. No anxiety could undermine my confidence in my preparation, and my piano recital\u2019s success was \u201cin the bag.\u201d I selected three pieces for my repertoire: the ambience of Erik Satie\u2019s Gymnopedie No. 1 as the opener, a somber contemplation of Beethoven\u2019s First Movement of the Moonlight Sonata, and Bach\u2019s light and surreal Prelude in C Major for the conclusion. My shining moment arrived, and I strode purposefully toward the piano. The building in which my performance was held was new, but its dwellers were old. Respect and prestige permeated the atmosphere as I took each stride to my seat. As I sat down, the chair creaked and moaned as if in sympathy with the audience\u2019s aching desire to hear me play. I prepared my sheet music and commenced my epic moment. Never was such an exhilarating performance heard. All of the little techniques and tricks that I practiced were executed perfectly. I captured the dynamics I wanted to express in Satie\u2019s phonological experiment with each chord to which I applied varying pressure. Moving onto one of Beethoven\u2019s most famous works, I crafted the cascading arpeggios of each new chord, which resonated unity uninterrupted in me and in the audience. When I concluded with the airy prelude from Bach\u2019s Well-Tempered Clavier, the room swelled with bliss. Having poured my heart and soul into each piece, I beamed with pride. As customary for a stellar show, I rose to bow to the audience to thank them for their eruption of applause. Flowers were thrown, cheers elicited, and standing ovations bestowed. From the subsiding din came a faint question to rain on my parade: \u201cCould you play something more lively, darling, say, a Neil Diamond song?\u201d I work on weekends at a long-term-care facility, and my geriatric audience, although a pleasure with whom to interact, can be brutally honest. Begrudgingly, I thanked Mrs. Hersch for her request, promised her better next time, and stewed in my own irrelevance. Going home that day, my feathers were ruffled. How could any civilized listener, after such a superb medley, disregard such time-honored compositions? The notion was absurd. Yet perhaps more outlandish, as I later acknowledged, was my visceral reaction to the events that had transpired. Why did I react hesitantly to a simple request made in earnestness? It would have been easier, in fact, to practice \u201cSweet Caroline\u201d than to break my fingers over Beethoven\u2019s work. Then, in my moments of introspection, I concluded that my choice of musical pieces mattered little as long as my audience enjoyed them. Whether it meant recreating the most tortured and heinously composed pop song or a masterfully crafted Romantic concerto, I vowed to play them all. Throughout my life, my adult mentors have succored me with platitudes when most needed, which laid the foundation for my confidence. Yet, while working with people who have lived five times longer than I have, experiencing so much more than I can imagine, I know that the world does not revolve around my tastes and interests. I\u2019m okay with that. Thus, for a couple of hours each day in the living room, unlucky family members passing by are subjected to the torment of my tenth run-through of \u201cSweet Caroline\u201d as I prepare for my next recital for an audience that has taught me more about personal preferences, and myself, than I anticipated.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0015", "text": "I have never felt such palpable emotion, such profound grief emanating from a space, as I did while hiking through the forest fire scorch in Philmont, New Mexico. A universe had once existed under the protection of these Ponderosa Pine, now black and crusted, turning brittle in the wind. It was a landscape that didn\u2019t sing its laments, but whispered of its loss through every pile of scalded timber and skinny, wavering shadow cast by the hollow towers of ash. I felt prepared when I made the decision to become a scout. I love nature and camping. I love the Scouts BSA program. I love the people. I was definitely not prepared, however, for the numerous challenges I would face during my years as a scout. I was the first female \u201cboy scout\u201d in my town, which continues to be both my greatest honor and a constant reminder of the isolation and insecurity that comes with being any \u201cfirst.\u201d I became a symbol, whether for good or bad, and my actions not only spoke of me, but of the future young women in Scouts BSA. I felt like an imposter. I wasn\u2019t a strong-willed leader like those who usually have \u201cfirst\u201d stitched into their title. My seventh-grade acting career did little to veil a shy and insecure girl who crumbled at overheard comments on how I didn\u2019t belong or how girls like me were poisoning BSA\u2019s spirit. As time passed, I found myself waiting to develop the toughened heart that the leaders that I knew held. As my troop and I backpacked in Philmont Scout Ranch this past summer, my doubts and insecurities seemed to echo from this inky forest. Coming from Pittsburgh, I had expected the kind of desert with raspy air and coat hanger cacti. Nothing quite shattered this expectation as much as putting on my last pair of dry socks before the fourth day of downpours. We navigated steep cliffs and vibrant meadows, and pulled ourselves up peak after peak. As the sun set on one of our final evenings, the flat, mountain-ornamented horizon gave way to a modest footpath, daring into a new forest. This forest, differing from the field of burnt pines we had seen prior, had burned several decades ago. The fire had cleared everything and had left its signature singed onto the bottom 10 feet of every tree. The forest floor was clean. Wild grasses with accents of purple and blue flowers blanketed the ground below the pines like snow, which had fallen while the world was asleep, completely untouched and extending to infinity. Above the burnt limbs of the trees, thick bundles of green needles soared into the sky. Not long after Philmont, I was awarded my Eagle Rank, the culmination of my experience as a scout. I believe that my time in Scouts BSA has been the first to the forest that is my life. Though scars remain from my experience, new change and strength have flourished out of the damage. I have come to the conclusion that it is not always the fierce leader who becomes a \u201cfirst.\u201d It is the extra hours. It is finding a way to listen to criticism and try harder, rather than feel the thorns. It is using one\u2019s own feeling of isolation to see others who feel alone. It is the act of going through the fire and staying with it, allowing it to advance you, which changes people who dare to be a \u201cfirst\u201d into the leaders that they go down in history as being. As I think back on my experience in Philmont, the first forest we saw, this blackened graveyard, is what I picture. I remember the charcoaled ground so vividly, but more so, I remember the soft purple wildflowers hidden in the desert soil. Though few and far between, against the grieving timber, they were stars.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0016", "text": "I\u2019m 6. The sounds of hornpipe and laughter drift across the gymnasium-turned-cafeteria-turned-auditorium. Mum caught me dancing to some of her old Irish tapes \u2014 the Chieftains, Sinead O\u2019Connor. She asked me if I wanted to do it for real. I said sure and went back to dancing. Now a freckled woman digs around in a cardboard box and pulls out a pair of dusty, worn black shoes. \u201cDon\u2019t worry,\u201d she says, \u201cyou\u2019ll learn eventually.\u201d The shoes are too big; they sag at the toes. I approach the stage. Twenty-five pairs of eyes fix on me. In a room bustling with motion, everything stands still. It doesn\u2019t matter that I feel like a clown in an ill-fitting costume. All that matters is the dancing. I\u2019m 9. I sit in the hallway of the Times Square Marriott watching girls in big wigs and sparkly dresses run around, squawking like glamorous, unhinged chickens. In my tartan skirt and simple bun, I feel like an ugly duckling. The bobby pins dutifully securing my bun in place make my scalp ache. My hands slide to my shoes. They\u2019re too tight. Mum put them on her feet to \u201ctry and stretch them out a little.\u201d I pass some over-enthusiastic dance moms who put the \u201cmother\u201d in \u201csmother.\u201d I reach the stage. A hundred pairs of eyes fix on me. In a hotel bustling with motion, everything stands still. It doesn\u2019t matter that I\u2019m out of place. All that matters is the dancing. I\u2019m 12. My brain won\u2019t stop flipping through disastrous scenarios as I stand with my teammates in a hotel in Orlando, Florida. We\u2019ve trained for months, sacrificed everything for this moment. I try to think of happy things: the pride on Dad\u2019s face when he watches me dance, the freedom of flying across a stage on invisible wings. We recite our steps like a poem, the sequences like a song that carries us through an ocean of fiddles, pipes, and drums. My parents sacrificed a lot to send me here. I want to make them proud. I want to make myself proud. We approach the national stage. A thousand pairs of eyes fix on me. In a world bustling with motion, everything stands still. It doesn\u2019t matter that I feel like a fraud. All that matters is the dancing. I\u2019m 15. An Irish accent lilts through the ballroom of the World Championships. It sounds like mashed potatoes and Sunday bests and the green hills of home that I know so well. We mutter a prayer. I\u2019m not sure I believe in God, though I should. I look at my partner and wish we were more than friends. She smiles. I don\u2019t think God believes in me. We ascend the stage. A million pairs of eyes fix on me. In a universe bustling with motion, everything stands still. It doesn\u2019t matter that I\u2019ll never be enough. All that matters is the dancing. I\u2019ll be 18. Murmuring voices will hover in the air of the gymnasium-turned-cafeteria-turned-auditorium. A little girl will approach me timidly, wearing a very old tartan skirt. I\u2019ll reach out softly, adjusting her bun to soothe her aching scalp. Then, I\u2019ll slide my hands toward her feet, toward a pair of small, dusty shoes. \u201cYou\u2019ll learn,\u201d I\u2019ll say. They\u2019ll sag at the toes, but I\u2019ll reassure her: \u201cDon\u2019t worry. You\u2019ll grow into them.\u201d Then, she and I will look at my own beloved shoes. They\u2019ll be worn, but I\u2019ll tell her the creases are like a map, evidence of the places I\u2019ve been, the heartbreaks I\u2019ve suffered, the joy I\u2019ve danced. My life is in these shoes. We\u2019ll hear the music begin to play, the tide of fiddles, and pipes, and drums. I\u2019ll take her hand and, with a deep breath, we\u2019ll climb the stage. \u201cAhd mor.\u201d It won\u2019t matter that this is the end. All that has ever mattered is the dancing.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0017", "text": "The black void descends toward the young girl standing in the grassy field. It slowly creeps up on her, and as it reaches for her perfectly white dress \u2026 Swipe. I quickly wipe away the paint without a thought except for panic. Before I realize what I have done, the black droop becomes an ugly smear of black paint. The peaceful picture of the girl standing in the meadow is nowhere to be seen. Even though I successfully avoid having the spilled paint touch the dress, all I can focus on is the black smudge. The stupid black smudge. As I continue to stare at the enemy in front of me, I hear Bob Ross\u2019s annoyingly cheerful voice in my head: \u201cThere are no mistakes, only happy accidents.\u201d At this moment, I completely disagree. There is nothing happy about this, only frustration. Actually, there is one other emotion: excitement. Don\u2019t get me wrong; I\u2019m not excited about making a mistake and definitely not happy about the accident. But I am thrilled at the challenge. The black smudge is taunting me, challenging me to fix the painting that took me hours to do. It is my opponent, and I am not planning to back off, not planning to lose. Looking back at the painting, I refuse to see only the black smudge. If lacrosse has taught me one thing, it is that I will not be bested by my mistakes. I snatch my picture and run downstairs, carefully setting it against the living room window. The TV newscaster drones in the background, \u201cCalifornia continues to be engulfed in flames as the fires continue to burn.\u201d I slowly step back from my painting. California fires, I think, as I look up into the blood-orange sky. California Fires! I look at the painting, imagining the black smudge not as a black void, but smoke creeping up on the girl as she watches the meadow burn. I grab my painting and run back to my room. The orange sky casts eerie shadows as I throw open my blinds. My hands reach first toward the reds, oranges, and yellows: reds as rich as blood; oranges as beautiful as California poppies; yellows as bright as the sun. I splatter them on my palette, making a beautiful assortment of colors that reminds me of one thing: fire. A rich, beautiful, bright thing, but at the same time, dangerous. My hand levitates toward the white and black. White, my ally: peaceful, wonderful, simple white. Black, my enemy: annoying, frustrating, chaotic black. I splat both of them onto a different palette as I create different shades of gray. My brush first dips into red, orange, and yellow as I create the flame around the girl. The flame engulfs the meadow, each stroke of red covering the serene nature. Next is the smoke, I sponge the dull colors onto the canvas, hazing over the fire and the trees, and, most importantly, hiding the smudge. But it doesn\u2019t work. It just looks like more blobs to cover the black smudge. What could make the gray paint turn into the hazy clouds that I have been experiencing for the past several days? I crack my knuckles in habit, and that\u2019s when a new idea pops into my head. My calloused fingers dip into the cold, slimy gray paint, which slowly warms as I rub it between my fingers. My fingers descend onto the canvas, and as they brush against the fabric, I can feel the roughness of the dried paint as I add the new layer. As I work, the tension from my body releases. With each stroke of my fingers, I see what used to be the blobs turn into the thing that has kept me inside my house for weeks. As I lift my last finger off the canvas, I step back and gaze at my new creation. I have won.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0018", "text": "Walking down a busy street, I see the quick glances and turned heads. The murmurs and giggles trickle toward me. I try to ignore the buzz, interspersed with, \u201cOh my God!\u201d and the occasional, \u201cDamn!\u201d Then, a complete stranger asks for a picture, so I stand with people foreign to me and politely smile and laugh. After the click of the camera, they go on their way. Sometimes I wish I weren\u2019t so tall. Maybe then I could take a friend to a movie and just blend into the crowd. Attention from strangers is nothing new to me. Questions about my height dominate almost every public interaction. My friends say my height is just a physical quality and not a personality trait. However, when I reflect on my life, I realize that my height has shaped my character in many ways and has helped to define the person I am. I learned how to be comfortable in my own skin. If I had the introverted personality my older brother had in high school, I\u2019d probably be overwhelmed by the constant public attention. Even as a young child, parents at the sidelines of my baseball games, as well as the umpire, would, in front of all my teammates, demand by birth certificate to prove my age. I grew acquainted early on with the fact that I am abnormally tall and stick out about the crowd. It\u2019s just the way it is. Being self-conscious about it would be paralyzing. I learned how to be kind. When I was younger, some parents in my neighborhood deemed me a bully because I was so much larger than children my age. I had to be extra welcoming and gentle simply to play with other children. Of course, now my coaches wish I weren\u2019t quite so kind on the basketball court. Even More Essays That WorkdI learned humility. At 7 feet tall, everyone expects me to be an amazing basketball player. They come expecting to see Dirk Nowitzki, and instead they might see a performance more like Will Ferrell in Semi-Pro. I have learned to be humble and to work even harder than my peers to meet their (and my) expectations. I developed a sense of lightheartedness. When people playfully make fun of my height, I laugh at myself too. On my first day of high school, a girl dropped her books in a busy hallway. I crouched down to her level and gathered some of her notebooks. As we both stood up, her eyes widened as I kept rising over her. Dumbfounded, she dropped her books again. Embarrassed, we both laughed and picked up the books a second time. All of these lessons have defined me. People unfamiliar to me have always wanted to engage me in lengthy conversations, so I have had to become comfortable interacting with all kinds of people. Looking back, I realize that through years of such encounters, I have become a confident, articulate person. Being a 7-footer is both a blessing and a curse, but in the end, accepting who you are is the first step to happiness.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0019", "text": "\u201cYou should scrub off the top layer of your skin whenever you lose a round,\u201d my debate teammate once advised me. \u201cThat\u2019s not practical,\u201d I replied. \u201cNeither is your refusal to wear clothes you\u2019ve lost important debate rounds in. Your wardrobe has very little to do with your success.\u201d Half of me disagrees with him. I still bring three BIC Round Stic pencils with 0.7 lead to every test because my gut tells me this fastidious procedure raises my scores. I\u2019m still convinced that labs receive better grades if written in Calibri. And I still won\u2019t rewear clothes in which I\u2019ve lost crucial rounds. Yet the other half of me is equally dismissive of my own superstitions. I love logic, never failing to check that steps in a proof lead to a precise conclusion without gaps in reasoning. Fortunately, I often abandon my penchant for pragmatism to accommodate for my unwarranted superstitions. And since I only feel the need to act logicalcally in selective situations, I am perfectly content with the illogical nature of my other habits: Raised with my great-grandmother, grandparents, and parents all under one roof, I never lacked a consultant to help me transcribe Korean holiday dates from the lunar calendar onto my schedule. Yet whenever all four generations of my family celebrates with a traditional meal of bulgogi, my untraceable and admittedly nonexistent Italian blood flares in protest; I rebelliously cook myself linguine con le vongole that clashes terribly with my mom\u2019s pungent kimchi. If I plot a graph of \u201chours I spend in physical activity\u201d versus \u201cweek of the year,\u201d the result looks like an irregular cardiac cycle. The upsurges symbolize my battles with colossal walls of water in hopes of catching a smooth surf back to Mission Bay shore. The ensuing period of rest mirrors the hours I spend researching in that one spot in my debate team\u2019s war room that isn\u2019t covered in papers (yet), or at the piano sight-reading the newest Adele song. Then the diastolic tranquility is interrupted by the weekends when I\u2019m sprinting through trenches to avoid paintballs swarming above my favorite arena at Paintball USA. I find comfort in the familiar. I treasure the regular midnight chats with my brother as we indulge in batter while baking cupcakes for a friend\u2019s birthday, keeping our voices hushed to avoid waking our mom and facing her \u201csalmonella is in your near future\u201d lecture. Yet, some of my fondest memories involve talking to people with whom I share nothing in common. Whether my conversations are about the Qatari coach\u2019s research on Kuwait\u2019s female voting patterns, or about the infinite differences between the \u201ccommon app\u201d and the Oxford interviewing process, or even about my friend\u2019s Swedish school\u2019s peculiar policy of mandating uniforms only on Wednesdays, I love comparing cultures with debaters from different countries. My behavior is unpredictable. Yet it\u2019s predictably unpredictable. Sure, I\u2019ll never eat a Korean dinner like one might expect. But I\u2019ll always be cooking linguine the moment I catch a whiff of kimchi.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0020", "text": "Several years ago, my mother told me I listen to \u201cwhite people music.\u201d And I suppose that\u2019s true\u2014rock 'n' roll tends to spring from the middle-class basements of young, white men. Though I did point out that its origins trace back to jazz musicians of the Harlem Renaissance. Also that one of the greatest guitarists of all time\u2014dear Mr.Hendrix; may he rest in peace\u2014was black. My devotion to punk rock began in seventh grade, when Green Day\u2019s \u201cBoulevard of Broken Dreams\u201d came up on my iTunes shuffle. I started to look into their other releases, eventually immersing myself into the complete punk discography. My mother, having grown up in a racially segregated New York, was more likely to listen to Stevie Wonder than Stevie Nicks. But, she must have figured, to each her own. So while my compatriots indulged in the music of Taylor Swift, One Direction, and Lady Gaga, my tacky Hot Topic headphones blasted Green Day, Ramones, and The Clash. My young adolescent ears drank in the raw, chaotic beauty, an echo of the pain of the past. The thrashing, pulsating vitality of the instruments painted a picture, connecting me to the disillusioned kids who launched an epic movement of liberation some 40 years ago. Punkers question authority. Aggressively contrarian, they advocate for the other side\u2014the side that seemed smothered silent during the post-Vietnam era. They rejected the established norms. They spoke out and weren\u2019t afraid. I had always felt different from my peers. In my girls\u2019s prep school, the goal was to be blond and good at soccer. I was neither, which automatically deemed me \u201cuncool\u201d. I had a few close friends but never felt like I was part of a whole. Then came the punk philosophy, for the outliers, for those who were different. That was something I could be part of. Instead of trying to conform to my peers, I adopted an anti-conformist attitude. Much like the prematurely gray anti-hero of my favorite book, I sneered at all the \u201cphonies\u201d around me. I resented anything popular. Uggs? Wouldn\u2019t buy them. Yoga pants? Never. Starbucks?Well, I could make a few concessions. But I felt more cynical than liberated. I wasted so much energy on being different than I lost track of what actually made me happy. I insisted I didn\u2019t care what people thought of me, which was true. Yet if I based my actions almost solely on their behavior, how could I deny their influence? Luckily, as I transitioned from a private school to a brand new public high school, I got to clean the slate. I bought yoga pants and found they were comfortable. I listened to a wide variety of music, even the eh kind that wasn\u2019t 100% hardcore punk. And I was happier. I revised my punk philosophy: Do as you like\u2014whether it fits into the \u201csystem\u201d or not. The Beatles\u2019s \u201cRevolution\u201d lyrics sum it up well: You tell me it\u2019s the institution Well, you know You\u2019d better free your mind instead What I think Lennon was getting at is questioning everything does not entail opposing everything. Defiance for the sake of defiance is unproductive at best, destructive at worst. I believe in life\u2019s greater Truths, like Love and Justice. These Truths are what should govern my actions\u2014not what\u2019s popular and what isn\u2019t. Striving to act on these ideals has helped me stay true to myself, regardless of what\u2019s considered \"conformist.\" Perhaps I\u2019ve failed the punk movement. We\u2019ll have to wait and see. In the meantime, I\u2019ll do what makes me happy and change what doesn\u2019t. I\u2019ll wear Doc Martens instead of Uggs; I\u2019ll partake in a grande pumpkin spice latte; I\u2019ll watch Gossip Girl; I\u2019ll blare my favorite guitar solo over the speakers in my room. And that\u2019s as punk as it gets.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0021", "text": "Garishly lined with a pearlescent lavender, my eyes idly scanned the haphazard desk in front of me, settling on a small kohl. I packed the ebony powder into my waterline with a shaky hand, wincing at the fine specks making their way into my eyes. The palette's colors bore in, the breadth of my imagination interwoven into now-brittle brushes. The girl in the mirror seemed sharper, older, somehow. At only 12, I was relatively new to the powders and blushes that lined my birthday makeup kit, but I was determined to decipher the deep splashes of color that had for so long been an enigma to me. After school involved self-inflicted solitary confinement, as I shut myself in my bedroom to hone my skills. The palette\u2019s colors bore in, the breadth of my imagination interwoven into now-brittle brushes. Much to my chagrin, my mom walked in one day, amused at my smudged lipstick, which congealed on the wispy hairs that lined my upper lip. \u201cHalloween already?\u201d she asked playfully. I flushed in embarrassment as she got to work, smoothing my skin with a brush and filling the gaps in my squiggly liner. Becoming a makeup aficionado was going to take some help. \u201cWhat\u2019s this even made of?\u201d I asked, transfixed by the bright powder she was smattering on my cheeks. \u201cYou know, I\u2019m not sure,\u201d she murmured. \u201cMaybe you should find out.\u201d I did. Hours down the internet rabbit hole, I learned that the shimmery powder was made of mica, a mineral commonly used in cosmetics. While the substance was dazzling, its production process was steeped in humanitarian violations and environmental damage. Determined to reconcile my burgeoning love for makeup with my core values, I flung the kit into the corner of my drawer, vowing to find a more sustainable alternative. Yes, I was every bit as dramatic as you imagine it. Now 17, I approach ethical makeup with assured deliberation. As I glance at my dusty kit, which still sits where I left it, I harken back on the journey it has taken me on. Without the reckoning that it spurred, makeup would still simply be a tool of physical transformation, rather than a catalyst of personal growth. Now, each swipe of eyeliner is a stroke of my pen across paper as I write a children\u2019s book about conscious consumerism. My flitting fingers programmatically place sparkles, mattes, and tints across my face in the same way that they feverishly move across a keyboard, watching algorithms and graphs integrate into models of supply chain transparency. Makeup has taught me to be unflinching, both in self expression and my expectations for the future. I coat my lips with a bold sheen, preparing them to form words of unequivocal urgency at global conferences and casual discussions. I see my passion take flight, emboldening others to approach their own reckonings, uncomfortable as they may be. I embark on a two-year journey of not buying new clothes in a statement against mass consumption and rally youth into a unified organization. We stand together, picking at the gritty knots of makeup, corporate accountability, and sustainability as they slowly unravel. Deep rooted journeys of triumph and tribulation are plastered across the surface of my skin \u2014 this paradox excites me. I\u2019m not sure why makeup transfixes me. Perhaps it\u2019s because I enjoy seeing my reveries take shape. Yukta, the wannabe Wicked Witch of the West, has lids coated with emerald luster and lips of coal. Yukta, the Indian classical dancer, wields thick eyeliner and bright crimson lipstick that allow her expressions to be amplified across a stage. Deep rooted journeys of triumph and tribulation are plastered across the surface of my skin \u2014 this paradox excites me. Perhaps I am also drawn to makeup because as I peel back the layers, I am still wholly me. I am still the young girl staring wide-eyed at her reflection, earnestly questioning in an attempt to learn more about the world. Most importantly, I still carry an unflagging vigor to coalesce creativity and activism into palpable change, one brushstroke at a time.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0022", "text": "Finally, I had found a volunteer opportunity at the Long Marine Lab, a marine biology research facility at UC Santa Cruz! I envisioned swimming with dolphins, or perhaps studying behavioral patterns of decorator crabs. But when I discovered the nature of my work on the first day of volunteering, my excitement turned to disappointment: I\u2019d be picking through albatross boluses, the indigestible materials they cough up before going to sea. Sure enough, after three hours of separating fishing line from brown muck, I began to dread what I was in for. At that point, I had no clue of just how interesting the opportunity would turn out to be, and it would remind me of how easily I become engrossed and fascinated by all sorts of random stuff. It didn\u2019t take long for my boredom with the boluses to shift toward curiosity. In the first place, the project itself was fascinating. The idea was to research the behavior and diet of albatrosses at sea. These birds can fly for months without touching land! When the birds have chicks, they cough up whatever they\u2019ve eaten at sea to feed their young. When the chicks become old enough to fly, they cough up the hard, indigestible materials left in their stomachs. These boluses contain squid beaks that can reveal the types of squid eaten and the area where the squid were caught. We volunteers would pick through the boluses, separating out anything that looked interesting. As I got better at dissecting these blobs, I started finding crazy stuff, and my colleagues and I would often discuss important findings. There was, of course, the search for the biggest squid beak, and the fish eyes were always interesting. But most shocking was the plastic. Beyond the normal Styrofoam and fishing line were plastic bottle caps, lighters, even toothbrushes. Occasionally, Asian writing revealed distant origins. Once, I picked through a bolus permeated with orange goo, eventually to discover the round mouthpiece of a balloon. The origins of these artifacts were sad, but also fascinating. I learned of the Texas-sized trash heap in the middle of the Pacific, the effects of which I was witnessing firsthand. I gained a heightened awareness of the damage inflicted on the oceans by humans, and their far-reaching impacts. Perhaps most importantly, I realized that even the most tedious things can blow my mind. If dissecting boluses can be so interesting, imagine the things I\u2019ve yet to discover! I play piano and can see myself dedicating my life to the instrument, but I can\u2019t bear to think of everything else I\u2019d have to miss. I\u2019d love to study albatrosses, but also particle physics or history, and preferably all three. At this point in my life, I can\u2019t imagine picking just one area. At the same time, though, I love studying subjects in depth. I tend to get overwhelmed by my options, since I can\u2019t possibly choose them all. But at least I know I\u2019ll never be bored in life: there are just too many subjects to learn about, books to read, pieces to play, albatrosses to save, and boluses to dissect.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0023", "text": "Gazing up at the starry sky, I see Cygnus, Hercules, and Pisces, remnants of past cultures. I listen to waves crash on the beach, the forces of nature at work. Isn\u2019t it odd how stars are flaming spheres and electrical impulses make beings sentient? The very existence of our world is a wonder; what are the odds that this particular planet developed all the necessary components, parts that all work in unison, to support life? How do they interact? How did they come to be? I thought back to how my previously simplistic mind-set evolved this past year. The very existence of our world is a wonder; what are the odds that this particular planet developed all the necessary components, parts that all work in unison, to support life? At Balboa, juniors and seniors join one of five small learning communities, which are integrated into the curriculum. Near the end of sophomore year, I ranked my choices: Law Academy first\u2014it seemed the most prestigious\u2014and WALC, the Wilderness Arts and Literacy Collaborative, fourth. So when I was sorted into WALC, I felt disappointed at the inflexibility of my schedule and bitter toward my classes. However, since students are required to wait at least a semester before switching pathways, I stayed in WALC. My experiences that semester began shifting my ambition-oriented paradigm to an interest-oriented one. I didn\u2019t switch out. Beyond its integrated classes, WALC takes its students on trips to natural areas not only to build community among its students, but also to explore complex natural processes and humanity\u2019s role in them. Piecing these lessons together, I create an image of our universe. I can visualize the carving of glacial valleys, the creation and gradation of mountains by uplift and weathering, and the transportation of nutrients to and from ecosystems by rivers and salmon. I see these forces on the surface of a tiny planet rotating on its axis and orbiting the sun, a gem in this vast universe. Through WALC, I have gained an intimate understanding of natural systems and an addiction to understanding the deep interconnections embedded in our cosmos. Understanding a system\u2019s complex mechanics not only satisfies my curiosity, but also adds beauty to my world; my understanding of tectonic and gradational forces allows me to appreciate mountains and coastlines beyond aesthetics. By physically going to the place described in WALC\u2019s lessons, I have not only gained the tools to admire these systems, but have also learned to actually appreciate them. This creates a thirst to see more beauty in a world that\u2019s filled with poverty and violence, and a hunger for knowledge to satisfy that thirst. There are so many different systems to examine and dissect\u2014science alone has universal, planetary, molecular, atomic, and subatomic scales to investigate. I hope to be able to find my interests by taking a variety of courses in college, and further humanity\u2019s understanding through research, so that all can derive a deeper appreciation for the complex systems that govern this universe.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0024", "text": "James was not fitting in with everyone else. During lunch, he sat alone, playing with his own toys. During group activities, the other campers always complained when paired with him. What was wrong? As camp counselor, I quietly observed his behavior\u2014nothing out of the ordinary. I just couldn\u2019t fathom why the other campers treated him like a pariah. After three days of ostracism, James broke down during a game of soccer. Tears streaming down his cheeks, he slumped off the field, head in his hands. I jogged toward him, my forehead creased with concern. Some campers loudly remarked, \u201cWhy is that creep crying?\u201d Furious indignation leaped into my heart. They were the ones who \u201caccidentally\u201d bumped into him and called him \u201cJames the Freak.\u201d It was their cruelty that caused his meltdown, and now they were mocking him for it. I sharply told them to keep their thoughts to themselves. I squatted beside James and asked him what was wrong. Grunting, he turned his back to me. I had to stop his tears, and I had to make him feel comfortable. So for the next hour, I talked about everything a seven-year-old boy might find interesting, from sports to Transformers. \u201cI have a question,\u201d I asked as James began to warm to me. I took a deep breath and dove right into the problem. \u201cWhy do the other campers exclude you?\u201d Hesitantly, he took off his shoes and socks, and pointed at his left foot. One, two, three \u2026 four. He had four toes. We had gone swimming two days before: All the campers must have noticed. I remembered my childhood, when even the smallest abnormality\u2014a bad haircut, a missing tooth\u2014could cause others, including myself, to shrink away. I finally understood. But what could I do to help? I scoured my mind for the words to settle his demons. But nothing came to me. Impulsively, I hugged him\u2014a gesture of intimacy we camp leaders were encouraged not to initiate, and an act I later discovered no friend had ever offered James before. Then, I put my hand on his shoulder and looked him straight in the eyes. I assured him that external features didn\u2019t matter, and that as long as he was friendly, people would eventually come around. I listed successful individuals who had not been hindered by their abnormalities. And finally, I told him he would always be my favorite camper, regardless of whether he had two, five, or a hundred toes. On the last day of camp, I was jubilant\u2014James was starting to fit in. Although the teasing had not completely disappeared, James was speaking up and making friends. And when, as we were saying our good-byes, James gave me one last hug and proclaimed that I was his \u201cbestest friend in the whole wide world,\u201d my heart swelled up. From my campers, I learned that working with children is simply awesome. And from James, I learned that a little love truly goes a long way.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0025", "text": "My Ye-Ye always wears a red baseball cap. I think he likes the vivid color\u2014bright and sanguine, like himself. When Ye-Ye came from China to visit us seven years ago, he brought his red cap with him and every night for six months, it sat on the stairway railing post of my house, waiting to be loyally placed back on Ye-Ye\u2019s head the next morning. He wore the cap everywhere: around the house, where he performed magic tricks with it to make my little brother laugh; to the corner store, where he bought me popsicles before using his hat to wipe the beads of summer sweat off my neck. Today whenever I see a red hat, I think of my Ye-Ye and his baseball cap, and I smile. Ye-Ye is the Mandarin word for \u201cgrandfather.\u201d My Ye-Ye is a simple, ordinary person\u2014not rich, not \u201csuccessful\u201d\u2014but he is my greatest source of inspiration and I idolize him. Of all the people I know, Ye-Ye has encountered the most hardship and of all the people I know, Ye-Ye is the most joyful. That these two aspects can coexist in one individual is, in my mind, truly remarkable. Ye-Ye was an orphan. Both his parents died before he was six years old, leaving him and his older brother with no home and no family. When other children gathered to read around stoves at school, Ye-Ye and his brother walked in the bitter cold along railroad tracks, looking for used coal to sell. When other children ran home to loving parents, Ye-Ye and his brother walked along the streets looking for somewhere to sleep. Eight years later, Ye-Ye walked alone\u2014his brother was dead. Ye-Ye managed to survive, and in the meanwhile taught himself to read, write, and do arithmetic. Life was a blessing, he told those around him with a smile. Years later, Ye-Ye\u2019s job sent him to the Gobi Desert, where he and his fellow workers labored for twelve hours a day. The desert wind was merciless; it would snatch their tent in the middle of the night and leave them without supply the next morning. Every year, harsh weather took the lives of some fellow workers. After eight years, Ye-Ye was transferred back to the city where his wife lay sick in bed. At the end of a twelve-hour workday, Ye-Ye took care of his sick wife and three young children. He sat with the children and told them about the wide, starry desert sky and mysterious desert lives. Life was a blessing, he told them with a smile. But life was not easy; there was barely enough money to keep the family from starving. Yet, my dad and his sisters loved going with Ye-Ye to the market. He would buy them little luxuries that their mother would never indulge them in: a small bag of sunflower seeds for two cents, a candy each for three cents. Luxuries as they were, Ye-Ye bought them without hesitation. Anything that could put a smile on the children\u2019s faces and a skip in their steps was priceless. Ye-Ye still goes to the market today. At the age of seventy-eight, he bikes several kilometers each week to buy bags of fresh fruits and vegetables, and then bikes home to share them with his neighbors. He keeps a small patch of strawberries and an apricot tree. When the fruit is ripe, he opens his gate and invites all the children in to pick and eat. He is Ye-Ye to every child in the neighborhood. I had always thought that I was sensible and self-aware. But nothing has made me stare as hard in the mirror as I did after learning about the cruel past that Ye-Ye had suffered and the cheerful attitude he had kept throughout those years. I thought back to all the times when I had gotten upset. My mom forgot to pick me up from the bus station. My computer crashed the day before an assignment was due. They seemed so trivial and childish, and I felt deeply ashamed of myself. Now, whenever I encounter an obstacle that seems overwhelming, I think of Ye-Ye; I see him in his red baseball cap, smiling at me. Like a splash of cool water, his smile rouses me from grief, and reminds me how trivial my worries are and how generous life has been. Today I keep a red baseball cap at the railing post at home where Ye-Ye used to put his every night. Whenever I see the cap, I think of my Ye-Ye, smiling in his red baseball cap, and I smile. Yes, Ye-Ye. Life is a blessing. But what could I do to help? I scoured my mind for the words to settle his demons. But nothing came to me. Impulsively, I hugged him\u2014a gesture of intimacy we camp leaders were encouraged not to initiate, and an act I later discovered no friend had ever offered James before. Then, I put my hand on his shoulder and looked him straight in the eyes. I assured him that external features didn\u2019t matter, and that as long as he was friendly, people would eventually come around. I listed successful individuals who had not been hindered by their abnormalities. And finally, I told him he would always be my favorite camper, regardless of whether he had two, five, or a hundred toes. On the last day of camp, I was jubilant\u2014James was starting to fit in. Although the teasing had not completely disappeared, James was speaking up and making friends. And when, as we were saying our good-byes, James gave me one last hug and proclaimed that I was his \u201cbestest friend in the whole wide world,\u201d my heart swelled up. From my campers, I learned that working with children is simply awesome. And from James, I learned that a little love truly goes a long way.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0026", "text": "In hazy stillness, a sudden flurry of colored skirts, whispers of \u201cMerde!\u201d Sternly, my fingers smooth back my hair, although they know no loose strands will be found. My skin absorbs heat from stage lights above\u2014if only that heat would seep into my brain, denature some proteins, and deactivate the neurons stressing me out. A warm hand, accompanied by an even warmer smile, interrupts my frenzied solitude. I glance up. My lovely teacher nods, coaxing my frozen lips into a thawed smile. A complex figure, filled in with doubt, yet finished with shades of confidence: My body takes its place and waits. One, two, three, four; two, two, three, four. On stage, the lights and music wash over me. Never having had a true ballet solo before, my lungs are one breath away from hyperventilating. Trying to achieve a Zen-like state, I imagine a field of daisies, yet my palms continue sweating disobediently. It\u2019s not that I\u2019ve never been on stage alone before; I\u2019ve had plenty of piano recitals and competitions. Yet, while both performances consume my mind and soul, ballet demands complete commitment of my body. Gently slide into arabesque and lean downward; try not to fall flat on face\u2014Mom\u2019s videotaping. In terms of mentality, I would hardly be described as an introvert; yet, a fear of failure has still kept me from taking risks. Maybe I was scared of leaping too high, falling too far, and hitting the hard floor. As I moved up in the cutthroat world of dance, this fear only increased; the pressure of greater expectations and the specter of greater embarrassment had held me contained. Now, every single eyeball is on me. Lean extra in this pirouette; it\u2019s more aesthetic. But is it always better to be safe than sorry? Glancing toward the wings, I see my teacher\u2019s wild gesticulations: Stretch your arms out, she seems to mime, More! A genuine smile replaces one of forced enthusiasm; alone on the stage, this is my chance to shine. I breathe in the movements, forget each individual step. More than just imagining, but finally experiencing the jubilation of the music, I allow my splits to stretch across the stage and my steps to extend longer and longer, until I\u2019m no longer safe and my heart is racing. Exhilarated and scared in the best way, I throw myself into my jumps. I no longer need to imagine scenes to get in the mood; the emotions are twirling and leaping within me. Reaching, stretching, grabbing, flinging ... My fear no longer shields me. I find my old passion for ballet, and remember the grace and poise that can nevertheless convey every color of emotion. Playing it safe will leave me part of the backdrop; only by taking risks can I step into the limelight. Maybe I\u2019ll fall, but the rush is worth it. I\u2019ll captain an all-male science bowl team, run a marathon, audition for a musical, and embrace the physical and intellectual elation of taking risks.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0027", "text": "Red, orange, purple, gold...I was caught in a riot of shifting colors. I pranced up and down the hill, my palms extended to the moving collage of butterflies that surrounded me. \u201cWould you like to learn how to catch one?\u201d Grandfather asked, holding out a glass jar. \u201cYes!\u201d I cheered, his huge calloused fingers closing my chubby five-year-old hands around it carefully. Grandfather put his finger to his lips, and I obliged as I watched him deftly maneuver his net. He caught one marvelous butterfly perched on a flower, and I clutched the open jar in anticipation as he slid the butterfly inside. It quivered and fell to the bottom of the jar, and I gasped. It struggled until its wings, ablaze in a glory of orange and red, quivered to a stop. I watched, wide-eyed, as it stopped moving. \u201cGrandpa! What\u2019s happening?\u201d My grandfather had always had a collection of butterflies, but that was the first time I saw him catch one. After witnessing the first butterfly die, I begged him to keep them alive; I even secretly let some of them go. Therefore, to compromise, he began carrying a special jar for the days I accompanied him on his outings, a jar to keep the living butterflies. But the creatures we caught always weakened and died after a few days in captivity, no matter how tenderly I fed and cared for them. Grandfather took me aside and explained that the lifespan of an adult butterfly was very short. They were not meant to live forever: their purpose was to flame brilliantly and then fade away. Thus, his art serves as a memory of their beauty, an acknowledgement of nature\u2019s ephemeral splendor. But nothing could stay the same. I moved to America and as the weekly excursions to the mountainside ended, so did our lessons in nature and science. Although six thousand miles away, I would never forget how my grandpa\u2019s wrinkles creased when he smiled or how he always smelled like mountain flowers. As I grew older and slowly understood how Grandfather lived his life, I began to follow in his footsteps. He protected nature\u2019s beauty from decay with his art, and in the same way, I tried to protect my relationships, my artwork, and my memories. I surrounded myself with the journals we wrote together, but this time I recorded my own accomplishments, hoping to one day show him what I had done. I recorded everything, from the first time I spent a week away from home to the time I received a gold medal at the top of the podium at the California Tae Kwon Do Competition. I filled my new home in America with the photographs from my childhood and began to create art of my own. Instead of catching butterflies like my grandpa, I began experimenting with butterfly wing art as my way of preserving nature\u2019s beauty. Soon my home in America became a replica of my home in China, filled from wall to wall with pictures and memories. Nine long years passed before I was reunited with him. The robust man who once chased me up the hillside had developed arthritis, and his thick black hair had turned white. The grandfather I saw now was not the one I knew; we had no hobby and no history in common, and he became another adult, distant and unapproachable. With this, I forgot all about the journals and photos that I had kept and wanted to share with him. After weeks of avoidance, I gathered my courage and sat with him once again. This time, I carried a large, leather-bound book with me. \u201cGrandfather,\u201d I began, and held out the first of my many journals. These were my early days in America, chronicled through pictures, art, and neatly-printed English. On the last page was a photograph of me and my grandfather, a net in his hand and a jar in mine. As I saw our faces, shining with proud smiles, I began to remember our days on the mountainside, catching butterflies and halting nature\u2019s eventual decay. My grandfather has weakened over the years, but he is still the wise man who raised me and taught me the value of capturing the beauty of life. Although he has grown old, I have grown up. His legs are weak, but his hands are still as gentle as ever. Therefore, this time, it will be different. This time, I will no longer recollect memories, but create new ones. Lean extra in this pirouette; it\u2019s more aesthetic. But is it always better to be safe than sorry? Glancing toward the wings, I see my teacher\u2019s wild gesticulations: Stretch your arms out, she seems to mime, More! A genuine smile replaces one of forced enthusiasm; alone on the stage, this is my chance to shine. I breathe in the movements, forget each individual step. More than just imagining, but finally experiencing the jubilation of the music, I allow my splits to stretch across the stage and my steps to extend longer and longer, until I\u2019m no longer safe and my heart is racing. Exhilarated and scared in the best way, I throw myself into my jumps. I no longer need to imagine scenes to get in the mood; the emotions are twirling and leaping within me. Reaching, stretching, grabbing, flinging ... My fear no longer shields me. I find my old passion for ballet, and remember the grace and poise that can nevertheless convey every color of emotion. Playing it safe will leave me part of the backdrop; only by taking risks can I step into the limelight. Maybe I\u2019ll fall, but the rush is worth it. I\u2019ll captain an all-male science bowl team, run a marathon, audition for a musical, and embrace the physical and intellectual elation of taking risks.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0028", "text": "I sat on my parents\u2019 bed weeping with my head resting on my knees. \u201cWhy did you have to do that to me? Why did you have to show me the house and then take it away from me?\u201d Hopelessly, I found myself praying to God realizing it was my last resort. For years, my family and I found ourselves moving from country to country in hopes of a better future. Factors, such as war and lack of academic opportunities, led my parents to pack their bags and embark on a new journey for our family around the world. Our arduous journey first began in Ku\u00e7ov\u00eb, Albania, then Athens, Greece, and then eventually, Boston, Massachusetts. Throughout those years, although my family always had a roof over our heads, I never had a place I could call \u201chome.\u201d That night that I prayed to God, my mind raced back to the night I was clicking the delete button on my e-mails, but suddenly stopped when I came upon a listing of the house. It was September 22, 2007 \u2014eight years exactly to the day that my family and I had moved to the United States. Instantly, I knew that it was fate that was bringing this house to me. I remembered visiting that yellow house the next day with my parents and falling in love with it. However, I also remembered the heartbreaking phone call I received later on that week saying that the owners had chosen another family\u2019s offer. A week after I had prayed to God, I had given up any hopes of my family buying the house. One day after school, I unlocked the door to our one-bedroom apartment and walked over to the telephone only to see it flashing a red light. I clicked PLAY and unexpectedly heard the voice of our real estate agent. \u201cEda!\u201d she said joyfully. \u201cThe deal fell through with the other family\u2014the house is yours! Call me back immediately to get started on the papers.\u201d For a moment, I stood agape and kept replaying the words in my head. Was this really happening to me? Was my dream of owning a home finally coming true? Over the month of November, I spent my days going to school and immediately rushing home to make phone calls. Although my parents were not fluent enough in English to communicate with the bank and real estate agent, I knew that I was not going to allow this obstacle to hinder my dream of helping to purchase a home for my family. Thus, unlike a typical thirteen-year-old girl\u2019s conversations, my phone calls did not involve the mention of makeup, shoes, or boys. Instead, my conversations were composed of terms, such as \u201cfixed-rate mortgages,\u201d \u201cpreapprovals,\u201d and \u201cdown payments.\u201d Nevertheless, I was determined to help purchase this home after thirteen years of feeling embarrassed from living in a one-bedroom apartment. No longer was I going to experience feelings of humiliation from not being able to host sleepovers with my friends or from not being able to gossip with girls in school about who had the prettiest room color. I had been homeless for the first thirteen years of my life. Although I will never be able to fully repay my parents for all of their sacrifices, the least I could do was to help find them a home that they could call their own\u2014and that year, I did. To me, a home means more than the general conception of \u201cfour walls and a roof.\u201d A home is a place filled with memories and laughter from my family. No matter where my future may lead me, I know that if at times I feel alone, I will always have a yellow home with my family inside waiting for me.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0029", "text": "The white yarn slipped off my aluminium crochet hook, adding a single crochet to rows and rows of existing stitches, that looked to be in the form of a blob. Staring at the image of the little unicorn amigurumi lit up on the screen of my laptop, and looking back at the UMO (unidentified messy object) number five, I was extremely perplexed. This had seemed so easy. Round 1, construct a magic circle with 6 single crochets. Done. Round 2 was an increase round resulting in a total of 12 stitches. Also done. The remaining rounds were blurred into hours and minutes that should have resulted in a little white creature in the likeness of a unicorn, but sitting on my desk (much like the four days before today) was a pool of tangled white yarn. It was not until day seven that a creature with a lopsided head whose horn was the only identifier of the mythical being emerged. Very much like learning how to crochet, my journey in forging my own path and finding a passion was confusing, messy and at times infuriating. Even in primary school, I had heard all the stories of individuals finding their own route in life. I had been told stories of those who found their passion at a young age and were exceptionally proficient at their craft, of those that abandoned their interests and pursued a lucrative career, even those who chose their dreams but regretted it afterwards. This weighed heavily on me, as I was determined to have a success story as many of my other family members had. The only problem was that I did not have a direction. In the years following primary school, I stepped out of my comfort zone in a frenzy to find a passion. I joined the school orchestra where I played the violin, and a debate class to practice public speaking and become much more eloquent. At my ballet school, I branched out to contemporary and jazz dance. I stuffed myself with experience similar to an amigurumi engorged with batting. I found myself enjoying all of those activities but soon enough, I was swamped with extracurriculars. Just like the tangles of white yarn on my desk, I was pulled in all directions. I still felt lost. To make things worse, it seemed as if everyone else had found their path in life, and they had all become white unicorns while I was still doubting the stitch I just made. It was not until high school that I realised that I could view this mission to find a passion from another perspective. While successfully completing a crochet project is an accomplishment itself, the motions of making slip knots, single or double crochets takes you on an adventure as well. The knots that I had encountered in my craft were evidence of my experiences and what shaped me as an individual. My exploration of various paths through detours may have sometimes resulted in roadblocks, but I continued to persevere and learn from my experiences, applying the skills that I have gained to future knots. The mini adventures that I went on were all crucial to me in the greater journey of life. Through trial and error, the current adventure that I am on resonates the most with me, taking me down the path of service and environmental activism. However, I have learnt that no one path is static, and I can be on more than one path at a time. While I may only be halfway to the proportionate unicorn amigurumi that some others may have already achieved, I still have so much to learn and so much that I want to learn, and so my journey to grow continues.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0030", "text": "If you told me I would be playing a sport called squash at 11 years old, I would call you crazy. But in seventh grade, I was at a new school 10 times bigger than my last one. I felt like a little fish in a big pond. I was quiet, withdrawn, and very introverted. A lot of the time, I stayed where I was comfortable. During the first week of school, a group of people visited the school and they introduced themselves as Squashbusters. At that time, I\u2019d only heard of Squash once before, but I didn\u2019t really know what it was. Because the program combined the sport of squash with academic support, mentoring, and service opportunities, I decided to sign up. It\u2019s been six years and this program has made a monumental difference in my life. Being a part of SquashBusters is a program that really pushed me out of my shell to the point where I\u2019ve grown accustomed to challenging myself. In SquashBusters, they tell us to push ourselves past our limits on the squash courts, but that mindset has transferred to other areas of my life as well. From team trips and tournaments to cringy karaoke moments and participating in eccentric traditions like our annual SquashBusters Olympics, my comfort zone has steadily grown larger. My peers brought out a side of me I didn\u2019t even know existed. I haven\u2019t transformed completely from introvert to extrovert, but I\u2019ve become more social as the years go by. At Hopkins, I want to do something similar. I want to try new things and embrace the campus traditions. Even though I will develop intellectually from the many academic classes and clubs/activities offered on campus, I feel as though a true community is birthed from exploring beyond what one\u2019s used to. From traditions like Blue Jay Opening Day and the Spring Fair to the many world-changing clubs like the Amnesty International club and the Foreign Affairs Symposium, the different ways to be involved in the Hopkins community is limitless and invigorating and I can\u2019t wait to be a part of the Hopkins family.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0031", "text": "\u201cBring the ace of spades up,\u201d my Grandmother said as we started our first game of solitaire after I got home from school. \u201cNow, put the black eight onto the red nine.\u201d We played solitaire often, working together to reorganize the cards most efficiently. While it was meant to be a single-player game, solitaire was the one thing we did together, moving and dealing the cards in a symphony of order: red to black, red to black. Pulling the pattern out of the random array of cards. For hours, we sat at our glossy kitchen table, playing game after game. If there were no more moves to make, I would always sneak a card from below a column without my grandma seeing. She always did. I couldn\u2019t understand- What was the big deal of revealing the cards? We might win one out of ten games played. But if we just \u2018helped ourselves,\u2019 as I liked to call it, we could win them all. I didn\u2019t understand her adherence to the \u201cTurn Three\u201d rule. Why not just turn the cards one by one? It was too frustrating to see the cards go by, but turn exactly three and not be able to pick them up! After one game we lost, I asked my grandma, \u201cWhy do we play this way? There\u2019s a much better way to play.\u201d In response, she quickly explained her adamancy to the rules, what before had made no sense to me. Her polished fingernails scratched against the cards as she shuffled them and told me. \u201cSolitaire isn\u2019t just a game for one person.\u201d Her deep brown eyes sharply glanced at me, \u201cNo.\u201d It wasn\u2019t just a game for one person, but rather for two sides of a person. It was an internal battle, a strengthening of the mind. One playing against oneself. \u201cIf one side of you cheats, how would either side get better?\u201d Red lipsticked lips slightly grinned as my grandma saw me trying to understand, but I didn\u2019t agree with this thought at once. The cards rhythmically slapped down onto the table as my grandmother, small yet stoic, effortlessly moved the cards with frail hands. I watched her. I thought about any other way to understand this idea. I desperately wanted to. Trying to think, I couldn\u2019t imagine another instance where this sense of tranquility, bringing the melody of organization out of a cacophony of random cards, came from such intense competition. The slow manipulation of life around her precedent made me think back to my grandma, to what she told me, and made me understand. Two years later, pushing myself harder than I ever had before in a field hockey match, I realized how much I had been cheating myself and my team by not putting this effort in before. Four years later, I was helping my parents clean after dinner when I saw the value in not taking the easy way out. Five years later, I found once again the difficult ease in pottery. Lifting the pot off the wheel, I found satisfaction. Looking back, I hadn\u2019t realized that this notion of self-accountability appears in almost every aspect of my life. Seven columns. Four aces. Fifty-two cards. Laying these down, I\u2019m brought back to playing solitaire with my grandmother. Through time, her inner spirit never crumbled as her body began to deteriorate. Her mind stayed strong and proud. I admired her for that more than she could\u2019ve imagined. Each challenge I face, or will face, in life, I think back to her lesson one inconspicuous afternoon. Never let myself cheat. Always hold myself accountable. Work hard in every competition, especially the ones against myself, as those are the ones that better me the most. I did not understand what my grandmother meant that day. Now, with each day, I do more.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0032", "text": "No, Dante. Stop, think, and look at the entire board. I was thoroughly confused. I thought I had procured the complete solution to this elaborate chess puzzle. What am I missing? A knight fork, a bishop move? Am I in check? After a quick glance at the left side of the board, I slapped my hand on my head as I suddenly realized what my chess coach was telling me. My queen was sitting unused, positioned all the way on the other side of the board, and I had no idea. If I were to sacrifice my queen, the opposing rook would be forced to capture it, allowing me to finish the game in style with the illustrious \u201csmothered mate.\u201d If you begin to look at the whole chessboard, then these puzzles will become a breeze for you. Ever since that chess lesson, those words have stuck. Indeed, my chess skills improved swiftly as my rating flew over the 1000 Elo threshold in a matter of months. However, those words did not merely pertain to chess. Looking at the whole picture became a foundational skill that I have utilized throughout my life in school and other endeavors. I particularly remember making use of it on the soccer field. Now, I\u2019m no Arnold Schwarzenegger. Weighing in at a monstrous 125 pounds and standing 5 foot 8 inches, my opponents made it a habit to tackle me to the ground. Once again, I found myself face to face with the defender, and before I knew it, I crumbled to the ground, left isolated and dispossessed. Laying dazed on the pitch, my mind flashed back to the chessboard. It occurred to me that soccer, much like chess, relies on the proper position of the many pieces that combine to create a finished strategy. The \u201cwhole picture\u201d of soccer is not just how fast or strong one is or how many tackles you put in; that is only one element of the puzzle. The intelligence and creativity needed in a playmaker is also an essential part of a well-rounded soccer team. I realized that my most significant advantage would always be my in-depth understanding of the game of soccer\u2014where to pass the ball, when to make a run, if the ball should be in the air or driven. I picked myself off the ground, and when that same defender came barreling towards me again, I was zoned in, oblivious to the noise around me. I chipped the ball into the open space right behind him, knowing my teammate would run into the space without even looking. From then on, I continued to hone my skills through intense practice to become the best playmaker I could be, working in conjunction with my faster and stronger teammates to become a well-balanced, unified team. Through chess and soccer, I have discovered that every piece in a puzzle has a purpose. This new perspective has enhanced my ability to stop, stand back, and analyze the whole picture in the many dimensions of my life. In my scientific studies, it was not enough to examine just one C. reinhardtii cell, but it was necessary to zoom out the microscope to capture all of the thousand cells to truly understand quorum sensing and its consequences. In my studies of music, it was not enough to listen to the melody of the finale of Beethoven\u2019s 9th symphony, but one must realize that the true beauty of the composition lies in the whole orchestra handing off this simple melody to every instrument. All these facets\u2014music, research, soccer, chess\u2014are not only completed puzzles but also parts of a greater whole: my life. Every aspect of myself matters as much as the other. As high school comes to an end, the pieces on my board are set, and I only have success in mind. Your move.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0033", "text": "The first lesson I learned as a student pilot is that left and right don\u2019t exist. Maybe driving on a highway or in a parking lot, left and right is precise enough to describe the location and movements of slow-moving bikers, pedestrians, and cars. But at 36,000 feet in the air in a steel tube hurdling almost 200 miles an hour? Left and right just don\u2019t cut it. During one of my first flights in a small Cessna-182, my flight instructor ordered me to scan the horizon for approaching aircrafts. To my right, I caught a glimpse of one: another Cessna with maroon stripes, the sun\u2019s reflection glinting off its windows. Gesturing vaguely to my two o\u2019clock, I informed my flying instructor, \u201cThere\u2019s a plane to the right.\u201d \u201cNo, to your right. From his position, what direction does he see you?\u201d From his angle, I was to his left. In that moment, I realized that perspective and precision of language is everything. The radio chirped: \u201cCessna One-Eight-Two Sandra, heading north to John Wayne Airport. Over.\u201d I navigate using my compass\u2019s north, east, south, and west directions because every pilot\u2019s vantage point differs from each other both vertically and horizontally, creating opposite perspectives. My right was that pilot\u2019s left. Through flying, I began to consider all points of view, regardless of my personal perspective. Perhaps it was my ability to scan the horizon to communicate a single story, uniting contrasting outlooks, that drew me to my love for journalism and the diverse melting pot that was my community. To me, journalism modernizes the ancient power of storytelling, filled with imperfect characters and intricate conflicts to which I am the narrator. As editor-in-chief for my school newspaper, The Wildcat\u2019s Tale, I aim to share the uncensored perspective of all students and encourage my editorial groups to talk \u2014 and listen \u2014 to those with whom they disagree. Starting each newspaper edition with a socratic, round-table discussion, I ask the other journalists to pursue stories that answer the questions: why did this happen and where will it lead? Expanding beyond the perspectives of my classmates, I began writing articles for the Korea Daily, and later, the Los Angeles Times High School Insider. I schedule interviews with city council candidates, young and old voters, and mayors of my town, obtaining quotes and anecdotes to weave into my writing. My interviews with both Democratic and Republican voters have taught me to thoroughly report polarizing-opposite opinions through an unbiased lens. As a journalist, I realized I cannot presume the opinions of the reader, but instead simply provide them with the tools necessary to formulate their own conclusions. However, differences in perspective in my articles are not solely limited to politics. I found that in my suburban community, people love to read about the small-town hospitality of their own friends and neighbors. Quirky traditions, like our Fourth of July carnival clown and local elementary school\u2019s Thanksgiving talent show, are equally as important to me as national headlines are. My favorite stories to publish are the ones taped onto fridges, proudly framed on the mom-and-pop downtown diner, or pinned into the corkboard in my teacher\u2019s classroom. I discovered the size of my story does not matter, but the impact I leave on the reader does. In my time as both a student pilot and journalist, I grew to love these stories, the ones that showed me that living life with blinders, can not only be boring, but dangerous. Whether I was 36,000 feet in the air or on ground level, by flying and writing, I realized that the most interesting stories of life come straight from the people most different from me.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0034", "text": "I cannot dance. This is not something I often admit willingly; in fact, it is quite baffling to me how horribly incapable I am at performing even the most basic movements on command. My grandmother often describes it as \u201ca tragedy\u201d as she is forced to watch her grandchild absolutely butcher our country\u2019s cultural dances, beautiful expressions of our unique West African roots turned into poor facsimiles by my robotic movements. And yet, year after year, I find myself taking the dance floor at my family\u2019s events, seemingly unaware of my objective lack of skill. Eventually, my display proves to be so amazingly unbearable that I am removed from the floor and shown the correct movements over and over again until I am able to replicate them well enough to come back. Bizarrely, despite my previous declaration that I cannot dance, for the past three years, I have found myself performing an entire choreographed routine at my school\u2019s yearly pep rallies. It is through looking back at these events that I realize that I have created a mischaracterization of my dancing abilities through my decisive first sentence. I can dance and am, in fact, very capable of doing so, but not when I act insularly. My ability to dance correlates directly with how willing I am to collaborate, the input and support of others turning the uncoordinated and unwieldy into the near-graceful. My attempts at dancing have led me to value community and collaboration greatly, and I find myself seeking and being drawn towards environments that will allow me to continue to develop both of these values as I learn and grow. Through my internship with the Johns Hopkins Applied Physics Lab, I was exposed to and became fascinated by the collaborative spirit that lies at the heart of Johns Hopkins. The idea that one cannot discover or innovate when working alone was affirmed during my research, and I have come to see that mutual collaboration and community are integral aspects of Johns Hopkins\u2019 unique culture. From the research initiatives that breach the boundaries between class levels, to the many organizations such as the Tutorial Project, relying on the shared initiatives of different students to directly make an impact on Baltimore and its many communities, and the distinctive access to especially interdisciplinary topics such as neuromorphic systems, I view that Johns Hopkins exemplifies the peak of collaborative achievement in education.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0035", "text": "Whether I was blowing out candles, writing a letter to santa, or waiting for the clock to turn 11:11, my one wish growing up was not for something, but for someone. I wanted a sibling. I would always look to my friends and think how lucky they were to have brothers and sisters to play with, while I was stuck at home alone with my parents. However, these sentiments soon changed and my life was transformed, when my parents came home with my new sister, Mia. And while Mia was a furry, Lhasa Apso dog, rather than the human baby sister or brother I dreamed of, she helped me accept and even cherish my life as an only child. I came to realize, however, that it would take much longer for me, and much more than a dog, to accept the other ways I felt alone within my group of friends and my community as a whole. Living in a predominantly white town and attending a school with a population of about 75% white students has had a huge impact on the way I view my Filipino self. While my friends ate turkey and cheese sandwiches at lunch, I would secretly pick at the traditional adobo chicken my mom had sent me that day. I stood by as my classmates made jokes stereotyping and generalizing Asians into one category, even though I knew there were vast differences in our cultures. During social studies classes, I noticed that I learned more about the ancestry of my friends, rather than my own. Consequently, I began to accept the notion that my heritage was of less importance and something to be ashamed of. I masked the pungent aromas of the Filipino delicacies my immigrant parents made with pasta and hamburgers when my friends came over, I laughed off incidents when parents or teachers would mistake me for the only other Filipino girl in my grade, and I recognized that learning solely about European and East Asian history in world history classes was the norm. I started to believe that assimilation was the only pathway to acceptance, along with the only way I could feel less alone within my community. It was not until I entered high school that I realized how wrong I was. Although I did not encounter an increase in diversity in terms of ethnicity, I saw an increase in the spectrum of perspectives around me. Through electives, clubs, and activities, the student body I was met with since my freshman year was open-minded, as well as politically and culturally active and engaged, and I immediately joined in. At speech and debate tournaments, I talked with students from across the globe, while at discussions between the High School Democrats Club and Young Conservatives Club at my school, I enjoyed listening and being exposed to different viewpoints. Suddenly, I was no longer willing to feel defeated and instead began to feel confident in displaying my Filipino pride. I introduced my friends to an array of Filipino dishes from lumpia to toron, I asked my social studies teachers questions about the history and current state of the Philippines, and I no longer saw myself and my background as what differentiated me from others and caused my feelings of aloneness, but as something that I should embrace. I changed my narrative from \u201calone\u201d to \u201cunique,\u201d and I strive to spread the message that being different can and should be the norm to my peers. I would not be who I am without my Filipino background, and although the community I live in is what previously made me feel alone, it is also what gave me the potential to learn, grow, and broadened my appreciation for what made me unique.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0036", "text": "out my tough transition. But instead of an answer, Ms. McVaugh offered me to join a girls\u2019 field hockey practice. I felt thrown off by the unusual opportunity at first, yet I quickly relished a warm rush of excitement surging through my veins as I imagined putting on field hockey cleats again. When I set foot on the turf the following day, however, my initial anxiety rejoined my exuberance. I felt more eyes turning towards me with each step I made. \u201cBoys do not play field hockey,\u201d I could hear the girls think. As I trailed behind the girls during the warm-up, the thought of quitting seemed more tempting with each second of silence that passed. But when the whistle blew and the ball was finally in play, I was surprised to see how quickly the gender barrier vanished. Where there was silence and separation at first, I could now see the shared fanaticism through our red faces and hear the emotion in our clamor. At the end of practice, I felt a burning glow of joy overtake my body as I caught my breath on the bench. In that moment, I gradually realized how I should not let obstacles, like gender boundaries in field hockey, hold me back from exploring new opportunities. Realizing the joy I had found in trying the unconventional, I took this experience to the soccer field to take on its new athletic challenges once again. Rather than agonizing over playing time or titles, I simply redirected my focus on the joy and beauty of the sport. Within days, I noticed the same atmosphere of sweat and screams from the turf take hold of the soccer field. Over time, this helped me take in feedback more readily, ask questions about tactics, and try out new skills. With each new improvement I made through this, I slowly began to grasp the value of my new approach to the sport. As a result, I decided to bring the same open, curious, and risk-taking mindset with me to the other opportunities that boarding school holds. In the classroom, I began asking deeper questions to fully comprehend new material. Back in the dorm, I turned the cultural differences between my peers into opportunities to learn from and contribute back to. From truly grasping nucleophile-electrophile reactions in organic chemistry to sharing Dutch \u2018stroopwafels\u2019 with my hall, such moments remind me of why I sacrificed my field hockey gear to go to Deerfield; even as my new mindset gradually led to the grades, friendships, and even athletic achievements I sought before, I realized that I value the exploration, growth and joy behind such successes far more. Now, before I put on my cleats, walk into the classroom or enter my dorm, I do not worry about the successes I might fail to reach or the obstacles that might hold me back. Rather, I pour my heart into such opportunities and take their experiences with me.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0037", "text": "Oreos. On the exterior, a firm chocolate crust; however, when opened, a creamy white center awaits. Unbeknownst to me, a social meaning awaited behind an Oreo that left a lingering poor taste in my mouth. From the seductive, powerful attacks within a tango melody to the upbeat, peppy nature of Top 40 hits, I find myself within a new story with each note. Ballroom and pop music, while vastly different styles, have been interconnected since I was a little girl listening to both Hans Zimmer\u2019s \u2018Discombobulate and One Direction\u2019s Kiss You. In high school, when I shared my musical taste with my black peers, I received confused stares back. \u201cFaith, that is the whitest thing. You are such an Oreo!\u201d a friend exclaimed. I didn\u2019t recognize the connection between two seemingly different commodities until I later learned that an Oreo means a black person who displays characteristics typically associated with white people, therefore betraying their black roots. I never saw ballroom and pop music belonging to a certain race, but the negatively charged implications behind \u2018betraying\u2019 introduced new guilty sensations. Should I embrace my musical interests and face social alienation from those who share my skin tone? Or set aside my so-called white core and conform to the expectations of an African-American woman that have been placed upon me? I didn\u2019t cut music completely out of my life. Being a clarinet player in my band meant being exposed to various musical styles each day. During my freshman year, I decided to challenge myself and perform a solo for the county solo & ensemble festival. Lyrical Composition No. 6 was a piece for which I could play the notes, the rhythms, and everything else on the page. To me, that was all I needed to do, but my band director thought otherwise. \u201cYou\u2019re great at playing the right note at the right time. But where is your interpretation? What can you do to add to this piece?\u201d At first glance, all I saw were measures of black ink permanently etched into the sheet \u2013 resistant to change. How do I add to a composition that exudes such a definitive nature? Then at second glance, I looked below the measures. Beyond the notes, beyond the rhythms, I noticed white space \u2013 unblemished and waiting for me to create my own contribution. Once I stopped and determined what I wanted someone to feel from this composition, I picked up my pencil and wrote in crescendos, decrescendos, breath marks, and other musical markings that I felt needed to be included. I didn\u2019t want to simply regurgitate the black ink, but rather take the audience on a dynamic journey that reaches a climactic precipice. This realization made the distinction between style and stereotype clear. Being categorized as an Oreo was jarring because the documented definition couldn\u2019t simply be erased. Most stereotypes are never fully expunged because they are deeply ingrained in how society views certain races. While I cannot easily change the minds of the many, I can change the mind of my own. I am my own music maker. I will celebrate the intricacies of ballroom music and belt out a One Direction tune as a proud black woman. That is my style. That is my choice of expression. If allowed, stereotypes can snowball until I am completely consumed by my desire to become the black woman society expects. But I refuse to be held down by its grip because I decide my definition of the black experience. My musical interests are not a betrayal that isolates me from my roots, but rather a beautiful addition that enhances my ever-evolving character. Am I an Oreo? Yes, but by my own design. The creamy white center does not represent a betrayal, but rather a blank canvas patiently waiting for my own input. With pencil in hand, I will not hesitate to make my mark.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0038", "text": "I could still hear her words, the words my teacher said as she handed me the packet, \u201cThis is a challenge. But I think you\u2019re up for it.\u201d I held the math packet in my hand. On the cover, the title \u2018Mission Possible!\u2019 screamed at me. I could feel my fingers tingling, and the goosebumps rolling up my arms. I stared at the black italicized letters of the title as I walked home. They seemed to stare back, alluding to the mysteries that lay underneath them. As soon as I got home, I ran to the top bunk where I slept, grabbed a pencil, and signed a mental contract with the packet: \u201cI, Zerubabel, promise to prioritize you, put you above all else in my life, not rest, and not eat until all the problems that lay in your pages are solved.\u201d I was a pretty dramatic 11-year-old. This is but one example of the many challenges I\u2019ve faced throughout my life. My love for challenges and the tenacity with which I approach them was instilled in me through observing my family and through my own experiences. Ten years ago, my family and I packed our belongings, sold everything we had, and flew across the Atlantic to our new home in America. During our first year in Minnesota, we were faced with the omnipresent challenge of money. My sister, rather than having the comfort of her crib, was forced to share a bed with my mom and I. My dad was forced to sleep on a makeshift bed my mom made for him every night, using cushions from a torn and scratchy old sofa. My mom was forced to wake up early and stay up late working, at home, and her minimum wage job. My parents never complained. To them, this was just another stage of life, another challenge to overcome. They worked tirelessly-my mom providing stability by maintaining one job while my dad, the creative one, was always switching between multiple in his pursuit for better pay. With each day, the consequences of their hard work showed; one bed became two, the second bed split into a bunk, and within that little room, each of us had a bed to sleep on. I now reflect on this, and many other challenges my family and I have faced during our ten years in America. I realize that it is through observing how my parents never slowed down that I learned the value of perseverance, through watching my mom\u2019s devotion to a single job that I learned the value of commitment, through my dad\u2019s consistent job switches that I learned the value of ambition, and through observing my sisters willingness to live with less that I learned the value of sacrifice. Through my own experiences, I learned I can apply these values and overcome any challenge that comes my way. My 11-year-old self figured this out after a grueling two months of working on the packet, finishing with all the questions answered. Throughout my time in middle and high school, my value of ambition has led me to take the most challenging courses available at my school. In my community, my value of commitment has allowed me to serve at my church for the past five years. These learned values have molded me into the person I am today and will continue to guide me as I pursue my goals in life. It is because of these values and the way they were instilled in me that I have decided to pursue a career as a surgeon; I know it is through the guidance of these values and the people who first showed them to me that I will be able to achieve this goal.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0039", "text": "M7652-000. Or at least that's how my bike-tire-greased, highlight-yellow, heel-cap-ripping-at-the-seams Chuck-Taylors are supposed to be colored. Freshman year, I tried so hard to keep them that pristine, popular M7652-000 color. Time progressed, however, and dirt, guitar chords, and conversations eventually covered the canvas of the shoes. When I first moved to Houston in eighth grade, I tried to follow the status quo and keep my shoes white. But as various conflicting influences crept into my life--Liberal vs. Conservative; Portland, OR vs. Houston, TX; LCD Sound system vs. Ed Sheeran--I began to realize how important it is to listen to the other side and to maintain the confidence to pursue my passions while inspiring others to do the same. I needed to appreciate Houston's voice and learn from its stories as much as it needed to hear mine, and my shoes grew dirtier every day as each person's testimony helped solidify and expand my own. As I walk, one can first make out \"Cheyenne yo yo\" engulfing the right inner canvas, weaving through clasps and eventually boarding \"PORTLAND!!!\" I met Cheyenne through Freshman year volleyball and we were friends because I tried; I borrowed cowboy boots for football games, didn't discuss my quirky music, and washed my shoes. As I grew, however, it was our differences that brought us together. She forced me to see the other side, forced me to make my own conclusions without the influence of my background or parents. In Portland, opinions are liberally voiced, and it's similar in my community in Houston, except rather than an abundance of Lizzie Fletcher stickers it's \"Come and Take It\". When I moved, I was bombarded by a completely foreign culture. By sophomore year, however, I realized that compromising myself in order to fit in was a mistake. I began vocally expressing my sentiments towards the world to my friends as I learned from theirs. While I introduced my friends to thrift-shopping and wrote articles about more environmentally friendly methods of transportation, they took me to my first line-dance and helped me examine the other side of gun-control in `Agora Coffee House'. As I grew more comfortable with expressing my beliefs, I began heading projects to install a bike rack around campus and took to writing more iconoclastic political pieces in English class. My left shoe houses various meme references, chords from songs I have written, sketches of the latest NASA star cluster discoveries, practice lines of Italian greetings from when I was set on learning it, and \"Lorrie Lake Ln.\" in small cursive letters. Sandalwood, my friends and I call it--a late-night, post-fast food, teen-angst polluted lake. Sandalwood is the cosmos and the meaning of God and the Sisyphus-like emotions that we discuss there. I never knew that Mormons couldn't drink coffee or that Romanians gut an entire pig to feast on for all of winter. Their philosophies, although often dissonating from my own, taught me that it's often beneficial to disagree. When I was hurled into Texas, I was miserable when I didn't express myself within the Kinkaid-bubble. However, I quickly began to realize that I didn't have to like Ed Sheeran or keep my shoes M7652-000 to enjoy life. Learning to embrace and assess so many dissonating ideas has enabled to grow more into myself--it makes me more nonpartisan and has educated me on what it truly means to listen to the other side. Now, whether it's Texas or Oregon, Republican or Democrat, my life is a playlist of contradictions. In college, where everyone works on discovering \"who they are\" or what their place is in the world, I know I can provide not only diversity of thought, but can educate people through my own stories on how crucial it is to maintain an open-minded ideology towards the world and an individual's power to change it.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0040", "text": "On one hot night in a dark room at the heart of Boston, I became friends with 19,580 people in one single moment. We had all journeyed to the TD Garden from wherever we were in our lives to see Tom Petty perform. I knew his music because my mother had shared it with me. It meant something to her and it meant something to me. His music meant something different to every person in that room and all those meanings, all infinite number of them, wrapped around the music notes and existed in harmony on that July night. I had to close my eyes. It was as if I could hear the heartbeats of every person in that room, pulsing along with the rhythm of the music. By sharing his music, Tom Petty gave me a striking awareness of 19,580 people that live and feel alongside each other. Tom Petty will live as long as people feel. Lights flashing beyond my eyelids, I could feel what it was like to live more lives than just my own. Tom Petty's art described his life, but it has weaved its way into those of so many others. My own, my mother's then and when she was my age, and all the strangers around me who didn't seem so strange anymore. We all have to go through our own lives and our own challenges, but just because we have our own lessons to learn doesn't mean we are alone. I looked into the smiles of the crowd, the dancing arms and carefree yes, and realised we were all feeling something of our own. But we were feeling it all together. With the shared heart of others, I can travel vertically through time and horizontally through space. I long to make connections and there are no boundaries that limit how this can be done, not even time and not even space. Imagine trying to count how many people have ever been inspired by the Beatles! Music is an honesty that you embrace more than escape. I sit in front of my piano for hours, copying the rhythm of until it feels right. I'll never tire of hearing another tell me how they're feeling without using any words at all and letting it become part of me. You can't hide from your feelings when someone else is telling them to you. And so I have become a curator of feeling. I am always listening, collecting the art of others. I have stared at paintings until they stared back at me. I cry while I watch almost every film, sometimes just because the characters are nice to each other. I'm as moved by the narrative of my old American Girl Doll books as I am by Dickens. It's all swirls of feelings, of lessons from others that mirror those you need to learn yourself. Art embodies empathy and empathy has become too easy to lose touch with. Art is the same world seen from a different heart. I look at characters or creators and think, \"How did you become the way you are?\" I can look at others and think the same thing. And I have the chance the ask them. Tom Petty did not write \"Breakdown\" just for me. Hard Promises comforts more than just me. I cannot live life from just my own perspective. Art exists in everyone. I embrace my hour-long commute to school as a chance to start conversations through the life that flows from my speakers, using old tunes to understand the world through my neighbors as we talk of our favourite colours or the abstract nature of time. My dad doesn't seem so distant when we talk about our mutual love for The Band. This is how our moments are made. This is how we find the music that surrounds all of us, all in each other.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0041", "text": "My first dream job was to be a pickle truck driver. I saw it in my favorite book, Richard Scarry's \"Cars and Trucks and Things That Go,\" and for some reason, I was absolutely obsessed with the idea of driving a giant pickle. Much to the discontent of my younger sister, I insisted that my parents read us that book as many nights as possible so we could find goldbug, a small little golden bug, on every page. I would imagine the wonderful life I would have: being a pig driving a giant pickle truck across the country, chasing and finding goldbug. I then moved on to wanting to be a Lego Master. Then an architect. Then a surgeon. Then I discovered a real goldbug: gold nanoparticles that can reprogram macrophages to assist in killing tumors,produce clear images of them without sacrificing the subject, and heat them to obliteration. Suddenly the destination of my pickle was clear. I quickly became enveloped by the world of nanomedicine; I scoured articles about liposomes, polymeric micelles, dendrimers, targeting ligands, and self-assembling nanoparticles, all conquering cancer in some exotic way. Completely absorbed, I set out to find a mentor to dive even deeper into these topics. After several rejections, I was immensely grateful to receive an invitation to work alongside Dr. Sangeeta Ray at Johns Hopkins. In the lab, Dr. Ray encouraged a great amount of autonomy to design and implement my own procedures. I chose to attack a problem that affects the entire field of nanomedicine: nanoparticles consistently fail to translate from animal studies into clinical trials. Jumping off recent literature, I set out to see if a pre-dose of a common chemotherapeutic could enhance nanoparticle delivery in aggressive prostate cancer, creating three novel constructs based on three different linear polymers, each using fluorescent dye (although no gold, sorry goldbug!). Though using radioactive isotopes like Gallium and Yttrium would have been incredible, as a 17-year-old, I unfortunately wasn't allowed in the same room as these radioactive materials (even though I took a Geiger counter to a pair of shoes and found them to be slightly dangerous). I hadn't expected my hypothesis to work, as the research project would have ideally been led across two full years. Yet while there are still many optimizations and revisions to be done, I was thrilled to find -- with completely new nanoparticles that may one day mean future trials will use particles with the initials \"RK-1\" -- thatcyclophosphamide did indeed increase nanoparticle delivery to the tumor in a statistically significant way. A secondary, unexpected research project was living alone in Baltimore, a new city to me, surrounded by people much older than I. Even with moving frequently between hotels, AirBnB's, and students' apartments, I strangely reveled in the freedom I had to enjoy my surroundings and form new friendships with graduate school students from the lab. We explored The Inner Harbor at night, attended a concert together one weekend, and even got to watch the Orioles lose (to nobody's surprise). Ironically, it's through these new friendships I discovered something unexpected: what I truly love is sharing research. Whether in a presentation or in a casual conversation, making others interested in science is perhaps more exciting to me than the research itself. This solidified a new pursuit to angle my love for writing towards illuminating science in ways people can understand, adding value to a society that can certainly benefit from more scientific literacy. It seems fitting that my goals are still transforming: in Scarry's book, there is not just one goldbug, there is one on every page. With each new experience, I'm learning that it isn't the goldbug itself, but rather the act of searching for the goldbugs that will encourage, shape, and refine my ever-evolving passions. Regardless of the goldbug I seek -- I know my pickle truck has just begun its journey.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0042", "text": "On Tuesdays and Thursdays, I sit in soil pulling crab grass and borage. I've been a farmer since sophomore year. The farm--managed by my school--is a one-acre plot more accurately described as a garden with chickens. My task today is to pick cherry tomatoes, most of which have ripened. I grab a tray from the shed and walk across pathways to the vine. I created these pathways during junior year, shoveling large heaps of wood-chips into a wheelbarrow, then raking these chips onto the pathways between beds. Our two tomato vines stand three feet tall and extend horizontally at least six feet; they are heavy with small red and orange glistening spheres. I fall into a rhythm, plucking and setting tomatoes in the container, eating several here and there. I recall when I was six, my Mom would send my twin brother and me to the backyard to weed dandelions. We would get distracted and play with our dog or climb the dogwood tree. I recall the awe I felt last week when I harvested a giant sunflower, discovering at least ten potatoes growing in its roots, or when I found a sweet potato the size of a football. I had planted the seed potato pieces last year. I think about jalapenos, how scratches on their skin indicate spiciness level. The satisfaction I felt the first time I ate a piece of food I grew at the farm, a raw green-bean. The pleasure I feel knowing friends and teachers also eat the food I grow; we donate the farm's produce to our school's dining hall and sell it at the weekly farmer's market in the parking lot. After farm, I will work a shift at the Farmer's Market. I will sit, perhaps eating Thai iced-tea-flavored ice cream from another stand, ready to explain where the farm is located, who works it, what we do with unsold food, and, finally, whether the price for a head of lettuce is negotiable (it is). Sometimes, I remember farmers I met during an exchange trip to Yangshuo, China, who were selling pomelos and bamboo shoots. I think about how to me, the difference between one-versus-two dollars for pomelos seems miniscule, but for those farmers, it means a lot. They rely solely on farming to feed their families; I farm for the pleasure of learning what they do out of necessity. As I carry my share of tomatoes to the shed - tomatoes I nurtured from seeds into sprouts into fruits \u2013 I contemplate how much farm has done for me. I can't sit down to a meal without imagining the plants on my plate as seeds and then sprouts, without wondering about the many hands that brought them to my table. Education, to me, means understanding the hidden processes that make up daily life. Playing with the farm chickens - Pablo, Claude, Vincent, Leonardo - and knowing how the coating around an egg works as a natural preservative makes me appreciate my omelet a tad more. Watching weeds that I pulled from various beds slowly decompose into fertilizer in the compost pile makes me consider the roles carbon and nitrogen cycles play in that process. Although I initially joined farm because I wanted to try something new, I quickly found that the work offers a balance with the intellectual work of the rest of my day. The farm connects education with experience; teaching me to see the application of my classroom learning in a real setting. Being able to see the relevance of what I am studying piques my curiosity. I aspire to maintain this connection between education and experience throughout my life, and will always find ways to contribute to my community, locally or globally. I will look for soil to cultivate, using my learning to see and understand more of the world, whether it be the natural environment or the way people live.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0043", "text": "My math teacher turns around to write an equation on the board and a sun pokes out from the collar of her shirt. A Starbucks barista hands me my drink with a hand adorned by a small music note. Where I work, a customer hands me her credit card wearing a permanent flower bracelet. Every day, I am on a scavenger hunt to find women with this kind of permanent art. I'm intrigued by the quotes, dates, symbols, and abstract shapes I see on people that I interact with daily. I've started to ask them questions, an informal interview, as an excuse to talk with these diverse women whose individuality continually inspires me. You can't usually ask the sorts of questions I have been asking and have the sorts of conversations I have been having, so I've created this project to make these kinds of encounters a bit more possible and acceptable. There is no school assignment, no teacher to give me a grade, and no deadline. I don't have a concrete outcome in mind besides talking with a mix of interesting women with interesting tattoos. So far I've conducted fifteen interviews with a range of women from my hometown to Hawaii, teenagers to senior citizens, teachers to spiritual healers. The same set of questions has prompted interviews lasting less than twenty minutes and over two hours. I'm being told stories about deaths of a parent, struggles with cancer, coming out experiences, sexual assaults, and mental illnesses. All of these things that may be taboo in today's society, these women are quite literally wearing on their sleeves. I'm eager to continue these interviews in college and use all of the material I've gathered to show the world the strength and creativity of these wonderful women I've encountered. I want to explore the art and stories behind the permanent transformations of personal landscapes. I attempt this by asking questions about why they decided to get their tattoos, how they were received in the workplace, the reactions from family and friends, and the tattoo's impact on their own femininity. Through these simple questions, I happened upon much greater lessons regarding human interaction, diversity, and connectedness. In my first interview, a local businesswoman told me about her rocky relationship with her mother, her struggles with mental illness, and her friend in jail, within 45 minutes of meeting her and in the middle of a busy Starbucks. An artist educator I worked with told me that getting a tattoo \"was like claiming a part of yourself and making it more visible and unavoidable.\" A model/homeopath said that having a tattoo is like \"giving people a little clue about you.\" A psychologist shared how she wishes that she could turn her tattoos \"on or off like a light switch to match different outfits and occasions.\" I've realized that tattoos show the complex relationship between the personal and the public (and how funny that can be when a Matisse cutout is thought to be phallic, or how a social worker's abstract doodle is interpreted as a tsunami of sticks, alien spaceship, and a billion other things by the children she works with). I've learned so much about the art of storytelling and storytelling through art. I've strengthened relationships with people that had conventional roles in my life and created friendships with some unconventional characters. Most importantly, I've realized that with the willingness to explore a topic and the willingness to accept not knowing where it will go, an idea can become a substantive reality.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0044", "text": "\u201cBiogeochemical. It's a word, I promise!\u201d There are shrieks and shouts in protest and support. Unacceptable insults are thrown, degrees and qualifications are questioned, I think even a piece of my grandmother's famously flakey parantha whizzes past my ear. Everyone is too lazy to take out a dictionary (or even their phones) to look it up, so we just hash it out. And then, I am crowned the victor, a true success in the Merchant household. But it is fleeting, as the small, glossy, plastic tiles, perfectly connected to form my winning word, are snatched out from under me and thrown in a pile with all the disgraced, \u201cunwinning\u201d tiles as we mix for our next game of Bananagrams. It's a similar donnybrook, this time ending with my father arguing that it is okay to use \u201cRambo\u201d as a word (it totally is not). Words and communicating have always been of tremendous importance in my life: from silly games like Bananagrams and our road-trip favorite \u201cword game,\u201d to stunted communication between opposing grandparents, each speaking a different Indian language; from trying to understand the cheesemonger behind the counter with a deep southern drawl (I just want some Camembert!), to shaping a script to make people laugh. Words are moving and changing; they have influence and substance. Words, as I like them, create powerful flavor combinations in a recipe or (hopefully) powerful guffaws from a stand-up joke. They make people laugh with unexpected storylines at an improv show and make people cry with mouthwatering descriptions of crisp green beans lathered with potently salty and delightfully creamy fish sauce vinaigrette at Girl and the Goat. Words create everything I love (except maybe my dog and my mom, but you know, the ideas). The thought that something this small, a word, can combine to create a huge concept, just like each small reaction that makes up different biogeochemical cycles (it's a stretch, I know), is truly amazing. After those aggressive games, my family is quickly able to, in the words of a fellow Nashvillian, \u201cshake it off.\u201d We gather around bowls of my grandmother's steaming rice and cumin-spiced chicken (food is always, always at the center of it), and enjoy. By the end of the meal, our words have changed, changed from the belligerent razzle dazzle of moments before to fart jokes and grandparental concern over the state of our bowels.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0045", "text": "\u201cYou\u2019re such a hipster.\u201d It\u2019s a phrase heard everyday in school hallways across America, and its usage often operates as a conundrum that obscures teenagers\u2019 perceptions of themselves and who they want to be. I, in turn, have struggled immensely with the paradoxical use of this label. Since the onset of my tween years and perhaps even before that, I have constantly carried with me an insistent urge for nonconformity; it has never sat well with me to be like everyone else. Throughout my middle school years, this natural instinct of mine manifested itself in many different ways: jeans tucked into knee-high socks, anything from punk to Harlem renaissance jazz bellowing from my headphones, Palahniuk novels peeking out of my backpack. As my identity shifted, my career as a social renegade flourished, and I found in myself a certain pride in being different and a passion for seeking out eccentric new ways to express myself. With the realization of my newfound passion, my nonconformist qualities were locked in, and I began high school without the usual freshman trepidation about getting labeled or branded. Thereby, I continued my habitual antics, rebelling against the social norm and doing what I could to think freely. In doing so, however, I encountered a particular subculture defined by certain fashion trends and, to some extent, genres of music. This subculture was and still is often associated with the term \u201chipster\u201d and regarded as having a correspondence with the \u201chipster lifestyle.\u201d Moreover, so-called \u201chipsters\u201d are known to have particularly poignant tendencies towards nonconformity. Thus, my rise to the hipster ideal began. I was enamored with various aspects of this subculture, so I enthusiastically donned a beanie and cardigan and crammed every Bon Iver and The Smiths album I could find on to my iPod. Such new developments in my identity perfectly suited my singularity as a nonconformist; no one I knew had adopted this flair. Admittedly, my new garb was somewhat funky, and thus the new look evoked, in both positive and negative renditions, choruses of \u201cYou\u2019re such a hipster!\u201d The attention was extraordinarily gratifying, and I consequently plunged into obsession with my new label, consumed in an effort to sustain my \u201chipster\u201d reputation. Much of my mental vitality was spent on keeping my appearance and status up to a sufficiently \u201chipster\u201d standard. The questions I asked myself about who I wanted to be quickly evolved into \u201cHow can I fit the ideal?\u201d and \u201cHow can I conform?\u201d Herein lies the continual paradox for people who identify themselves as \u201chipsters\u201d and the contradiction that brought me much confusion and uncertainty for parts of my high school career: implicit in the definition of the term \u201chipster\u201d is the prominence of nonconformity in all aspects of a \u201chipster\u2019s\u201d lifestyle. Individualist ideals permeate his clothes, his music, his social behavior, even his politics. Simultaneously, however, one who seeks to identify himself and be identified by others as a \u201chipster\u201d undoubtably strives to conform to the \u201chipster\u201d construct; he tries to fit himself inside an inflexible \u201chipster\u201d box. Nevertheless, as with most paradoxes, the problem at hand does not imply a real contradiction. I found the solution after many months of personal struggle with my own identity. It is not that there is something inherently wrong with the qualities of a \u201chipster.\u201d I have come to understand that a label such as \u201chipster\u201d must never precede my own actual characteristics, and I can never let such a notion inform my identity by itself. Before I ever begin to set words to my character, I have to figure out who I am free from outside influence. The adjectives come much later.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0046", "text": "I had never broken into a car before. We were in Laredo, having just finished our first day at a Habitat for Humanity work site. The Hotchkiss volunteers had already left, off to enjoy some Texas BBQ, leaving me behind with the college kids to clean up. Not until we were stranded did we realize we were locked out of the van. Someone picked a coat hanger out of the dumpster, handed it to me, and took a few steps back. \"Can you do that thing with a coat hanger to unlock it?\" \"Why me?\" I thought. More out of amusement than optimism, I gave it a try. I slid the hanger into the window's seal like I'd seen on crime shows, and spent a few minutes jiggling the apparatus around the inside of the frame. Suddenly, two things simultaneously clicked. One was the lock on the door. (I actually succeeded in springing it.) The other was the realization that I'd been in this type of situation before. In fact, I'd been born into this type of situation. My upbringing has numbed me to unpredictability and chaos. With a family of seven, my home was loud, messy, and spottily supervised. My siblings arguing, the dog barking, the phone ringing\u2014all meant my house was functioning normally. My Dad, a retired Navy pilot, was away half the time. When he was home, he had a parenting style something like a drill sergeant. At the age of nine, I learned how to clear burning oil from the surface of water. My Dad considered this a critical life skill\u2014you know, in case my aircraft carrier should ever get torpedoed. \"The water's on fire! Clear a hole!\" he shouted, tossing me in the lake without warning. While I'm still unconvinced about that particular lesson's practicality, my Dad's overarching message is unequivocally true: much of life is unexpected, and you have to deal with the twists and turns. Living in my family, days rarely unfolded as planned. A bit overlooked, a little pushed around, I learned to roll with reality, negotiate a quick deal, and give the improbable a try. I don't sweat the small stuff, and I definitely don't expect perfect fairness. So what if our dining room table only has six chairs for seven people? Someone learns the importance of punctuality every night. But more than punctuality and a special affinity for musical chairs, my family life has taught me to thrive in situations over which I have no power. Growing up, I never controlled my older siblings, but I learned how to thwart their attempts to control me. I forged alliances, and realigned them as necessary. Sometimes, I was the poor, defenseless little brother; sometimes I was the omniscient elder. Different things to different people, as the situation demanded. I learned to adapt. Back then, these techniques were merely reactions undertaken to ensure my survival. But one day this fall, Dr. Hicks, our Head of School, asked me a question that he hoped all seniors would reflect on throughout the year: \"How can I participate in a thing I do not govern, in the company of people I did not choose?\" The question caught me off guard, much like the question posed to me in Laredo. Then, I realized I knew the answer. I knew why the coat hanger had been handed to me. Growing up as the middle child in my family, I was a vital participant in a thing I did not govern, in the company of people I did not choose. It's family. It's society. And often, it's chaos. You participate by letting go of the small stuff, not expecting order and perfection, and facing the unexpected with confidence, optimism, and preparedness. My family experience taught me to face a serendipitous world with confidence.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0047", "text": "I have a fetish for writing. I\u2019m not talking about crafting prose or verses, or even sentences out of words. But simply constructing letters and characters from strokes of ink gives me immense satisfaction. It\u2019s not quite calligraphy, as I don\u2019t use calligraphic pens or Chinese writing brushes; I prefer it simple, spontaneous, and subconscious. I often find myself crafting characters in the margins of notebooks with a fifty-cent pencil, or tracing letters out of thin air with anything from chopsticks to fingertips. The art of handwriting is a relic in the information era. Why write when one can type? Perhaps the Chinese had an answer before the advent of keyboards. \u201cOne\u2019s handwriting,\u201d said the ancient Chinese, \u201cis a painting of one\u2019s mind.\u201d After all, when I practice my handwriting, I am crafting characters. My character. I particularly enjoy meticulously designing a character, stroke by stroke, and eventually building up, letter by letter, to a quote person\u00adalized in my own voice. Every movement of the pen and every drop\u00adlet of ink all lead to something profound, as if the arches of every \"m\" are doorways to revelations. After all, characters are the build\u00ading blocks of language, and language is the only vehicle through which knowledge unfolds. Thus, in a way, these letters under my pen are themselves representations of knowledge, and the delicate beauty of every letter proves, visually, the intrinsic beauty of know\u00ading. I suppose handwriting reminds me of my conviction in this vi\u00adsual manner: through learning answers are found, lives enriched, and societies bettered. Moreover, perhaps this strange passion in polishing every single character of a word delineates my dedication to learning, testifies my zeal for my conviction, and sketches a crucial stroke of my character. \"We--must--know ... \" the mathematician David Hilbert's voice echoes in resolute cursive at the tip of my pen, as he, addressing German scientists in 1930, propounds the goal of modern intellectu\u00adals. My pen firmly nods in agreement with Hilbert, while my mind again fumbles for the path to knowledge. The versatility of handwriting enthralls me. The Chinese devel\u00adoped many styles -- called hands -- of writing. Fittingly, each hand seems to parallel one of my many academic interests. Characters of the Regular Hand (kai shu), a legible script, serve me well during many long hours when I scratch my head and try to prove a mathematical statement rigorously, as the legibility illuminates my logic on paper. Words of the Running Hand (xing shu), a semi-cursive script, are like the passionate words that I speak before a committee of Model United Nations delegates, propounding a decisive course of action: the words, both spoken and written, are swift and coherent but resolute and emphatic. And strokes of the Cursive Hand (cao shu) resemble those sudden artistic sparks when I deliver a line on stage: free spontaneous, but emphatic syllables travel through the lights like rivers of ink flowing on the page. Yet the fact that the three distinctive hands cooperate so seamlessly, fusing together the glorious culture of writing, is perhaps a fable of learning, a testament that the many talents of the Renaissance Man could all be worthwhile for enriching human society. Such is my methodology: just like I organize my different hands into a neat personal style with my fetish for writing, I can unify my broad interests with my passion for learning. \u201c...We -- will -- know!\u201d Hilbert finishes his adage, as I frantically slice an exclamation mark as the final stroke of this painting of my mind. I must know: for knowing, like well-crafted letters, has an inherent beauty and an intrinsic value. I will know: for my versatile interests in academics will flow like my versatile styles of writing. I must know and I will know: for my fetish for writing is a fetish for learning.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0048", "text": "When I failed math in my sophomore year of high school, a bitter dispute engulfed my household -- \u201cNicolas Yan vs. Mathematics.\u201d I was the plaintiff, appearing pro se, while my father represented the defendant (inanimate as it was). My brother and sister constituted a rather understaffed jury, and my mother presided over the case as judge. In a frightening departure from racial stereotype, I charged Mathematics with the capital offences of being \u201ctoo difficult\u201d and \u201cirrelevant to my aspirations,\u201d citing my recent shortcomings in the subject as evi. dence. My father entered a not guilty plea on the defendant's behalf, for he had always harbored hopes that I would follow in his entrepreneurial footsteps -- and who ever heard of a businessman who wasn't an accomplished mathematician? He argued that because I had fallen sick before my examination and had been unable to sit one of the papers, it would be a travesty of justice to blame my \u201cUngraded\u201d mark on his client. The judge nodded sagely. With heartrending pathos, I recalled how I had studied A-Level Mathematics with calculus a year before the rest of my cohort, bravely grappling with such perverse concepts as the poisson distribution to no avail. I decried the subject's lack of real-life utility and lamented my inability to reconcile further effort with any plausible success; so that to persist with Mathematics would be a Sisyphean endeavor. Since I had no interest in becoming the entrepreneur that my father envisioned, I petitioned the court for academic refuge in the humanities. The members of the jury exchanged sympathetic glances and put their heads together to deliberate. In hushed tones, they weighed the particulars of the case. Then, my sister announced their unanimous decision with magisterial gravity: \"Nicolas shouldn't have to do math if he doesn't want to!\" I was ecstatic; my father distraught. With a bang of her metaphorical gavel, the judge sentenced the defendant to \"Death by Omission\"-- and so I chose my subjects for 11th Grade sans Mathematics. To my father's disappointment, a future in business for me now seemed implausible. Over the next year, however, new evidence that threw the court's initial verdict into question surfaced. Languishing on death row, Mathematics exercised its right to appeal, and so our quasi-court reconvened in the living room. My father reiterated his client's innocence, maintaining that Mathematics was neither \"irrelevant\" nor \"too difficult.\" He proudly recounted how just two months earlier, when my friends had convinced me to join them in creating a business case competition for high school students (clerical note: the loftily-titled New Zealand Secondary Schools Case Competition), I stood in front of the Board of a company and successfully pitched them to sponsor us-- was this not evidence that l could succeed in business? I think I saw a tear roll down his cheek as he implored me to give Mathematics another chance. I considered the truth of his words. While writing a real-world business case for NZSSCC, l had been struck by how mathematical processes actually made sense when deployed in a practical context, and how numbers could tell a story just as vividly as words can. By reviewing business models and comparing financial projections to actual returns, one can read a company's story and identify areas of potential growth; whether the company then took advantage of these opportunities determined its success. It wasn't that my role in organizing NZSSCC had magically taught me to embrace all things mathematical or commercial -- I was still the same person -- but I recognized that no intellectual constraints prevented me from succeeding in Mathematics; I needed only the courage to seize an opportunity for personal growth. I stood up and addressed my family: \u201cI\u2019ll do it.\u201d Then, without waiting for the court\u2019s final verdict, I crossed the room to embrace my father: and the rest, as they (seldom) say, was Mathematics.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0049", "text": "I learned the definition of cancer at the age of fourteen. I was taking my chapter 7 biology test when I came upon the last question, \u201cWhat is cancer?\u201d, to which I answered: \u201cThe abnormal, unrestricted growth of cells.\u201d After handing in the test, I moved on to chapter 8, oblivious then to how earth-shattering such a disease could be. I learned the meaning of cancer two years later. A girl named Kiersten came into my family by way of my oldest brother who had fallen in love with her. I distinctly recall her hair catching the sea breeze as she walked with us along the Jersey shore, a blonde wave in my surrounding family's sea of brunette. Physically, she may have been different, but she redefined what family meant to me. She attended my concerts, went to my award ceremonies, and helped me study for tests. Whenever I needed support, she was there. Little did I know that our roles would be reversed, forever changing my outlook on life. Kiersten was diagnosed with Stage II Hodgkin's lymphoma at the age of 22. Tears and hair fell alike after each of her 20 rounds of chemotherapy as we feared the worst. It was an unbearable tragedy watching someone so vivacious skirt the line between life and death. Her cancer was later classified as refractory, or resistant to treatment. Frustration and despair flooded my mind as I heard this news. And so I prayed. In what universe did this dynamic make any sense? I prayed to God and to even her cancer itself to just leave her alone. Eventually, Kiersten was able to leave the hospital to stay for six weeks at my home. My family and I transformed the house into an antimicrobial sanctuary, protecting Kiersten from any outside illness. I watched TV with her, baked cookies for her, and observed her persistence as she regained strength and achieved remission. We beat biology, time, and death, all at the same time, with cookies, TV, and friendship. Yet I was so concerned with helping Kiersten that I had not realized how she helped me during her battle with cancer. I had been so used to solving my problems intellectually that when it came time to emotionally support someone, I was afraid. I could define cancer, but what do I say to someone with it? There were days where I did not think I could be optimistic in the face of such adversity. But the beauty that resulted from sympathizing as opposed to analyzing and putting aside my own worries and troubles for someone else was an enormous epiphany for me. My problems dissipated into thin air the moment I came home and dropped my books and bags to talk with Kiersten. The more I talked, laughed, smiled, and shared memories with her, the more I began to realize all that she taught me. She influenced me in the fact that she demonstrated the power of loyalty, companionship, and optimism in the face of desperate, life-threatening situations. She showed me the importance of loving to live and living to love. Most of all, she gave me the insight necessary to fully help others not just with intellect and preparation, but with solidarity and compassion. In this way, I became able to help myself and others with not only my brain, but with my heart. And that, in the words of Robert Frost, \u201chas made all the difference.\u201d", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0050", "text": "They covered the precious mahogany coffin with a brown amalgam of rocks, decomposed organisms, and weeds. It was my turn to take the shovel, but I felt too ashamed to dutifully send her off when I had not properly said goodbye. I refused to throw dirt on her. I refused to let go of my grandmother, to accept a death I had not seen coming, to believe that an illness could not only interrupt, but steal a beloved life. When my parents finally revealed to me that my grandmother had been battling liver cancer, I was twelve and I was angry--mostly with myself. They had wanted to protect me--only six years old at the time--from the complex and morose concept of death. However, when the end inevitably arrived, I wasn\u2019t trying to comprehend what dying was; I was trying to understand how I had been able to abandon my sick grandmother in favor of playing with friends and watching TV. Hurt that my parents had deceived me and resentful of my own oblivion, I committed myself to preventing such blindness from resurfacing. I became desperately devoted to my education because I saw knowledge as the key to freeing myself from the chains of ignorance. While learning about cancer in school I promised myself that I would memorize every fact and absorb every detail in textbooks and online medical journals. And as I began to consider my future, I realized that what I learned in school would allow me to silence that which had silenced my grandmother. However, I was focused not with learning itself, but with good grades and high test scores. I started to believe that academic perfection would be the only way to redeem myself in her eyes--to make up for what I had not done as a granddaughter. However, a simple walk on a hiking trail behind my house made me open my own eyes to the truth. Over the years, everything--even honoring my grandmother--had become second to school and grades. As my shoes humbly tapped against the Earth, the towering trees blackened by the forest fire a few years ago, the faintly colorful pebbles embedded in the sidewalk, and the wispy white clouds hanging in the sky reminded me of my small though nonetheless significant part in a larger whole that is humankind and this Earth. Before I could resolve my guilt, I had to broaden my perspective of the world as well as my responsibilities to my fellow humans. Volunteering at a cancer treatment center has helped me discover my path. When I see patients trapped in not only the hospital but also a moment in time by their diseases, I talk to them. For six hours a day, three times a week, Ivana is surrounded by IV stands, empty walls, and busy nurses that quietly yet constantly remind her of her breast cancer. Her face is pale and tired, yet kind--not unlike my grandmother\u2019s. I need only to smile and say hello to see her brighten up as life returns to her face. Upon our first meeting, she opened up about her two sons, her hometown, and her knitting group--no mention of her disease. Without even standing up, the three of us\u2014Ivana, me, and my grandmother--had taken a walk together. Cancer, as powerful and invincible as it may seem, is a mere fraction of a person\u2019s life. It\u2019s easy to forget when one\u2019s mind and body are so weak and vulnerable. I want to be there as an oncologist to remind them to take a walk once in a while, to remember that there\u2019s so much more to life than a disease. While I physically treat their cancer, I want to lend patients emotional support and mental strength to escape the interruption and continue living. Through my work, I can accept the shovel without burying my grandmother\u2019s memory.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0051", "text": "Every Saturday morning, I\u2019d awaken to the smell of crushed garlic and piquant pepper. I would stumble into the kitchen to find my grandma squatting over a large silver bowl, mixing fat lips of fresh cabbages with garlic, salt, and red pepper. That was how the delectable Korean dish, kimchi, was born every weekend at my home. My grandma\u2019s specialty always dominated the dinner table as kimchi filled every plate. And like my grandma who had always been living with us, it seemed as though the luscious smell of garlic would never leave our home. But even the prided recipe was defenseless against the ravages of Alzheimer\u2019s that inflicted my grandma\u2019s mind. Dementia slowly fed on her memories until she became as blank as a brand-new notebook. The ritualistic rigor of Saturday mornings came to a pause, and during dinner, the artificial taste of vacuum-packaged factory kimchi only emphasized the absence of the family tradition. I would look at her and ask, \u201cGrandma, what\u2019s my name?\u201d But she would stare back at me with a clueless expression. Within a year of diagnosis, she lived with us like a total stranger. One day, my mom brought home fresh cabbages and red pepper sauce. She brought out the old silver bowl and poured out the cabbages, smothering them with garlic and salt and pepper. The familiar tangy smell tingled my nose. Gingerly, my grandma stood up from the couch in the living room, and as if lured by the smell, sat by the silver bowl and dug her hands into the spiced cabbages. As her bony hands shredded the green lips, a look of determination grew on her face. Though her withered hands no longer displayed the swiftness and precision they once did, her face showed the aged rigor of a professional. For the first time in years, the smell of garlic filled the air and the rattling of the silver bowl resonated throughout the house. That night, we ate kimchi. It wasn\u2019t perfect; the cabbages were clumsily cut and the garlic was a little too strong. But kimchi had never tasted better. I still remember my grandma putting a piece in my mouth and saying, \u201cHere, Dong Jin. Try it, my boy.\u201d Seeing grandma again this summer, that moment of clarity seemed ephemeral. Her disheveled hair and expressionless face told of the aggressive development of her illness. But holding her hands, looking into her eyes, I could still smell that garlic. The moments of Saturday mornings remain ingrained in my mind. Grandma was an artist who painted the cabbages with strokes of red pepper. Like the sweet taste of kimchi, I hope to capture those memories in my keystrokes as I type away these words. A piece of writing is more than just a piece of writing. It evokes. It inspires. It captures what time takes away. My grandma used to say: \u201cTigers leave furs when they die, humans leave their names.\u201d Her legacy was the smell of garlic that lingered around my house. Mine will be these words.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0052", "text": "When I was very little, I caught the travel bug. It started after my grandparents first brought me to their home in France and I have now been to twenty-nine different countries. Each has given me a unique learning experience. At five, I marveled at the Eiffel Tower in the City of Lights. When I was eight, I stood in the heart of Piazza San Marco feeding hordes of pigeons, then glided down Venetian waterways on sleek gondolas. At thirteen, I saw the ancient, megalithic structure of Stonehenge and walked along the Great Wall of China, amazed that the thousand-year-old stones were still in place. It was through exploring cultures around the world that I first became interested in language. It began with French, which taught me the importance of pronunciation. I remember once asking a store owner in Paris where Rue des Pyramides was. But when I pronounced it PYR\u2013a\u2013mides instead of pyr\u2013A\u2013mides, with more accent on the A, she looked at me bewildered. In the eighth grade, I became fascinated with Spanish and aware of its similarities with English through cognates. Baseball in Spanish, for example, is b\u00e9isbol, which looks different but sounds nearly the same. This was incredible to me as it made speech and comprehension more fluid, and even today I find that cognates come to the rescue when I forget how to say something in Spanish. Then, in high school, I developed an enthusiasm for Chinese. As I studied Chinese at my school, I marveled how if just one stroke was missing from a character, the meaning is lost. I loved how long words were formed by combining simpler characters, so Hu\u01d2 (\u706b) meaning fire and Sh\u0101n (\u5c71) meaning mountain can be joined to create Hu\u01d2sh\u0101n (\u706b\u5c71), which means volcano. I love spending hours at a time practicing the characters and I can feel the beauty and rhythm as I form them. Interestingly, after studying foreign languages, I was further intrigued by my native tongue. Through my love of books and fascination with developing a sesquipedalian lexicon (learning big words), I began to expand my English vocabulary. Studying the definitions prompted me to inquire about their origins, and suddenly I wanted to know all about etymology, the history of words. My freshman year I took a world history class and my love for history grew exponentially. To me, history is like a great novel, and it is especially fascinating because it took place in my own world. But the best dimension that language brought to my life is interpersonal connection. When I speak with people in their native language, I find I can connect with them on a more intimate level. I\u2019ve connected with people in the most unlikely places, finding a Bulgarian painter to use my few Bulgarian words with in the streets of Paris, striking up a conversation in Spanish with an Indian woman who used to work at the Argentinian embassy in Mumbai, and surprising a library worker by asking her a question in her native Mandarin. I want to study foreign language and linguistics in college because, in short, it is something that I know I will use and develop for the rest of my life. I will never stop traveling, so attaining fluency in foreign languages will only benefit me. In the future, I hope to use these skills as the foundation of my work, whether it is in international business, foreign diplomacy, or translation. I think of my journey as best expressed through a Chinese proverb that my teacher taught me, \u201cI am like a chicken eating at a mountain of rice.\u201d Each grain is another word for me to learn as I strive to satisfy my unquenchable thirst for knowledge. Today, I still have the travel bug, and now, it seems, I am addicted to language too.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0053", "text": "This was written for a Common App college application essay prompt that no longer exists, which read: Evaluate a significant experience, risk, achievement, ethical dilemma you have faced and its impact on you. Smeared blood, shredded feathers. Clearly, the bird was dead. But wait, the slight fluctuation of its chest, the slow blinking of its shiny black eyes. No, it was alive. I had been typing an English essay when I heard my cat's loud meows and the flutter of wings. I had turned slightly at the noise and had found the barely breathing bird in front of me. The shock came first. Mind racing, heart beating faster, blood draining from my face. I instinctively reached out my hand to hold it, like a long-lost keepsake from my youth. But then I remembered that birds had life, flesh, blood. Death. Dare I say it out loud? Here, in my own home? Within seconds, my reflexes kicked in. Get over the shock. Gloves, napkins, towels. Band-aid? How does one heal a bird? I rummaged through the house, keeping a wary eye on my cat. Donning yellow rubber gloves, I tentatively picked up the bird. Never mind the cat's hissing and protesting scratches, you need to save the bird. You need to ease its pain. But my mind was blank. I stroked the bird with a paper towel to clear away the blood, see the wound. The wings were crumpled, the feet mangled. A large gash extended close to its jugular rendering its breathing shallow, unsteady. The rising and falling of its small breast slowed. Was the bird dying? No, please, not yet. Why was this feeling so familiar, so tangible? Oh. Yes. The long drive, the green hills, the white church, the funeral. The Chinese mass, the resounding amens, the flower arrangements. Me, crying silently, huddled in the corner. The Hsieh family huddled around the casket. Apologies. So many apologies. Finally, the body lowered to rest. The body. Kari Hsieh. Still familiar, still tangible. Hugging Mrs. Hsieh, I was a ghost, a statue. My brain and my body competed. Emotion wrestled with fact. Kari Hsieh, aged 17, my friend of four years, had died in the Chatsworth Metrolink Crash on Sep. 12, 2008. Kari was dead, I thought. Dead. But I could still save the bird. My frantic actions heightened my senses, mobilized my spirit. Cupping the bird, I ran outside, hoping the cool air outdoors would suture every wound, cause the bird to miraculously fly away. Yet there lay the bird in my hands, still gasping, still dying. Bird, human, human, bird. What was the difference? Both were the same. Mortal. But couldn't I do something? Hold the bird longer, de-claw the cat? I wanted to go to my bedroom, confine myself to tears, replay my memories, never come out. The bird's warmth faded away. Its heartbeat slowed along with its breath. For a long time, I stared thoughtlessly at it, so still in my hands. Slowly, I dug a small hole in the black earth. As it disappeared under handfuls of dirt, my own heart grew stronger, my own breath more steady. The wind, the sky, the dampness of the soil on my hands whispered to me, \u201cThe bird is dead. Kari has passed. But you are alive.\u201d My breath, my heartbeat, my sweat sighed back, \u201cI am alive. I am alive. I am alive.\u201d", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0054", "text": "Bowing down to the porcelain god, I emptied the contents of my stomach. Foaming at the mouth, I was ready to pass out. My body couldn\u2019t stop shaking as I gasped for air, and the room started spinning. Ten minutes prior, I had been eating dinner with my family at a Chinese restaurant, drinking chicken-feet soup. My mom had specifically asked the waitress if there were peanuts in it, because when I was two we found out that I am deathly allergic to them. When the waitress replied no, I went for it. Suddenly I started scratching my neck, feeling the hives that had started to form. I rushed to the restroom to throw up because my throat was itchy and I felt a weight on my chest. I was experiencing anaphylactic shock, which prevented me from taking anything but shallow breaths. I was fighting the one thing that is meant to protect me and keep me alive \u2013 my own body. At five years old, I couldn\u2019t comprehend what had happened. All I knew was that I felt sick, and I was waiting for my mom to give me something to make it better. I thought my parents were superheroes; surely they would be able to make well again. But I became scared when I heard the fear in their voices as they rushed me to the ER. After that incident, I began to fear. I became scared of death, eating, and even my own body. As I grew older, I became paranoid about checking food labels and I avoided eating if I didn\u2019t know what was in the food. I knew what could happen if I ate one wrong thing, and I wasn\u2019t willing to risk it for a snack. Ultimately, that fear turned into resentment; I resented my body for making me an outsider. In the years that followed, this experience and my regular visits to my allergy specialist inspired me to become an allergy specialist. Even though I was probably only ten at the time, I wanted to find a way to help kids like me. I wanted to find a solution so that nobody would have to feel the way I did; nobody deserved to feel that pain, fear, and resentment. As I learned more about the medical world, I became more fascinated with the body\u2019s immune responses, specifically, how a body reacts to allergens. This past summer, I took a month-long course on human immunology at Stanford University. I learned about the different mechanisms and cells that our bodies use in order to fight off pathogens. My desire to major in biology in college has been stimulated by my fascination with the human body, its processes, and the desire to find a way to help people with allergies. I hope that one day I can find a way to stop allergic reactions or at least lessen the symptoms, so that children and adults don\u2019t have to feel the same fear and bitterness that I felt.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0055", "text": "When I was 16, I lived with the Watkins family in Wichita, Kansas. Mrs. Watkins was the coordinator of the foreign exchange student program I was enrolled in. She had a nine year old son named Cody. I would babysit Cody every day after school for at least two to three hours. We would play Scrabble or he would read to me from Charlotte\u2019s Web or The Ugly Duckling. He would talk a lot about his friends and school life, and I would listen to him and ask him the meanings of certain words. He was my first friend in the New World. My second family was the Martinez family, who were friends of the Watkins\u2019s. The host dad Michael was a high school English teacher and the host mom Jennifer (who had me call her \u201cJen\u201d) taught elementary school. She had recently delivered a baby, so she was still in the hospital when I moved into their house. The Martinez family did almost everything together. We made pizza together, watched Shrek on their cozy couch together, and went fishing on Sunday together. On rainy days, Michael, Jen and I would sit on the porch and listen to the rain, talking about our dreams and thoughts. Within two months I was calling them mom and dad. After I finished the exchange student program, I had the option of returning to Korea but I decided to stay in America. I wanted to see new places and meet different people. Since I wasn\u2019t an exchange student anymore, I had the freedom--and burden--of finding a new school and host family on my own. After a few days of thorough investigation, I found the Struiksma family in California. They were a unique group. The host mom Shellie was a single mom who had two of her own sons and two Russian daughters that she had adopted. The kids always had something warm to eat, and were always on their best behavior at home and in school. It would be fair to say that this was all due to Shellie\u2019s upbringing. My room was on the first floor, right in front of Shellie\u2019s hair salon, a small business that she ran out of her home. In the living room were six or seven huge amplifiers and a gigantic chandelier hung from the high ceiling. The kitchen had a bar. At first, the non-stop visits from strangers made me nervous, but soon I got used to them. I remember one night, a couple barged into my room while I was sleeping. It was awkward. After a few months I realized we weren\u2019t the best fit. In the nicest way possible, I told them I had to leave. They understood. The Ortiz family was my fourth family. Kimberly, the host mom, treated me the same way she treated her own son. She made me do chores: I fixed dinner, fed their two dogs Sassy and Lady, and once a week I cleaned the bathroom. I also had to follow some rules: No food in my room, no using the family computer, no lights on after midnight, and no ride unless it was an emergency. The first couple of months were really hard to get used to, but eventually I adjusted. I lived with the Ortiz family for seven months like a monk in the deep forest. However, the host dad Greg\u2019s asthma got worse after winter, so he wanted to move to the countryside. It was unexpected and I only had a week to find a new host family. I asked my friend Danielle if I could live with her until I found a new home. That\u2019s how I met the Dirksen family, my fifth family. The Dirksen family had three kids. They were all different. Danielle liked bitter black coffee, Christian liked energy drinks, and Becca liked sweet lemon tea. Dawn, the host mom didn\u2019t like winter, and Mark, the host dad, didn\u2019t like summer. After dinner, we would all play Wii Sports together. I was the king of bowling, and Dawn was the queen of tennis. I don\u2019t remember a single time that they argued about the games. Afterward, we would gather in the living room and Danielle would play the piano while the rest of us sang hymns. Of course, those 28 months were too short to fully understand all five families, but I learned from and was shaped by each of them. By teaching me English, nine year-old Cody taught me the importance of being able to learn from anyone; the Martinez family showed me the value of spending time together as a family; the Struiksma family taught me to reserve judgment about divorced women and adopted children; Mrs. Ortiz taught me the value of discipline and the Dirksen family taught me the importance of appreciating one another\u2019s different qualities. Getting along with other people is necessary for anyone and living with five families has made me more sensitive to others\u2019 needs: I have learned how to recognize when someone needs to talk, when I should give advice and when to simply listen, and when someone needs to be left alone; in the process, I have become much more adaptable. I\u2019m ready to change, learn, and be shaped by my future families.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0056", "text": "I\u2019ve spent most of my life as an anti-vegetable carboholic. For years, processed snack foods ruled the kitchen kingdom of my household and animal products outnumbered plant-based offerings. My transformation began with my mom\u2019s cancer diagnosis. My mom went on a 100% whole food plant-based diet. I fully embraced this new eating philosophy to show my support. Eager to figure out the whole \u201cvegan\u201d thing, the two of us started binge-watching health documentaries such as \u201cWhat the Health\u201d and \u201cForks Over Knives\u201d. We read all the books by the featured doctors like \u201cThe China Study\u201d and \u201cHow Not To Die\u201d. I became entranced by the world of nutritional science and how certain foods could help prevent cancer or boost metabolism. Each new food I discovered gave me an education on the role diet plays on health. I learned that, by eating sweet potatoes and brown rice, you could cure acne and heart disease. I discovered eating leafy greens with citrus fruits could boost iron absorption rates. I loved pairing my foods to create the perfect macronutrient balance. Did you know beans and rice make a complete protein? Food has also turned me into a sustainability nut. Living plant-based also saves the planet from the impact of animal agriculture. For the same amount of land space, a farmer can produce 200 kilograms of soybeans versus 16 kilograms of beef. I do my part to have as small of an ecological footprint as I can. I stopped using plastic snack bags and instead turned to reusable beeswax wraps. My favorite reusable appliance is my foldable straw. If I am going to nourish my body, shouldn\u2019t I also want to nourish the earth? My journey toward healthy living led me to becoming co-leader of the Northern Nevada PlantPure Pod, \u201cBiggest Little Plant Pod\u201d, a group dedicated to spreading the message about the whole food plant-based lifestyle. We are currently working on a restaurant campaign to encourage local eateries to create a plant-based, oil-free menu option and become PlantPure certified. After discovering how many restaurants use oil in their cooking, I decided I needed to open a plant-based oil free cafe to make up for this gap. My dream is to open up my very own affordable oatmeal cafe based on my Instagram page, morning_mOATivations. And I know that oatmeal isn\u2019t the sexiest superfood out there, so here\u2019s my sales pitch: I\u2019m going to make oatmeal the Beyonce of the breakfast world- sweet, sassy, and power packed. This allows me to educate people about nutritional science through the stomach. Finally, I am a strong proponent of hands-on experience for learning what good food looks and tastes like, so cooking is one of my favorite ways to teach the benefits of a plant-based lifestyle. Using my taste buds as my textbook to learn which flavors work together and which ones don\u2019t helps me educate, as I\u2019ve found that information tends to stick in a person\u2019s mind once they\u2019ve experienced healthy, delicious foods with their own senses. Our society has taught us that delicious food has to make us feel guilty, when that is simply not the case. The best feeling in the world is falling in love with a dish and then learning all the health benefits that it provides the body. While my classmates complain about being tired, I have more energy because my body is finally getting the right macros, vitamins, and minerals it needs. This has allowed me to push myself harder physically, excelling in running and earning my high school Cross Country team\u2019s Most Improved award. I\u2019m still a picky eater. But the foods I am particular about have changed. Rather than a carboholic, I choose to call myself a vegeholic.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0057", "text": "Meditation over a flaxen sunset with a friend and parmesan-topped spaghetti for dinner \u2014 \u201c14.\u201d Assignments piling up on my desk as a high fever keeps me sick at home \u2014 \u201c3.\u201d Taking a photo excursion through downtown Seattle for a Spanish project \u2014 \u201c15.\u201d For the past 700 days and counting, the Happiness Spreadsheet has been my digital collection for documenting numerical, descriptive, and graphical representations of my happiness. Its instructions are simple: Open the Google Sheet, enter a number between 1 and 20 that best represents my level of happiness, and write a short comment describing the day. But the practical aspect of the spreadsheet is only a piece of what it has represented in my life. A \u201c14\u201d etched on November 15, 2018, marked the first Lakeside Cooking on the Stove Club meeting. What had started as a farcical proposition of mine transformed into a playground where high school classmates and I convene every two weeks to prepare a savory afternoon snack for ourselves. A few months later, a \u201c16\u201d scribbled on February 27, 2019, marked the completion of a fence my Spanish class and I constructed for the dusty soccer field at a small Colombian village. Hard-fought days of mixing cement and transporting supplies had paid off for the affectionate community we had immediately come to love. The Happiness Spreadsheet doesn\u2019t only reflect my own thoughts and emotions; it is an illustration of the fulfillment I get from gifting happiness to others. If happiness paves the roads of my life, my family is the city intertwined by those roads \u2014 each member a distinct neighborhood, a distinct story. In times of stress, whether it be studying for an upcoming derivatives test or presenting my research at an international conference, I dash to my father for help. Coming from the dusty, people-packed backstreets of Thiruvananthapuram, India, he guides me in looking past the chaos and noticing the hidden accomplishments that lie in the corners. When in need of confidence, I find my mother, who taps her experiences living in her tranquil and sturdy tatami-covered home in Hiroshima, Japan, helping me prepare for my first high school dance or my final match in a tennis tournament. Whenever my Happiness Spreadsheet numbers touch lows, my family is always there to level me out to \u201c10.\u201d The Happiness Spreadsheet is also a battery monitor for enthusiasm. On occasion, it is on full charge, like when I touched the last chord on the piano for my composition's winner recital or when, one frosty Friday morning, I convinced a teacher to play over the school speakers a holiday medley I\u2019d recorded with a friend. Other times, the battery is depleted, and I am frustrated by writer's block, when not a single melody, chord, or musical construct crosses my mind. The Happiness Spreadsheet can be a hall of fame, but it can likewise be a catalog of mistakes, burdens, and grueling challenges. The spreadsheet began on a typical school day when I left my physics class following the most confusing test I\u2019d taken. The idea was born spontaneously at lunch, and I asked two of my friends if they were interested in pursuing this exercise with me. We thought the practice would last only a couple of weeks or months at most, but after reaching 700 days, we now wonder if we\u2019ll ever stop. To this day, I ponder its full importance in my life. With every new number I enter, I recognize that each entry is not what defines me; rather, it is the ever-growing line connecting all the data points that reflects who I am today. With every valley, I force myself onward and with every mountain's peak, I recognize the valleys I\u2019ve crossed to reach the summit. Where will the Happiness Spreadsheet take me next?", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0058", "text": "I sit, cradled by the two largest branches of the Newton Pippin Tree, watching the ether. The Green Mountains of Vermont stretch out indefinitely, and from my elevated vantage point, I feel as though we are peers, motionless in solidarity. I\u2019ve lost my corporeal form and instead, while watching invisible currents drive white leviathans across the sky, have drifted up into the epistemological stream; completely alone with my questions, diving for answers. But a few months ago, I would have considered this an utter waste of time. Prior to attending Mountain School, my paradigm was substantially limited; opinions, prejudices, and ideas shaped by the testosterone-rich environment of Landon School. I was herded by result-oriented, fast-paced, technologically-reliant parameters towards psychology and neuroscience (the NIH, a mere 2.11 mile run from my school, is like a beacon on a hill). I was taught that one\u2019s paramount accomplishment should be specialization. Subconsciously I knew this was not who I wanted to be and seized the chance to apply to the Mountain School. Upon my arrival, though, I immediately felt I did not belong. I found the general atmosphere of hunky-dory acceptance foreign and incredibly unnerving. So, rather than engage, I retreated to what was most comfortable: sports and work. In the second week, the perfect aggregate of the two, a Broomball tournament, was set to occur. Though I had never played before, I had a distinct vision for it, so decided to organize it. That night, the glow-in-the-dark ball skittered across the ice. My opponent and I, brooms in hand, charged forward. We collided and I banana-peeled, my head taking the brunt of the impact. Stubborn as I was, even with a concussion, I wanted to remain in class and do everything my peers did, but my healing brain protested. My teachers didn\u2019t quite know what to do with me, so, no longer confined to a classroom if I didn\u2019t want to be, I was in limbo. I began wandering around campus with no company except my thoughts. Occasionally, Zora, my English teacher\u2019s dog, would tag along and we\u2019d walk for miles in each other's silent company. Other times, I found myself pruning the orchard, feeding the school\u2019s wood furnaces, or my new favorite activity, splitting wood. Throughout those days, I created a new-found sense of home in my head. However, thinking on my own wasn\u2019t enough; I needed more perspectives. I organized raucous late-night discussions about everything from medieval war machines to political theory and randomly challenged my friends to \u201csay something outrageous and defend it.\u201d And whether we achieve profundity or not, I find myself enjoying the act of discourse itself. As Thoreau writes, \u201cLet the daily tide leave some deposit on these pages, as it leaves, the waves may cast up pearls.\u201d I have always loved ideas, but now understand what it means to ride their waves, to let them breathe and become something other than just answers to immediate problems. I am most enamored by ideas that cultivate ingenious and practical enrichments for humanity. I enjoy picking some conundrum, large or small, and puzzling out a solution. Returning from a cross country meet recently, my friend and I, serendipitously, designed a socially responsible disposable water bottle completely on accident. Now we hope to create it. I am still interested in psychology and neuroscience, but also desire to incorporate contemplative thought into this work, analyzing enigmas from many different perspectives. My internships at the NIH and the National Hospital for Neuroscience and Neurosurgery in London have offered me valuable exposure to research and medicine. But I have come to realize that neither of my previous intended professions allow me to expand consciousness in the way I would prefer. After much soul-searching, I have landed on behavioral economics as the perfect synergy of the fields I love. All it took was a knock on the head.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0059", "text": "Before I came to America, I drank Puer Tea with my father every morning in my bedroom, sitting cross-legged on Suzhou-silk mats beside a view of the Lakeside reservoir. Beside a dark end table, we picked up teacups as the mild aroma greeted our noses. As we faced the French window, my father would share the news he read in China Daily: the Syrian civil war, climate change, and gender equality in Hollywood. Most of the time, I only listened. With each piece of news, my curiosity piqued. Secretly, I made a decision that I wanted to be the one to discuss the news with him from my perspective. So, I decided to study in America to learn more about the world. After one year\u2019s extensive research and hours of interviews, I came to America for 9th grade and moved in with a host family. But, my new room lacked stories and cups of tea. Fortunately, I found Blue House Cafe on my walk home from church, and started studying there. With white walls, comfortable sofas, and high stools, Blue House is spacious and bright. Hearing people\u2019s stories and looking at their warm smiles when they taste various pastries as I sat by the window, I watched as a production designer scouted locations for his film, or a painter took notes while brainstorming for his freehand brushwork of Blue House. With a cup of coffee, I dig into differential and parametric equations for my upcoming AP Calculus test, learn the nuances of public speaking by watching Michael Sandel\u2019s Justice lectures on my laptop, and plan fundraising events for my non-profit. I\u2019ve also learned by watching leaders host meetings at the rectangle conference table at the back of the cafe and I learn from the leaders of meetings, watching as they hold the edge of the table and express their ideas. Similarly, as president of the International Students Club, I invited my teammates to have meetings with me at the cafe. Coordinating the schedule with other members in Blue House has become a frequent event. Consuming several cups of coffee, my team and I have planned Lunar New Year events, field trip to the Golden Gate Bridge, and Chinese lunch in school to help international students feel more at home. Straightening my back and bracing my shoulders, I stood up behind the conference table and expressed my creative ideas passionately. After each meeting, we shared buttermilk coffee-cake. In my spot next to the window, I also witnessed different kinds of people. I viewed visitors dragging their luggage, women carrying shopping bags, and people wandering in tattered clothes --the diversity of San Francisco. Two years ago I saw volunteers wearing City Impact shirts offering sandwiches and hot chocolate to homeless people outside of the cafe. I investigated more about City Impact and eventually signed up to volunteer. No longer was I a bystander. At holiday outreach events, I prepared and delivered food to homeless people. While sharing my coffee, I listened to a story from an older Chinese man who told me, in Mandarin, how he had been abandoned by his children and felt lonely. Last summer, I returned to Xiamen, China, and taught my father how to drink coffee. Now, a Chemex and teapot are both on the end table. Instead of simply listening, I shared my experiences as a club president, a community leader, and a volunteer. I showed him my business plan and prototypes. My father raised his cup of coffee and made a toast to me, \u201cGood girl! I am so proud of you.\u201d Then, he patted my head as before. Together, we emptied our cups while the smell of coffee lingered.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0060", "text": "I am a dancer. It\u2019s something I\u2019ve only learned recently, but it\u2019s my reality. My story is not one of the typical dancer: I was not the student who couldn\u2019t sit still or pay attention in class, only to find focus and expression through movement. That just isn\u2019t my story. I\u2019ve always been able to sit still, stay engaged, and absorb what my teachers threw at me: I was a \u201cgood student\u201d. I would sit at my desk, listen and learn, then go home and do my homework. But, the entire time I embodied that \u201cgood student\u201d, I felt like something was missing. It wasn\u2019t physical health\u2014I stayed active and had a healthy diet. But, there was a disconnect between my mind and body. For the longest time, I felt like I lived from the neck up. I love to learn \u2014I always have\u2014but before dance, I was only focused on learning with my head. At the beginning of my junior year I picked up dance. It started on a bit of a whim: I liked watching and I thought learning some moves would help me impress girls. So, I grabbed a like-minded friend and started attending classes. Once I began, I was surprised by how much I liked it. I had discovered something in it that I hadn\u2019t been expecting; I found that I was learning with my entire body. Not to mention that at the same time, I was learning about my body itself\u2014how it worked and moved, every little muscle and bone. My friend eventually quit, but I kept attending class, and began to add more and more classes to my schedule. I dove deep into dance and took every opportunity that I could find to learn. Dancing was like returning to my childhood, like learning to take those first steps. I was learning how my body moved, how to challenge and develop it, and how to interact with other people through a new language. It challenged me in a completely new way and I\u2019ve loved every second of it. Dance has changed my life. Through it, I\u2019ve met people who challenge my beliefs about how the world works and how we all learn. It\u2019s shown me many different paths and ways to navigate through life. I\u2019ve found role models in my teachers who engage me mentally and physically and push me to grow; teachers who I am lucky enough to also call my friends. I\u2019ve found a global and local community of hardworking, intelligent, and skilled people who are always hungry to learn; a community where everyone is accepted, because dance transcends everything\u2014race, class, gender, religion, even language. And for the first time, I\u2019ve found a community where I am fully supported and accepted; a feeling, it seems, that I had never experienced before. Through all of this, I have found a part of my identity and I am proud to call myself a dancer because of it.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0061", "text": "Winter is coming. And as the chilly season approaches, my high school will soon be invaded by smoothing\u2026abominable. Lovesick teenagers armed with cheesy posters and grocery store flowers. Because at my school, winter is the harbinger of the Winter Formal Dance. But as girls secretly gossip as to who they wish to ask them and guys muster up the courage to do so, I spend another year resigning myself to not going. Whenever someone finds out that I\u2019m skipping it, they never assume that it\u2019s because I can\u2019t afford to. Which is why I am always asked this same question: \u201cWhy not? What are you too poor? Hahaha!\u201d The only way I can respond is to laugh it off and to make up an excuse. At times like these, however, living in a homogenously wealthy community can get disheartening because of how indelicate the kids here can be. But they aren\u2019t simply mean for the sake of being petty, they just don\u2019t realize how tactless they are being. Especially since the few less fortunate members of my community hide their situation for fear of being labelled as different. And though hiding the fact that we are poor may seem to work, we\u2019re really just avoiding the problem. The problem being that we shouldn\u2019t be made to feel ashamed of being poor. And the only way to fix this problem is to better inform our community about our struggles. If we want change, it has to start with us. We have to stop hiding the fact that we are poor because it isn\u2019t something to be ashamed of. And by learning our stories and our situations, my community will strive for better understanding and work to be more considerate towards those less fortunate than they are. How do I know this? Because it\u2019s already begun. There has been effort by the less fortunate members of my community to share their stories in person and on social media. I was inspired by this movement and confessed to my own friends about why I never got to the dance. And through this process, I found out how wonderful my community is. Because my friends are all so well-off, they\u2019ve never seen money to be important. Something that I myself am guilty of. Since I never had enough, I\u2019d always viewed money as something sacred. Which is why I never learned to be generous. But my friends, after I told them my reason, offered my $60 each so that I could go. As one of my friends put it: \u201cI\u2019d rather spend money on letting you have a good time rather than spending it on myself.\u201d Despite my intention to teach my community, it was I who was humbled. I had never realized how stingy I had been until I was shown generosity. I hope to never again be as unaware as I had thought my community to be. I must be better, because I too am part of my community.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0062", "text": "I was immensely disappointed when I didn\u2019t hear my name as the winners were being announced. A few seconds before, I was so excited that it might have seemed as if I was waiting to win the Nobel Prize, instead of an award for my project in mathematics at the Scientific and Research Council of Turkey National Projects Competition. Throughout the 4 days of the Project Fair, I presented my project to over 100 visitors. I was even offered a mentorship by an accomplished mathematics professor, who also visited the fair and seemed very interested in my project, in which I had developed two alternative approaches to methods for expressing power sums in a formula, a complex topic in mathematics previously worked on but that could not be simplified. I was confident, because everyone, including the other contestants, thought that my project would win. Overconfidence, as it turns out, can sometimes lead to great disappointments. I was not sure why I actually wanted to win this contest: to be giving the honor of winning the contest or to have my mathematical findings recognized nationally? When they were announcing the winners, I realized that having my work appreciated was what mattered the most. Some of the projects that Turkish scientific institutions overlooked went on to later win recognition internationally; so my project might not have actually been insufficient, but it just did not win. The fact that this competition was the only place in Turkey where I could truly demonstrate my competence and skills in mathematics on such a stage was the reason why I so badly wanted to excel at it. However, failing to get my project recognized showed me that there will be times in life when I will lose, just like there will be times when I win. Fortunately, I was raised in a family where I was taught that I should not be discouraged by failure; rather I should learn lessons and build myself up through them. Further, my failure made me more sensitive to the current conditions in Turkey, in terms of the political difficulties, threats of terror and unrest, and constraints on scientific development. The current atmosphere in the country is in many ways quite opposite from the view of the world that I have learned as an IB student. So how can I, as an international-mind and creative thinker, reach my true potential in an environment that is in many unsuitable at present, and how can I be useful in the future to help us overcome the challenges we currently face? Answer: by carrying out my studies in a place where science and development are put above all else. This would allow me to pursue my passions without the current limitations of the Turkish system, in which I must, for example, choose between biology and mathematics, instead of being able to study both, which study abroad will allow me to do. Something one hears less every day in Turkey is \u201cI want to make a difference,\u201d due to those constant distractions that people here have to deal with daily, and which make it much more difficult to focus on progressing. I do, however, want to make a difference as a woman and an aspiring scientist, two parts of my identity that unfortunately are not allowed their full expression in my country. Because I love my community and the many remarkable people in it, and because I have gained so much from them, I want to give back by contributing to science, being a force for positive change in my homeland, and inspiring Turkish women to take part in the scientific world. Long story short, I interpreted the outcome of this competition as a failure before, but I have come to realize more each day that the broader perspective in this incident inspired in me has put me on the road to success.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0063", "text": "Growing up with a stutter was difficult. My thoughts were always fully formed, but the words would get stuck. The harder I tried to force them out, the more they would jam up, like train cars going off a track. Sometimes kids would laugh or make fun of my stutter, but mostly they just ignored me. They had better things to do than wait to hear my ideas, so they assumed I had none worth hearing. Eventually, I gave up talking to people entirely. They thought I was stupid, and, soon enough, I thought so too. My parents signed me up to play soccer in the hopes that being part of a team would help me make friends. I wasn\u2019t particularly athletic, and I could barely kick a ball. But soccer is a game anyone can play. On the field, my stutter didn\u2019t matter. I discovered that I could lead, quietly, through action, rather than words. Eventually, speech therapy resolved by stutter, but it was on the soccer field that I learned how to be me. One of my teammates had a brother with Down Syndrome. Every season, he came to our games to watch from the sidelines. He had cleats and a ball that he kicked around by himself, but because he also had an intellectual disability, there was no room for him on our team or anywhere else. I realized that although soccer is a sport for everyone, not everyone is included in the sport. I understood the pain of being excluded simply because of an inability to communicate. So, in February of 2015, I launched GOALS (Giving Opportunities to All who Love Soccer), a unified soccer program for kids with and without special needs. GOALS partners youth athletes who have intellectual disabilities with neurotypical peer buddies. The athletes and buddies play together, as unified pairs, in small-sided, non-competitive scrimmages. The first GOALS program had just nine participants. Today, we hold GOALS events twice a month for fifty players of all abilities. GOALS has impacted over 400 kids and is now an official partner of Special Olympics Arizona. But I don\u2019t measure the success of GOALS by the numbers. Success comes in the form of an athlete like Josh*, who came reluctantly to his first GOALS event, having never tried sports before, preferring instead to play video games by himself. Josh was surprised to find that he loves soccer, and he looks forward to playing with his friends at every GOALS event, where his diagnosis of autism doesn\u2019t define him. What makes GOALS special is that it is not a community service program for kids with intellectual disabilities. GOALS is a program that serves the entire community, understanding that our community includes people of all abilities. GOALS champions people for what they bring to the community, rather than defining them by what they take. GOALS breaks down the barriers that separate kids with special needs from their neurotypical peers, creating intentional connections that allow true friendships to develop. For many kids, GOALS is the first time they experience genuine acceptance. Through sports, we have the capacity to create something better than tolerance. Tolerance is for summer heat, visits to the doctor\u2019s office, and lines at the bank. People, though, deserve more than tolerance. People deserve acceptance. So often, kids with intellectual disabilities are isolated socially, for no other reason than that kids pass them by. But special needs kids can be incredibly smart and talented. We just need to slow down long enough to get to know them. Some need more time to turn their ideas into words, but we can afford to have those slower conversations. That is why, for me, unified sports will be a lifelong passion. Through sports, anyone can communicate that each of us is valued, each of us is a part of the time, and each of us is a friend worth having.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0064", "text": "Ocean waves of panic perspired in my palms and a 6.3 magnitude earthquake trembled in my hands. I was afraid but spoke deliberately; fear would not stop me from sharing my first vulnerable poem: \u2026I want my insides\u2014dry, dead wood\u2014to be lit with a match, and no water could ever put me out, no hurricane of sadness, no gentle rainstorm of doubt could stop the heat inside\u2026 When finished, I looked up to see unblinking eyes and tears running down my teacher\u2019s face. In that moment, I became a writer. I recited the poem near the end of my creative writing class my sophomore year. Throughout the class, students focused on one genre, and choosing to stay on the safe path, I focused on fiction, which I had written since I could hold a pencil. Although I admired poetry and the way a poet in a few lines could convey the feelings expressed in 300 pages of a novel, it intimidated me. I feared I did not have the skill to craft with such imagery, detail, and purpose. When a poet in my class shared her work, I was taken aback by her striking metaphors and cryptic imagery. But what shocked me most was that she got her message across. Suddenly, I had an epiphany: writing didn\u2019t have to follow all the rules. A writer could take a feeling and express it through unique images. It\u2019s not about the picture on the page, but what the picture makes the reader feel. With zeal and inspiration, I began to use literary devices and images with purpose. I aimed to convey emotion through images. Most of my writing before told the stories of fictional characters, but in my poem, I channeled all my confusion and stress. I poured my soul onto the page. When I read my poem out load, several changes occurred in me. I freed myself from the fear of taking risks. My poem gave me the courage to transfer to a new school, a decision which continued to build my confidence and creativity. Before, I had always written as a means of escape, as a way to create distractions by hiding in a world that was not my own. But in writing the poem, I confronted my problems and answered questions. Poetry taught me how to be brave, how to get right up to the edge of a cliff and embrace vulnerability and the fear of the fall. I also realized the impact my writing could have on others. Before, I did not enjoy sharing my writing because I created stories for my own amusement and pleasure. Now my eyes are open to the power of words. I do not view a story or poem as an individual experience, but as a unifying tie amongst people. Writing is about observing the world and using my life stories and emotions to help listeners and readers feel less lost and alone. The tears which fell down my teacher\u2019s face and the wide eyes of my peers were not because they had the same experience as me, but because they paralleled the feeling I created with their own life stories. In revealing the deepest parts of myself, the class contemplated their own deeper thoughts. Now I write to examine; now I write to understand; now I write to comfort the chaos. Etching pieces of myself into the grooves and curves of each sentence. I do not expect others to connect with the story but rather connect with the emotion. I now know each story or poem is a heart, beating and alive, raw and utterly vulnerable, but also stretching out in a network of veins drawing readers back to the center, unifying one another.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0065", "text": "\u201cHow prone to doubt, how cautious are the wise!\u201d -Homer \u201cD\u2019oh!\u201d -Homer Simpson I\u2019m not a philosopher; eloquence eludes me, the meaning of life is unquestioned, and thinking, beyond what is required to carry out a potential, is postponed to a more leisurely time. I\u2019ve experienced doubt, and proceeded with caution; and in my experience, I\u2019ve learned to discard unnecessary thought and conventional wisdom in favor of progress. Philosophy amounts to nothing unless it results in action. \u201cYou\u2019re kidding.\u201d Scanning my schedule, my classmate shakes her head. \u201cWhy didn\u2019t you take Dual Credit?\u201d During Junior year, my high school began to incentivize Dual Credit courses with a GPA multiplier. Advertised to be less demanding than an AP class, Dual Credit was extolled as the wise man\u2019s curriculum. So, mustering all the wisdom I had, I took 6 AP classes, and frankly, I enjoyed their depth. When it comes to education, I\u2019m not cautious \u2013 and I\u2019m prone to doubt. I just act. If I want chemistry, then I get chemistry; if I\u2019m intrigued by psychology, then I pursue psychology. There is no point in pondering the inevitable; I am determined to take educational opportunities. I\u2019ll judge the difficulty for myself after I complete it. The practice of prioritizing action has proved useful in my pursuits. In ninth grade, I could have doubted my capability; instead I ran for office in the school\u2019s health club and earned a position in the eleventh grade. That year, there was a debate amongst the members over meeting schedules: if the Technology Students Association meeting coincided with ours, how would we attract new members? As the club officers weighed the costs and benefits amongst themselves, I left the meeting and signed up for the technology club, discussed an agreement, and voted for the technology club to move its meetings to the second half of lunch before scheduling the Health club meetings for the first half. Did it require thinking? No. Eloquence? Hardly. Contrary to the anticipated speeches and club-based patriotism, it only took clear action and a request to solve the conflict. Attendance increased, and as a bonus, I enjoyed a continued membership with both organizations. Beyond the sphere of public education, doubt-free determination facilitated my impact in the community. I am seventeen; I cannot vote in the upcoming elections. However, that does not mean I will hesitate to make a mark with my city. Small actions, from teaching addition to a church member\u2019s kindergartener to tutoring three classmates for the SAT, matter in the long run. Can a teenage end world hunger? Doubtful; but by pulling weeds from the community garden, I can further progress one step at a time. Not all actions end successfully. However, between cautious wisdom and failure, I choose action. I don\u2019t fancy myself as wise; I\u2019m not prone to doubt, nor am I perpetually cautious. I simply pursue my goal. As the wiser Homer has taught America, when torn between success and potential peril, one must simply \u201cD\u2019oh.\u201d", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0066", "text": "Most airplanes are constructed with seats in rows of two or three. Mathematically, that means no matter the configuration, someone in my family of five has to sit by a stranger. Ever since I was little, I always asked to be that person. Perhaps it\u2019s the optimistic middle child in me, but I always considered the greatest possibility was that I could meet someone remarkable, and that the conversation could be anything on the spectrum from slightly interesting to life-changing. From the time I could speak, I began to realize that overcoming communication barriers was an integral key to unlocking the enormous potential in constructing meaningful relationships with others. My father is a successful scientist, but he has also been profoundly deaf since birth. My childhood was spent understanding his intelligence while still struggling at times to convey basic needs because I was choosing words that were too difficult to lipread and that I couldn\u2019t yet write. As a kid, I learned how to continually recalibrate my own approach to overcome the challenge of constantly being misunderstood. My ability to build a relationship with my father was contingent on spending a lifetime navigating around the communication barriers that exist for someone who cannot hear. At the time I didn\u2019t foresee I was developing an aptitude for communication skills that would be critical for succeeding in so many other important areas. Since kindergarten, I have loved Chinese culture. My mom got tired of me requesting panda birthday cakes year after year and seeing me dressed as a panda each Halloween until I grew out of every costume. In second grade, I convinced the owner of a noodle house to give me two Chinese lanterns that still hang in my room today. In my junior year of high school, I earned a competitive scholarship from the U.S. State Department to study abroad for the summer learning Mandarin and immersing myself in eastern culture. Being dropped into Chengdu, China when you don\u2019t speak the language fluently and being cut off from all communication back home was not all the cuddly pandas and Tai chi in the park that I had fantasized. Once again, I found myself a toddler, unable to communicate basic needs. I wondered, \u201cAre humans really supposed to eat all the foods you\u2019re giving me?\u201d I quickly learned the Chinese education system is one of unparalleled expectations, not for the meek. With every grade a student receives, they can see their successes or failures broadcasted on a board in front of the class. Each new day tested my adaptability, my resilience, and my digestive system. I, for the first time, realized what it must feel like to be my father on the other side of the communication barrier, not just trying to express my needs, but trying to really understand what others are saying. At the end of the program I was told I had been unanimously voted by my school administration in China to represent the scholarship recipients and deliver a speech on their behalf to over 500 people\u2026 in Chinese. The flight was now descending after so many remarkable experiences and conversations with strangers. Throughout my life, I have learned that the path to overcoming communication barriers is to will oneself through them. One must embrace it all and say \u201cyes\u201d to every new and uncomfortable experience. In the end, I returned home with a cultural awareness beyond expectation, possessing lifelong friendships with former strangers whom I now communicate with in their native language, and surprisingly loving the taste of rabbit eyeballs and cow intestines. I am so grateful to have learned and confirmed in my life that stepping out of my comfort zone can, in fact, lead to experiences anywhere on the spectrum from slightly interesting to life-changing. On the flight home from China I, of course, chose to sit next to a stranger\u2026 and it didn\u2019t disappoint.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0067", "text": "When we are small, the world seems infinite. Personally, I believed that Germany was adjacent to Wisconsin until I was 8. But eventually, physical growth lends itself to a greater understanding of the world around us as we become exposed to truths of society. It was easy for me to justify my mom\u2019s long work hours and our pocket-sized apartment filled with black mold when I did not know that everyone else had something \u201cbetter\u201d\u2014and for me, it never felt like I was worse off, it just felt different. My friend had blue eyes and a house. I had brown eyes and I got free lunch. But as I learned more about the world, I found that those differences became difficult to overlook as people grew up and closed their minds in order to conform to their roles in society. My mom\u2019s young age, financial status, and lack of a degree, as well as my lack of a second parent were all characteristics I saw in people who were portrayed to me as failures. It was a harsh reality to accept, because my mom was anything but a failure; she worked tirelessly, prioritizing my needs over hers and resigning herself to fast food jobs because she could not go to college while supporting a newborn. She grew up much faster than any 20-year-old should have to. And yet, for all her strength, we received looks of pity and degradation. But for all the vitriol, we steadfastly refused to let the judgments of other ruin us. When my mother worked late, she left me with her oldest friends, Brian and Eric. They discussed everything\u2014politics, philosophy, physics, beer; and for every question I had, they had insightful and honest responses, even when I demanded to know what was so special about Indiana Pale Ale when I was five. They inspired my passion for learning and taught me about the world while my mom worked to make sure we still had a home. Brian was a chef. Most conversations happened while he saut\u00e9ed mushrooms or julienned peppers. Years passed, and on the night he made risotto, I stood in the kitchen and asked about welfare. I knew my mom and I had it, but I failed to understand the negative connotation surrounding it. They explained that people often have misconstrued ideas about welfare; they become close-minded to the lifestyles and perspectives of others as they adhere to their own confining positions as members of society. This made sense, but it did not seem fair, particularly after school that day. \u201cToday a girl laughed at me because we have welfare,\u201d I mumbled, shifting uncomfortably. \u201cShe said her mom said my mom shouldn\u2019t be in the PTA if she can\u2019t even come to meetings because she\u2019s working.\u201d Brian and Eric exchanged heavy glances, but I rambled on, voice shaking as I realized at the same time as everyone else in the room that this incident had affected me more than I initially thought it had. \u201cMy mom works really hard. For us. To keep us safe and fed and okay. They don\u2019t get to say she isn\u2019t doing enough when she\u2019s trying her best.\u201d They hesitated the way adults do before having serious conversations. \u201cKiddo\u2014there are a lot of things about the world that aren\u2019t fair. This is one of them,\u201d Brian started. \u201cThat girl and her mom try to tear down people like you and your mom because they have no perception of how hard you two work to be where you are. They won\u2019t try to understand because they don\u2019t want to. And that\u2019s not on you, that\u2019s on them.\u201d And I understood. I knew that my mom and I worked hard. Welfare did not make me anyone\u2019s inferior; instead, it taught me about perspective. People are quick to judge what they do not know or understand, because empathy is not indoctrinated in people as well as derision and hatred are. Empathy and morality are traits that I believe take priority over any other; I care about how people treat each other, because I have seen the damage that results when people become too self-involved to care about how their words affect others. The best way for me to inspire that empathy is through arts and humanities. Brian and Eric helped cultivate my passion for learning about people and for evoking emotion within them to form meaningful connections, and whether it is through art, literature, or human sciences, I want to be someone who can open people up to different perspectives, and I want to do it by learning as much as I can so that I have something to give back. on the spectrum from slightly interesting to life-changing. On the flight home from China I, of course, chose to sit next to a stranger\u2026 and it didn\u2019t disappoint.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0068", "text": "In Fyodor Dostoevsky\u2019s, \u201cCrime and Punishment\u201d, the character Sonia is metaphorically linked to Christ. After prostituting herself to feed her family, she covers her head and face in shawls, before lying on her bed face down and sobbing\u2013 through this, she is linked to the death of Jesus. Her mother, Katarina, kisses her feet while she sobs, the same way people in the churches of that time wept and kissed at the feet of idols to Christ. In this situation, Dostoevsky is implying that even something such as prostitution that might be deemed a sin can instead be that which allows one to be a Saint. As my mother choked up while I described the above anecdote, I was filled with confusion. What could lead her to be so upset over this philosophical question? I asked if there was something she wanted to talk about and to say there was would be an understatement. She described to me the process by which my Father, in pursuit of a sexual relationship with a young woman, had demolished our family\u2019s house, and all of my Mom\u2019s identifying documents, before successfully taking away both me and my brother. While my father wasn\u2019t on my birth certificate for a Welfare bid, and my mother regained custody of me, my brother had to remain in the care of a man who put little emphasis on caring for his sons at that point in his life. My mother was left with no money, no place to live, and no friends who would lend their support. She turned to her sister for guidance and instead of love and compassion was met with cruelty, deceit, and greed. My mother found a parallel between herself and Sonia. Both were faced with a problem the likes of which seems unsolvable and were thrust into a patriarchal system that far too often values little of women beyond the most primitive desires. Despite constant attempts to get herself onto a more admirable path, the system resisted her. She could not afford to purchase new identifying documents without missing rent, and I couldn\u2019t handle being paraded through 105-degree weather. She was stuck. My dad came back and offered to continue their relationship after more than a year of abject poverty and lack of bodily autonomy. And she accepted the invitation into the man who had ruined her life for me. After going through a phase of alcoholism and an instance of domestic violence against my Father, I viewed my mother as immoral, or misguided at the least. I was wrong. Despite experiencing some of the worst things a human can experience, and being able to tell nobody about it, she remained in a household with a man who intentionally hurt her beyond belief, for my well being. If there is a God above us, he views Sonia and my Mother not as sinners, but as Saints, and in that conviction, I could not be more absolute.", "source": "CollegeEssay", "is_esl": false}
{"id": "college_0069", "text": "The craft of storytelling, for me, is holy. Looking back on my life, I don\u2019t see one defining moment where I realized that my purpose is to study, compose, and teach story. It\u2019s more like a collection of snapshots whipping by, each one yellowed with age and fingerprints. I remember reading The Empty Space by Peter Brook on theatre theory long into the night, encountering the line, \u201cDrama was exposure, it was confrontation\u2026 it led to\u2026 an awakening of understanding.\u201d These words were what led me to the discovery of how storytelling is an emotional confrontation between the author and the writing and between the writing and the audience. It\u2019s collision. It\u2019s catharsis. Catharsis defines me as a playwright. The first play I wrote, The Rocket Man, adapted from a short story of the same name by Ray Bradbury, follows a teenage boy whose astronaut father spends much of his time in space. It\u2019s uncanny \u2013 that\u2019s my entire life. My own father travels from Denver to Los Angeles four days a week on business, and my family isn\u2019t whole unless he\u2019s with us. Drafting a scene of The Rocket Man, where the boy confronts his father before he leaves again, changed my life: Stay with me, the boy begged in the original scene I added. Please. I immediately began to cry, praying that my own father, a thousand miles away, was listening. I learned that day that catharsis is releasing my own story within a story. When the line between my soul and the soul of my story blurs, that\u2019s when the real work happens. The construct of The Rocket Man was like a cathedral, with my own emotion as stained glass and my memories as arches, but I realized after sharing it with my cast and crew for the first time that a cathedral is nothing without people to experience it. My 18-year-old male lead, Pierce, cried when he first read the script. So did my light designer and sound designer. What I want is to recreate this experience for an audience as a playwright with the intention of establishing the theatre as a safe place. You can grieve here. You can be seen here. You can hope here. This goal starts not just with craft, but with overwhelming love for that audience. At its core, storytelling is service. One of the defining challenges of my life presented itself as the opportunity to create and execute a free playwriting course for middle-school girls. When the pandemic hit, it forced me to reimagine my course for a virtual setting offered through the local school district; I realigned everything \u2013 my three-week curriculum, my downloadable course exercises, and my teaching strategies. Teaching playwriting to middle-school girls over Zoom meant listening to their struggle to make friends at school and their desire to participate in protest marches against the will of their parents. With each lesson, they experienced the transcendence of having their lives and emotions reflected through story, and they loved it. One student, Isabel, told me with ten exclamation points about how excited she was for class. She even filmed a one-woman version of a play she wrote, complete with costumes and accents. I came out of class every night feeling like I might burst from joy. Showing students how to release their own story within a story is the most purposeful thing I have ever done. Sitting in a theatre as the overture starts, hearing a thousand conversations stop in the span of a single heartbeat. A hand over my mouth in awe as I watch the finale and wonder at how a two-hour show can contain all the nuances of life. That\u2019s why I exist \u2013 to offer story. To teach it. That\u2019s my mission and my ministry.", "source": "CollegeEssay", "is_esl": false}
