#!/usr/bin/env python3
"""
Quick integration test for validated detector ensemble.
Verifies both RoBERTa and Fast-DetectGPT are working correctly.
"""

import asyncio
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from stealthrl.tinker.detectors import DetectorCache, DetectorEnsemble


async def test_detector_ensemble():
    """Test the integrated detector ensemble."""
    
    print("\n" + "=" * 80)
    print("Testing Validated Detector Ensemble")
    print("=" * 80)
    
    # Initialize cache
    cache = DetectorCache(cache_path="cache/test_detectors.db")
    
    # Initialize ensemble with validated detectors
    print("\nðŸ“¦ Initializing detector ensemble...")
    ensemble = DetectorEnsemble(
        detector_names=["roberta_openai", "fast_detectgpt"],
        detector_weights={
            "roberta_openai": 0.6,
            "fast_detectgpt": 0.4,
        },
        cache_path="cache/test_detectors.db",
        fast_detectgpt_model="gpt-neo-2.7B",
        roberta_openai_model="roberta-large-openai-detector",
    )
    
    print("âœ“ Ensemble initialized")
    print(f"  Detectors: {list(ensemble.detectors.keys())}")
    print(f"  Weights: {ensemble.weights}")
    
    # Pre-warm models
    print("\nðŸ”¥ Pre-warming detector models (may take 2-5 min on first run)...")
    ensemble.prewarm_models()
    print("âœ“ All models pre-warmed and ready")
    
    # Test texts
    test_cases = [
        {
            "text": "The quick brown fox jumps over the lazy dog.",
            "expected": "Low score (human-like)",
        },
        {
            "text": "In conclusion, this essay demonstrates that artificial intelligence has "
                   "significantly impacted modern society in various ways, including but not "
                   "limited to technological advancement, economic transformation, and social change.",
            "expected": "Higher score (AI-like)",
        },
    ]
    
    print("\n" + "=" * 80)
    print("Running Test Cases")
    print("=" * 80)
    
    for i, test_case in enumerate(test_cases, 1):
        text = test_case["text"]
        expected = test_case["expected"]
        
        print(f"\nðŸ§ª Test Case {i}: {expected}")
        print(f"   Text: {text[:80]}...")
        
        # Compute ensemble score
        result = await ensemble.compute(text)
        
        ensemble_prob = result["ensemble_prob"]
        detector_scores = result["detector_scores"]
        
        print(f"\n   ðŸ“Š Results:")
        print(f"      RoBERTa Score:       {detector_scores['roberta_openai']:.3f} (60% weight)")
        print(f"      Fast-DetectGPT:      {detector_scores['fast_detectgpt']:.3f} (40% weight)")
        print(f"      Ensemble P(AI):      {ensemble_prob:.3f}")
        print(f"      Detector Reward:     {1.0 - ensemble_prob:.3f} (1 - P(AI))")
        
        # Interpretation
        if ensemble_prob < 0.3:
            interpretation = "âœ… Human-like (low AI probability)"
        elif ensemble_prob < 0.6:
            interpretation = "âš ï¸ Uncertain (medium AI probability)"
        else:
            interpretation = "âŒ AI-like (high AI probability)"
        
        print(f"      Interpretation:      {interpretation}")
    
    # Performance summary
    print("\n" + "=" * 80)
    print("Integration Test Summary")
    print("=" * 80)
    print("\nâœ… SUCCESS:")
    print("   - Both detectors loaded and working")
    print("   - Ensemble weighting applied correctly (60/40)")
    print("   - Scores computed and cached")
    print("   - Ready for RL training")
    
    print("\nðŸ“š Validation Results:")
    print("   - RoBERTa-large-openai-detector: AUROC 0.891 (200 samples)")
    print("   - Fast-DetectGPT gpt-neo-2.7B:   AUROC 0.691 (5000 samples)")
    print("   - Ensemble (estimated):          AUROC ~0.81")
    
    print("\nðŸš€ Next Steps:")
    print("   1. Run full training: python -m stealthrl.tinker.train --config configs/tinker_stealthrl.yaml")
    print("   2. Monitor detector scores during training")
    print("   3. Evaluate trained model on MAGE test set")
    
    print("\n" + "=" * 80)
    
    # Cleanup
    ensemble.close()


if __name__ == "__main__":
    try:
        asyncio.run(test_detector_ensemble())
    except KeyboardInterrupt:
        print("\n\nâš  Test interrupted by user")
        sys.exit(0)
    except Exception as e:
        print(f"\n\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
