# Task 2: Dataset Curation

**Status**: ğŸš§ IN PROGRESS

---

## ğŸ“‹ Overview

This folder contains all materials for **TASK 2: Dataset Curation** - preparing ESL/native corpus for StealthRL training and fairness evaluation.

---

## ğŸ¯ Objectives

1. âœ… Download ChatGPT-Detector-Bias dataset (primary ESL source)
2. âœ… Extract TOEFL essays (ESL data) and native writing samples
3. âœ… Convert to required JSONL format
4. âœ… Generate AI text versions if needed
5. âœ… Create stratified splits (40% ESL, 60% native)
6. âœ… Prepare training data for Tinker platform

**Target**: 1000-2000 samples total (400-800 ESL, 600-1200 native)

---

## ğŸ“ Directory Structure

```
task2_dataset_curation/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ TASK2_COMPLETION_REPORT.md         # Final completion report
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ convert_chatgpt_bias_data.py   # Main conversion script
â”‚   â”œâ”€â”€ generate_ai_text.py            # AI text generation (if needed)
â”‚   â””â”€â”€ validate_datasets.py           # Dataset validation
â”œâ”€â”€ notebooks/                          # Exploration notebooks (optional)
â”‚   â””â”€â”€ explore_chatgpt_bias.ipynb
â””â”€â”€ logs/
    â”œâ”€â”€ conversion.log                 # Conversion logs
    â””â”€â”€ validation.log                 # Validation results
```

---

## ğŸš€ Execution Steps

### Step 1: Download Datasets âœ…

```bash
cd /Users/nishchaymahor/Documents/Study/291\ -\ Safety\ in\ Gen\ AI/StealthRL/StealthRL
bash scripts/download_datasets.sh
```

**Downloads:**
- `data/raw/ChatGPT-Detector-Bias/` - Primary ESL/native source

### Step 2: Explore Data Structure ğŸ”

```bash
cd data/raw/ChatGPT-Detector-Bias
ls -la
cat README.md
```

**Identify:**
- Where TOEFL essays are located
- Where native samples are located
- Current data format
- Available metadata (is_esl, proficiency, etc.)

### Step 3: Convert to Required Format ğŸ”§

```bash
python task2_dataset_curation/scripts/convert_chatgpt_bias_data.py \
    --input data/raw/ChatGPT-Detector-Bias \
    --output-esl data/esl/toefl11.jsonl \
    --output-native data/native/native_academic.jsonl \
    --log task2_dataset_curation/logs/conversion.log
```

**Output format:**
```json
{
  "id": "toefl11_001",
  "text": "Essay text...",
  "source": "TOEFL11",
  "is_esl": true,
  "proficiency_level": "medium",
  "prompt_id": "P1"
}
```

### Step 4: Generate AI Text (If Needed) ğŸ¤–

If data only contains human text, generate AI versions:

```bash
python task2_dataset_curation/scripts/generate_ai_text.py \
    --input data/esl/toefl11.jsonl \
    --output data/esl/toefl11_with_ai.jsonl \
    --model gpt-3.5-turbo
```

### Step 5: Create Evaluation Splits âœ…

```bash
python -m stealthrl.data.esl_native_corpus
```

**Creates:**
- `data/processed/esl_native_dev.jsonl` (200 samples)
- `data/processed/esl_native_test.jsonl` (500 samples)

### Step 6: Create Training Data âœ…

```bash
python scripts/prepare_tinker_data.py \
    --input-paths data/esl/toefl11.jsonl data/native/native_academic.jsonl \
    --output-dir data/tinker \
    --train-split 0.8
```

**Creates:**
- `data/tinker/train.jsonl` (80% training)
- `data/tinker/test.jsonl` (20% testing)

### Step 7: Validate ğŸ”

```bash
python task2_dataset_curation/scripts/validate_datasets.py \
    --esl-data data/esl/toefl11.jsonl \
    --native-data data/native/native_academic.jsonl \
    --output task2_dataset_curation/logs/validation.log
```

---

## ğŸ“Š Expected Outputs

### Data Files

```
data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ ChatGPT-Detector-Bias/       # Downloaded raw data
â”œâ”€â”€ esl/
â”‚   â””â”€â”€ toefl11.jsonl                # Processed ESL data
â”œâ”€â”€ native/
â”‚   â””â”€â”€ native_academic.jsonl        # Processed native data
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ esl_native_dev.jsonl         # Dev split (200 samples)
â”‚   â””â”€â”€ esl_native_test.jsonl        # Test split (500 samples)
â””â”€â”€ tinker/
    â”œâ”€â”€ train.jsonl                   # Training data (80%)
    â””â”€â”€ test.jsonl                    # Testing data (20%)
```

### Statistics

**Target Composition:**
- ESL: 40% (400-800 samples)
- Native: 60% (600-1200 samples)
- Total: 1000-2000 samples

**Quality Metrics:**
- Valid JSONL format: 100%
- All required fields present: 100%
- Correct ESL ratio: 40% Â± 5%
- Stratified by source: Yes

---

## âœ… Success Criteria

- [x] ChatGPT-Detector-Bias downloaded successfully
- [ ] ESL data extracted and converted (TOEFL essays)
- [ ] Native data extracted and converted
- [ ] All files in correct JSONL format
- [ ] ESL/Native splits created (40/60 ratio)
- [ ] Training data prepared for Tinker
- [ ] Validation passed (all checks green)

---

## ğŸ› Troubleshooting

### Issue: ChatGPT-Detector-Bias has different structure than expected
**Solution**: Examine the actual structure and adapt conversion script

### Issue: Missing AI text field
**Solution**: Generate using GPT-3.5-turbo or local LLM

### Issue: Insufficient samples
**Solution**: Extract from other downloaded datasets (DetectRL, Ghostbuster)

### Issue: Imbalanced ESL/native ratio
**Solution**: Adjust sampling in `build_esl_native_eval_split()`

---

## ğŸ“š References

- Main README: `../README.md`
- ESL Fairness Guide: `../knowledge_base/ESL_FAIRNESS_GUIDE.md`
- Team Handoff: `../knowledge_base/TEAM_HANDOFF.md`
- Data Schema: `../stealthrl/data/esl_native_corpus.py`

---

**Last Updated**: December 1, 2025
